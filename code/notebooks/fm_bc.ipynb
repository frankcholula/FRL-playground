{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc11682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# flow_matching\n",
    "from flow_matching.path.scheduler import CondOTScheduler\n",
    "from flow_matching.path import AffineProbPath\n",
    "from flow_matching.solver import Solver, ODESolver\n",
    "from flow_matching.utils import ModelWrapper\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "# To avoide meshgrid warning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b92ffd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f93eed6d670>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    print('Using gpu')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('Using cpu.')\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7640966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return torch.sigmoid(x) * x\n",
    "\n",
    "\n",
    "# TODO: need to resolve temporal locality problem maybe with a CNN later.\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, time_dim: int = 1, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.time_dim = time_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim + time_dim, hidden_dim),\n",
    "            Swish(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            Swish(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            Swish(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            Swish(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor, t: Tensor) -> Tensor:\n",
    "        sz = x.size()\n",
    "        x = x.reshape(-1, self.input_dim)\n",
    "        t = t.reshape(-1, self.time_dim).float()\n",
    "\n",
    "        t = t.reshape(-1, 1).expand(x.shape[0], 1)\n",
    "        h = torch.cat([x, t], dim=1)\n",
    "        output = self.main(h)\n",
    "\n",
    "        return output.reshape(*sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3416b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_fn(batch):\n",
    "#     batch_observations = []\n",
    "#     batch_actions = []\n",
    "\n",
    "#     for episode_data in batch:\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        \"id\": torch.Tensor([x.id for x in batch]),\n",
    "        \"observations\": torch.nn.utils.rnn.pad_sequence(\n",
    "            [torch.as_tensor(x.observations) for x in batch],\n",
    "            batch_first=True\n",
    "        ),\n",
    "        \"actions\": torch.nn.utils.rnn.pad_sequence(\n",
    "            [torch.as_tensor(x.actions) for x in batch],\n",
    "            batch_first=True\n",
    "        ),\n",
    "        \"rewards\": torch.nn.utils.rnn.pad_sequence(\n",
    "            [torch.as_tensor(x.rewards) for x in batch],\n",
    "            batch_first=True\n",
    "        ),\n",
    "        \"terminations\": torch.nn.utils.rnn.pad_sequence(\n",
    "            [torch.as_tensor(x.terminations) for x in batch],\n",
    "            batch_first=True\n",
    "        ),\n",
    "        \"truncations\": torch.nn.utils.rnn.pad_sequence(\n",
    "            [torch.as_tensor(x.truncations) for x in batch],\n",
    "            batch_first=True\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9751e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EpisodeData(id=0, total_steps=1000, observations=ndarray of shape (1001, 8) and dtype float32, actions=ndarray of shape (1000, 2) and dtype float32, rewards=ndarray of 1000 floats, terminations=ndarray of 1000 bools, truncations=ndarray of 1000 bools, infos=dict with the following keys: [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load minari dataset\n",
    "import minari\n",
    "minari_dataset = minari.load_dataset(dataset_id=\"LunarLanderContinuous-v3/ppo-1000-v1\")\n",
    "dataloader = DataLoader(minari_dataset, batch_size=256, shuffle=True, collate_fn=collate_fn)\n",
    "env = minari_dataset.recover_environment()\n",
    "episode = minari_dataset[0]\n",
    "episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fc663f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess dataset to the right horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325af361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "| Epoch    100 | 0.76 s/epoch | Loss  0.95060 \n",
      "| Epoch    200 | 0.84 s/epoch | Loss  0.86491 \n",
      "| Epoch    300 | 0.83 s/epoch | Loss  0.82484 \n",
      "| Epoch    400 | 0.84 s/epoch | Loss  0.80036 \n",
      "| Epoch    500 | 0.85 s/epoch | Loss  0.79039 \n",
      "| Epoch    600 | 0.83 s/epoch | Loss  0.77608 \n",
      "| Epoch    700 | 0.84 s/epoch | Loss  0.76352 \n",
      "| Epoch    800 | 0.84 s/epoch | Loss  0.75767 \n",
      "| Epoch    900 | 0.82 s/epoch | Loss  0.75547 \n",
      "| Epoch   1000 | 0.84 s/epoch | Loss  0.74468 \n",
      "| Epoch   1100 | 0.84 s/epoch | Loss  0.73785 \n",
      "| Epoch   1200 | 0.84 s/epoch | Loss  0.73716 \n",
      "| Epoch   1300 | 0.84 s/epoch | Loss  0.72871 \n",
      "| Epoch   1400 | 0.84 s/epoch | Loss  0.73089 \n",
      "| Epoch   1500 | 0.84 s/epoch | Loss  0.72767 \n",
      "| Epoch   1600 | 0.84 s/epoch | Loss  0.72332 \n",
      "| Epoch   1700 | 0.84 s/epoch | Loss  0.72246 \n",
      "| Epoch   1800 | 0.84 s/epoch | Loss  1.22273 \n",
      "| Epoch   1900 | 0.85 s/epoch | Loss  1.23737 \n",
      "| Epoch   2000 | 0.83 s/epoch | Loss  1.39969 \n",
      "| Epoch   2100 | 0.84 s/epoch | Loss  1.16784 \n",
      "| Epoch   2200 | 0.86 s/epoch | Loss  1.37827 \n",
      "| Epoch   2300 | 0.85 s/epoch | Loss  1.25674 \n",
      "| Epoch   2400 | 0.85 s/epoch | Loss  1.12477 \n",
      "| Epoch   2500 | 0.84 s/epoch | Loss  1.11416 \n",
      "| Epoch   2600 | 0.85 s/epoch | Loss  1.10418 \n",
      "| Epoch   2700 | 0.85 s/epoch | Loss  1.09903 \n",
      "| Epoch   2800 | 0.82 s/epoch | Loss  1.08919 \n",
      "| Epoch   2900 | 0.84 s/epoch | Loss  1.08658 \n",
      "| Epoch   3000 | 0.83 s/epoch | Loss  1.08520 \n",
      "| Epoch   3100 | 0.82 s/epoch | Loss  1.08395 \n",
      "| Epoch   3200 | 0.83 s/epoch | Loss  1.08350 \n",
      "| Epoch   3300 | 0.81 s/epoch | Loss  1.08073 \n",
      "| Epoch   3400 | 0.84 s/epoch | Loss  1.08342 \n",
      "| Epoch   3500 | 0.83 s/epoch | Loss  1.08171 \n",
      "| Epoch   3600 | 0.82 s/epoch | Loss  1.08080 \n",
      "| Epoch   3700 | 0.82 s/epoch | Loss  1.08225 \n",
      "| Epoch   3800 | 0.83 s/epoch | Loss  1.08246 \n",
      "| Epoch   3900 | 0.83 s/epoch | Loss  1.08198 \n",
      "| Epoch   4000 | 0.81 s/epoch | Loss  1.08132 \n",
      "| Epoch   4100 | 0.82 s/epoch | Loss  1.08171 \n",
      "| Epoch   4200 | 0.81 s/epoch | Loss  1.08353 \n",
      "| Epoch   4300 | 0.85 s/epoch | Loss  1.07923 \n",
      "| Epoch   4400 | 0.83 s/epoch | Loss  1.08342 \n",
      "| Epoch   4500 | 0.82 s/epoch | Loss  1.08293 \n",
      "| Epoch   4600 | 0.84 s/epoch | Loss  1.07950 \n",
      "| Epoch   4700 | 0.82 s/epoch | Loss  1.08128 \n",
      "| Epoch   4800 | 0.82 s/epoch | Loss  1.08029 \n",
      "| Epoch   4900 | 0.82 s/epoch | Loss  1.08302 \n",
      "| Epoch   5000 | 0.83 s/epoch | Loss  1.08244 \n",
      "| Epoch   5100 | 0.81 s/epoch | Loss  1.08284 \n",
      "| Epoch   5200 | 0.82 s/epoch | Loss  1.08031 \n",
      "| Epoch   5300 | 0.82 s/epoch | Loss  1.08345 \n",
      "| Epoch   5400 | 0.82 s/epoch | Loss  1.08366 \n",
      "| Epoch   5500 | 0.84 s/epoch | Loss  1.08511 \n",
      "| Epoch   5600 | 0.81 s/epoch | Loss  1.08456 \n",
      "| Epoch   5700 | 0.83 s/epoch | Loss  1.08283 \n",
      "| Epoch   5800 | 0.80 s/epoch | Loss  1.08388 \n",
      "| Epoch   5900 | 0.82 s/epoch | Loss  1.07967 \n",
      "| Epoch   6000 | 0.83 s/epoch | Loss  1.07977 \n",
      "| Epoch   6100 | 0.82 s/epoch | Loss  1.08327 \n",
      "| Epoch   6200 | 0.81 s/epoch | Loss  1.08335 \n",
      "| Epoch   6300 | 0.82 s/epoch | Loss  1.08132 \n",
      "| Epoch   6400 | 0.83 s/epoch | Loss  1.08256 \n",
      "| Epoch   6500 | 0.80 s/epoch | Loss  1.07884 \n",
      "| Epoch   6600 | 0.82 s/epoch | Loss  1.08109 \n",
      "| Epoch   6700 | 0.82 s/epoch | Loss  1.08120 \n",
      "| Epoch   6800 | 0.82 s/epoch | Loss  1.07977 \n",
      "| Epoch   6900 | 0.80 s/epoch | Loss  1.08630 \n",
      "| Epoch   7000 | 0.83 s/epoch | Loss  1.08328 \n",
      "| Epoch   7100 | 0.82 s/epoch | Loss  1.08141 \n",
      "| Epoch   7200 | 0.82 s/epoch | Loss  1.08132 \n",
      "| Epoch   7300 | 0.84 s/epoch | Loss  1.08110 \n",
      "| Epoch   7400 | 0.81 s/epoch | Loss  1.08264 \n",
      "| Epoch   7500 | 0.82 s/epoch | Loss  1.08171 \n",
      "| Epoch   7600 | 0.83 s/epoch | Loss  1.08333 \n",
      "| Epoch   7700 | 0.83 s/epoch | Loss  1.08385 \n",
      "| Epoch   7800 | 0.83 s/epoch | Loss  1.07986 \n",
      "| Epoch   7900 | 0.83 s/epoch | Loss  1.07784 \n",
      "| Epoch   8000 | 0.83 s/epoch | Loss  1.08371 \n",
      "| Epoch   8100 | 0.82 s/epoch | Loss  1.08331 \n",
      "| Epoch   8200 | 0.83 s/epoch | Loss  1.08154 \n",
      "| Epoch   8300 | 0.82 s/epoch | Loss  1.08366 \n",
      "| Epoch   8400 | 0.83 s/epoch | Loss  1.08191 \n",
      "| Epoch   8500 | 0.83 s/epoch | Loss  1.07910 \n",
      "| Epoch   8600 | 0.82 s/epoch | Loss  1.08167 \n",
      "| Epoch   8700 | 0.82 s/epoch | Loss  1.08429 \n",
      "| Epoch   8800 | 0.82 s/epoch | Loss  1.08257 \n",
      "| Epoch   8900 | 0.81 s/epoch | Loss  1.08317 \n",
      "| Epoch   9000 | 0.83 s/epoch | Loss  1.08231 \n",
      "| Epoch   9100 | 0.83 s/epoch | Loss  1.08127 \n",
      "| Epoch   9200 | 0.82 s/epoch | Loss  1.08250 \n",
      "| Epoch   9300 | 0.83 s/epoch | Loss  1.07885 \n",
      "| Epoch   9400 | 0.82 s/epoch | Loss  1.08400 \n",
      "| Epoch   9500 | 0.82 s/epoch | Loss  1.08311 \n",
      "| Epoch   9600 | 0.81 s/epoch | Loss  1.08111 \n",
      "| Epoch   9700 | 0.83 s/epoch | Loss  1.08140 \n",
      "| Epoch   9800 | 0.82 s/epoch | Loss  1.08219 \n",
      "| Epoch   9900 | 0.83 s/epoch | Loss  1.08515 \n",
      "| Epoch  10000 | 0.82 s/epoch | Loss  1.08186 \n",
      "| Epoch  10100 | 0.81 s/epoch | Loss  1.08094 \n",
      "| Epoch  10200 | 0.82 s/epoch | Loss  1.08053 \n",
      "| Epoch  10300 | 0.85 s/epoch | Loss  1.08149 \n",
      "| Epoch  10400 | 0.82 s/epoch | Loss  1.08276 \n",
      "| Epoch  10500 | 0.82 s/epoch | Loss  1.08093 \n",
      "| Epoch  10600 | 0.84 s/epoch | Loss  1.08018 \n",
      "| Epoch  10700 | 0.82 s/epoch | Loss  1.08428 \n",
      "| Epoch  10800 | 0.83 s/epoch | Loss  1.08632 \n",
      "| Epoch  10900 | 0.82 s/epoch | Loss  1.08055 \n",
      "| Epoch  11000 | 0.82 s/epoch | Loss  1.08357 \n",
      "| Epoch  11100 | 0.83 s/epoch | Loss  1.08380 \n",
      "| Epoch  11200 | 0.83 s/epoch | Loss  1.08290 \n",
      "| Epoch  11300 | 0.82 s/epoch | Loss  1.08548 \n",
      "| Epoch  11400 | 0.82 s/epoch | Loss  1.08176 \n",
      "| Epoch  11500 | 0.84 s/epoch | Loss  1.08376 \n",
      "| Epoch  11600 | 0.83 s/epoch | Loss  1.08296 \n",
      "| Epoch  11700 | 0.85 s/epoch | Loss  1.08219 \n",
      "| Epoch  11800 | 0.83 s/epoch | Loss  1.07958 \n",
      "| Epoch  11900 | 0.83 s/epoch | Loss  1.08225 \n",
      "| Epoch  12000 | 0.83 s/epoch | Loss  1.08079 \n",
      "| Epoch  12100 | 0.83 s/epoch | Loss  1.08364 \n",
      "| Epoch  12200 | 0.83 s/epoch | Loss  1.08324 \n",
      "| Epoch  12300 | 0.82 s/epoch | Loss  1.08146 \n",
      "| Epoch  12400 | 0.83 s/epoch | Loss  1.08029 \n",
      "| Epoch  12500 | 0.82 s/epoch | Loss  1.08001 \n",
      "| Epoch  12600 | 0.82 s/epoch | Loss  1.08261 \n",
      "| Epoch  12700 | 0.83 s/epoch | Loss  1.08279 \n",
      "| Epoch  12800 | 0.81 s/epoch | Loss  1.08106 \n",
      "| Epoch  12900 | 0.81 s/epoch | Loss  1.08386 \n",
      "| Epoch  13000 | 0.83 s/epoch | Loss  1.08682 \n",
      "| Epoch  13100 | 0.82 s/epoch | Loss  1.08128 \n",
      "| Epoch  13200 | 0.82 s/epoch | Loss  1.08460 \n",
      "| Epoch  13300 | 0.82 s/epoch | Loss  1.08196 \n",
      "| Epoch  13400 | 0.82 s/epoch | Loss  1.08251 \n",
      "| Epoch  13500 | 0.84 s/epoch | Loss  1.08185 \n",
      "| Epoch  13600 | 0.82 s/epoch | Loss  1.08310 \n",
      "| Epoch  13700 | 0.82 s/epoch | Loss  1.08083 \n",
      "| Epoch  13800 | 0.83 s/epoch | Loss  1.08427 \n",
      "| Epoch  13900 | 0.82 s/epoch | Loss  1.08459 \n",
      "| Epoch  14000 | 0.82 s/epoch | Loss  1.08199 \n",
      "| Epoch  14100 | 0.82 s/epoch | Loss  1.08308 \n",
      "| Epoch  14200 | 0.82 s/epoch | Loss  1.08213 \n",
      "| Epoch  14300 | 0.82 s/epoch | Loss  1.08256 \n",
      "| Epoch  14400 | 0.84 s/epoch | Loss  1.08583 \n",
      "| Epoch  14500 | 0.82 s/epoch | Loss  1.08124 \n",
      "| Epoch  14600 | 0.82 s/epoch | Loss  1.08041 \n",
      "| Epoch  14700 | 0.82 s/epoch | Loss  1.08279 \n",
      "| Epoch  14800 | 0.83 s/epoch | Loss  1.08231 \n",
      "| Epoch  14900 | 0.84 s/epoch | Loss  1.08216 \n",
      "| Epoch  15000 | 0.81 s/epoch | Loss  1.08315 \n",
      "| Epoch  15100 | 0.84 s/epoch | Loss  1.08311 \n",
      "| Epoch  15200 | 0.83 s/epoch | Loss  1.08122 \n",
      "| Epoch  15300 | 0.83 s/epoch | Loss  1.08066 \n",
      "| Epoch  15400 | 0.82 s/epoch | Loss  1.08343 \n",
      "| Epoch  15500 | 0.81 s/epoch | Loss  1.08029 \n",
      "| Epoch  15600 | 0.85 s/epoch | Loss  1.08032 \n",
      "| Epoch  15700 | 0.82 s/epoch | Loss  1.08411 \n",
      "| Epoch  15800 | 0.82 s/epoch | Loss  1.08378 \n",
      "| Epoch  15900 | 0.84 s/epoch | Loss  1.08367 \n",
      "| Epoch  16000 | 0.83 s/epoch | Loss  1.08253 \n",
      "| Epoch  16100 | 0.83 s/epoch | Loss  1.08305 \n",
      "| Epoch  16200 | 0.84 s/epoch | Loss  1.08086 \n",
      "| Epoch  16300 | 0.82 s/epoch | Loss  1.08086 \n",
      "| Epoch  16400 | 0.83 s/epoch | Loss  1.08106 \n",
      "| Epoch  16500 | 0.82 s/epoch | Loss  1.08413 \n",
      "| Epoch  16600 | 0.83 s/epoch | Loss  1.08179 \n",
      "| Epoch  16700 | 0.82 s/epoch | Loss  1.08380 \n",
      "| Epoch  16800 | 0.83 s/epoch | Loss  1.08011 \n",
      "| Epoch  16900 | 0.84 s/epoch | Loss  1.08162 \n",
      "| Epoch  17000 | 0.82 s/epoch | Loss  1.08158 \n",
      "| Epoch  17100 | 0.83 s/epoch | Loss  1.08131 \n",
      "| Epoch  17200 | 0.82 s/epoch | Loss  1.08199 \n",
      "| Epoch  17300 | 0.82 s/epoch | Loss  1.08297 \n",
      "| Epoch  17400 | 0.83 s/epoch | Loss  1.08318 \n",
      "| Epoch  17500 | 0.84 s/epoch | Loss  1.08258 \n",
      "| Epoch  17600 | 0.82 s/epoch | Loss  1.08047 \n",
      "| Epoch  17700 | 0.84 s/epoch | Loss  1.08152 \n",
      "| Epoch  17800 | 0.83 s/epoch | Loss  1.08240 \n",
      "| Epoch  17900 | 0.82 s/epoch | Loss  1.08308 \n",
      "| Epoch  18000 | 0.84 s/epoch | Loss  1.08159 \n",
      "| Epoch  18100 | 0.82 s/epoch | Loss  1.08431 \n",
      "| Epoch  18200 | 0.81 s/epoch | Loss  1.08530 \n",
      "| Epoch  18300 | 0.82 s/epoch | Loss  1.08066 \n",
      "| Epoch  18400 | 0.84 s/epoch | Loss  1.08381 \n",
      "| Epoch  18500 | 0.83 s/epoch | Loss  1.08250 \n",
      "| Epoch  18600 | 0.83 s/epoch | Loss  1.08322 \n",
      "| Epoch  18700 | 0.83 s/epoch | Loss  1.08178 \n",
      "| Epoch  18800 | 0.82 s/epoch | Loss  1.08142 \n",
      "| Epoch  18900 | 0.83 s/epoch | Loss  1.08460 \n",
      "| Epoch  19000 | 0.82 s/epoch | Loss  1.08335 \n",
      "| Epoch  19100 | 0.81 s/epoch | Loss  1.08351 \n",
      "| Epoch  19200 | 0.82 s/epoch | Loss  1.08142 \n",
      "| Epoch  19300 | 0.82 s/epoch | Loss  1.08229 \n",
      "| Epoch  19400 | 0.83 s/epoch | Loss  1.08237 \n",
      "| Epoch  19500 | 0.83 s/epoch | Loss  1.08263 \n",
      "| Epoch  19600 | 0.83 s/epoch | Loss  1.08207 \n",
      "| Epoch  19700 | 0.83 s/epoch | Loss  1.08147 \n",
      "| Epoch  19800 | 0.83 s/epoch | Loss  1.08085 \n",
      "| Epoch  19900 | 0.82 s/epoch | Loss  1.08344 \n",
      "| Epoch  20000 | 0.82 s/epoch | Loss  1.08087 \n",
      "| Epoch  20100 | 0.83 s/epoch | Loss  1.08170 \n",
      "| Epoch  20200 | 0.83 s/epoch | Loss  1.08173 \n",
      "| Epoch  20300 | 0.83 s/epoch | Loss  1.08171 \n",
      "| Epoch  20400 | 0.83 s/epoch | Loss  1.08171 \n",
      "| Epoch  20500 | 0.83 s/epoch | Loss  1.08136 \n",
      "| Epoch  20600 | 0.83 s/epoch | Loss  1.08216 \n",
      "| Epoch  20700 | 0.82 s/epoch | Loss  1.08434 \n",
      "| Epoch  20800 | 0.82 s/epoch | Loss  1.08132 \n",
      "| Epoch  20900 | 0.82 s/epoch | Loss  1.08194 \n",
      "| Epoch  21000 | 0.82 s/epoch | Loss  1.08313 \n",
      "| Epoch  21100 | 0.83 s/epoch | Loss  1.08039 \n",
      "| Epoch  21200 | 0.84 s/epoch | Loss  1.08216 \n",
      "| Epoch  21300 | 0.83 s/epoch | Loss  1.08101 \n",
      "| Epoch  21400 | 0.82 s/epoch | Loss  1.08494 \n",
      "| Epoch  21500 | 0.81 s/epoch | Loss  1.08323 \n",
      "| Epoch  21600 | 0.82 s/epoch | Loss  1.08119 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     19\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# 1. Zero gradients for this batch\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# 2. Prepare data\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/School/FRL-playground/.frl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/Workspace/School/FRL-playground/.frl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Workspace/School/FRL-playground/.frl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Workspace/School/FRL-playground/.frl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Workspace/School/FRL-playground/.frl/lib/python3.10/site-packages/minari/dataset/minari_dataset.py:298\u001b[0m, in \u001b[0;36mMinariDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m EpisodeData:\n\u001b[1;32m    297\u001b[0m     episode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate_episodes([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_indices[idx]])\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepisode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/School/FRL-playground/.frl/lib/python3.10/site-packages/minari/dataset/_storages/hdf5_storage.py:132\u001b[0m, in \u001b[0;36mHDF5Storage.get_episodes\u001b[0;34m(self, episode_indices)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ep_idx \u001b[38;5;129;01min\u001b[39;00m episode_indices:\n\u001b[0;32m--> 132\u001b[0m         ep_group \u001b[38;5;241m=\u001b[39m \u001b[43mfile\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepisode_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mep_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ep_group, h5py\u001b[38;5;241m.\u001b[39mGroup)\n\u001b[1;32m    134\u001b[0m         infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Workspace/School/FRL-playground/.frl/lib/python3.10/site-packages/h5py/_hl/group.py:360\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 360\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:257\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5i.pyx:47\u001b[0m, in \u001b[0;36mh5py.h5i.wrap_identifier\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:404\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "horizon = 100 # need to adjust this\n",
    "action_dim = env.action_space.shape[0]\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "input_dim = (obs_dim + action_dim) * horizon\n",
    "\n",
    "# Training params\n",
    "lr = 0.001\n",
    "num_epochs = 1500\n",
    "print_every = 100\n",
    "hidden_dim = 1024\n",
    "\n",
    "vf = MLP(input_dim=input_dim, time_dim=1, hidden_dim=hidden_dim).to(device)\n",
    "path = AffineProbPath(scheduler=CondOTScheduler())\n",
    "optim = torch.optim.Adam(vf.parameters(), lr=lr)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch in dataloader:\n",
    "        # 1. Zero gradients for this batch\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # 2. Prepare data\n",
    "        observations = batch[\"observations\"][:, :-1][:, :horizon]\n",
    "        expert_actions = batch[\"actions\"][:, :horizon]\n",
    "        x_1 = torch.cat([observations, expert_actions], dim=-1)\n",
    "        x_1 = x_1.reshape(x_1.shape[0], -1).to(device)\n",
    "        x_0 = torch.randn_like(x_1).to(device)\n",
    "        t = torch.rand(x_1.shape[0]).to(device)\n",
    "\n",
    "        # 3. Forward pass and Loss\n",
    "        path_sample = path.sample(t=t, x_0=x_0, x_1=x_1)\n",
    "        predicted_velocity = vf(path_sample.x_t, path_sample.t)\n",
    "        loss = torch.pow(predicted_velocity - path_sample.dx_t, 2).mean()\n",
    "\n",
    "        # 4. Backward pass and Optimize\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "    if (epoch + 1) % print_every == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"| Epoch {epoch+1:6d} | {elapsed:.2f} s/epoch | Loss {avg_epoch_loss:8.5f} \")\n",
    "        start_time = time.time()\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "668e0d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try sampling from trained model...\n",
    "\n",
    "class WrappedModel(ModelWrapper):\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor, **extras):\n",
    "        return self.model(x, t)\n",
    "\n",
    "wrapped_vf = WrappedModel(vf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b22867d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step size for ode solver\n",
    "step_size = 0.05\n",
    "\n",
    "batch_size = 1  # batch size\n",
    "T = torch.linspace(0,1,10)  # sample times\n",
    "T = T.to(device=device)\n",
    "\n",
    "x_init = torch.randn((batch_size, input_dim), dtype=torch.float32, device=device)\n",
    "solver = ODESolver(velocity_model=wrapped_vf)  # create an ODESolver class\n",
    "sol = solver.sample(time_grid=T, x_init=x_init, method='midpoint', step_size=step_size, return_intermediates=True)  # sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66c6c74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 8]) torch.Size([100, 2])\n"
     ]
    }
   ],
   "source": [
    "final_trajectory = sol.reshape(horizon, -1)\n",
    "final_trajectory.shape\n",
    "observations = final_trajectory[:, :obs_dim]\n",
    "actions = final_trajectory[:, obs_dim:obs_dim + action_dim]\n",
    "print(observations.shape, actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4042d802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: [-1.1722629  0.7583265], Reward: 0.6375981558857995\n",
      "Action: [1.9599218  0.45798123], Reward: -4.504294383485461\n",
      "Action: [-1.0760934  2.048606 ], Reward: 0.2667735376406608\n",
      "Action: [0.59545684 0.6822942 ], Reward: -5.112996145088616\n",
      "Action: [-1.4163488  2.2833805], Reward: -0.08246028055910301\n",
      "Action: [ 1.9525062 -1.7280059], Reward: -1.4656804134121604\n",
      "Action: [ 0.63257545 -0.09153331], Reward: -1.854936977588261\n",
      "Action: [ 0.3800331  -0.53515935], Reward: -3.110143281546466\n",
      "Action: [-0.21625257  2.0234437 ], Reward: 0.060902082400816654\n",
      "Action: [ 0.33920717 -2.706087  ], Reward: -0.6641208879853298\n",
      "Action: [-1.2724048  0.7058647], Reward: 0.28389711074927393\n",
      "Action: [1.8796579 0.4381677], Reward: -2.6834044219850055\n",
      "Action: [-1.132049   2.0635967], Reward: -0.3745501055491036\n",
      "Action: [0.6013028 0.717165 ], Reward: -3.587055311932185\n",
      "Action: [-1.3698475  2.3062391], Reward: -0.8832771738943268\n",
      "Action: [ 2.0063336 -1.759538 ], Reward: -2.083958208590944\n",
      "Action: [ 0.6986403  -0.10829926], Reward: -3.2094981076997726\n",
      "Action: [ 0.41628554 -0.5399332 ], Reward: -0.6964520212966181\n",
      "Action: [-0.16445039  2.0317576 ], Reward: -0.7187770194976213\n",
      "Action: [ 0.37407503 -2.7143052 ], Reward: -3.156504813598268\n",
      "Action: [-1.368052   0.6534305], Reward: -0.4399433755976133\n",
      "Action: [1.7993307  0.41826895], Reward: -1.900916902633287\n",
      "Action: [-1.1893954  2.0776734], Reward: -1.0135054366517398\n",
      "Action: [0.60643303 0.75259537], Reward: -5.1528309424753616\n",
      "Action: [-1.3228009  2.3312917], Reward: -1.5107454110684262\n",
      "Action: [ 2.0603492 -1.7879362], Reward: -3.635005603143854\n",
      "Action: [ 0.7629432 -0.125735 ], Reward: -2.561414062260701\n",
      "Action: [ 0.4544264  -0.54444003], Reward: -2.221987704008543\n",
      "Action: [-0.11300112  2.0368829 ], Reward: -1.4511204690255386\n",
      "Action: [ 0.4089889 -2.722153 ], Reward: -1.0991220690782983\n",
      "Action: [-1.4586176  0.6013745], Reward: -1.2881184982893898\n",
      "Action: [1.720204 0.398341], Reward: -5.940665987939798\n",
      "Action: [-1.2484157  2.0905058], Reward: -1.8558378092685348\n",
      "Action: [0.61042035 0.7885    ], Reward: -5.440607902464069\n",
      "Action: [-1.275053   2.3580005], Reward: -2.114945528915824\n",
      "Action: [ 2.1148677 -1.8143696], Reward: -5.633588233247382\n",
      "Action: [ 0.82524645 -0.1434107 ], Reward: -4.087168373587508\n",
      "Action: [ 0.4941459 -0.5487459], Reward: -3.500746997350191\n",
      "Action: [-0.0623626  2.0397627], Reward: -2.2490588400504223\n",
      "Action: [ 0.4440478 -2.7298589], Reward: -3.4854391985719118\n",
      "Action: [-1.5435678  0.5496889], Reward: -1.8352135009417179\n",
      "Action: [1.6426517  0.37830538], Reward: -5.585615911181139\n",
      "Action: [-1.3095828  2.1016984], Reward: -2.72548854004654\n",
      "Action: [0.6128946  0.82478946], Reward: -6.623607491026592\n",
      "Action: [-1.2263716  2.3859801], Reward: -3.2515160640057545\n",
      "Action: [ 2.1700776 -1.8394891], Reward: -4.778918348286497\n",
      "Action: [ 0.8852977  -0.16079256], Reward: -5.759612778105224\n",
      "Action: [ 0.53528863 -0.5529295 ], Reward: -4.260349916362011\n",
      "Action: [-0.01282594  2.041047  ], Reward: -3.0450253287616804\n",
      "Action: [ 0.47944203 -2.7374573 ], Reward: -4.524906432868129\n",
      "Action: [-1.6224831   0.49812108], Reward: -2.0721540431068206\n",
      "Action: [1.5659978 0.3579571], Reward: -6.853401565319859\n",
      "Action: [-1.3733122  2.1108768], Reward: -3.1915916035431153\n",
      "Action: [0.61368066 0.86116976], Reward: -5.360937107446391\n",
      "Action: [-1.1766673  2.4148953], Reward: -3.5507534152380615\n",
      "Action: [ 2.2257876 -1.8632635], Reward: -4.9733631755833745\n",
      "Action: [ 0.9428221  -0.17709833], Reward: -5.904230091823218\n",
      "Action: [ 0.5776071 -0.5572047], Reward: -5.774547651908637\n",
      "Action: [0.03544039 2.0411336 ], Reward: -6.095607235786002\n",
      "Action: [ 0.5153679 -2.744805 ], Reward: -5.206024405879218\n",
      "Action: [-1.6957233   0.44630712], Reward: -2.4695909539245804\n",
      "Action: [1.488774   0.33703414], Reward: -8.62016750896662\n",
      "Action: [-1.4395435  2.1178396], Reward: -3.444192634801509\n",
      "Action: [0.61299664 0.89702046], Reward: -10.293833752579921\n",
      "Action: [-1.126166   2.4443386], Reward: -3.7730663658699357\n",
      "Action: [ 2.2814467 -1.8852873], Reward: -7.386212246808116\n",
      "Action: [ 0.99767506 -0.1912971 ], Reward: -7.785294031883916\n",
      "Action: [ 0.620486 -0.561966], Reward: -9.818412356384078\n",
      "Action: [0.08233292 2.0404348 ], Reward: -5.924837032030114\n",
      "Action: [ 0.5518519 -2.7516735], Reward: -5.714277528447297\n",
      "Action: [-1.7646893   0.39390752], Reward: -2.909104457285707\n",
      "Action: [1.4094316  0.31532395], Reward: -11.088130120580605\n",
      "Action: [-1.5076406  2.1225903], Reward: -3.683297493355694\n",
      "Action: [0.6114291 0.9315582], Reward: -7.0468275403835285\n",
      "Action: [-1.0753227  2.4739006], Reward: -4.067214351365947\n",
      "Action: [ 2.3364894 -1.9051902], Reward: -12.26906040261055\n",
      "Action: [ 1.0498363  -0.20224261], Reward: -9.401998991508595\n",
      "Action: [ 0.66301346 -0.56766856], Reward: -7.489279421867925\n",
      "Action: [0.12767 2.03943], Reward: -7.008546372359108\n",
      "Action: [ 0.58866715 -2.7578409 ], Reward: -6.147621285872463\n",
      "Action: [-1.8316206   0.34063512], Reward: -3.1908952774890054\n",
      "Action: [1.3267964  0.29270297], Reward: -12.891080676388402\n",
      "Action: [-1.5766191  2.1252737], Reward: -3.808622139277047\n",
      "Action: [0.60974807 0.964039  ], Reward: -9.52961355808116\n",
      "Action: [-1.0246317  2.5032618], Reward: -4.239396455905449\n",
      "Action: [ 2.3905907 -1.9228003], Reward: -9.584779850142768\n",
      "Action: [ 1.0991975 -0.2086297], Reward: -12.467403630743366\n",
      "Action: [ 0.7042136  -0.57471615], Reward: -12.234664505019474\n",
      "Action: [0.17103481 2.038551  ], Reward: -6.685244191094971\n",
      "Action: [ 0.62539613 -2.76312   ], Reward: -7.550019876158403\n",
      "Action: [-1.8995593   0.28625077], Reward: -3.7792892026878917\n",
      "Action: [1.240329   0.26918453], Reward: -8.874569917409463\n",
      "Action: [-1.6453264  2.1262937], Reward: -4.153981301361369\n",
      "Action: [0.6087776  0.99399745], Reward: -10.128194264817717\n",
      "Action: [-0.9744887  2.5322506], Reward: -4.517490946406638\n",
      "Action: [ 2.4437895 -1.9383124], Reward: -8.94963175414428\n",
      "Action: [ 1.1455324 -0.2091506], Reward: -8.860254919787781\n",
      "Action: [ 0.7433296 -0.5833617], Reward: -11.511060964877494\n",
      "Action: [0.21184334 2.0380783 ], Reward: -7.101692555704658\n",
      "Action: [ 0.661539 -2.767406], Reward: -11.238657606742212\n"
     ]
    }
   ],
   "source": [
    "env = minari_dataset.recover_environment(eval_env = True, render_mode=\"human\")\n",
    "obs, _ = env.reset(seed=42)\n",
    "total_rew = 0\n",
    "for i in range(horizon):\n",
    "    action = actions[i].cpu().numpy()\n",
    "    obs, rew, terminated, truncated, info = env.step(action)\n",
    "    total_rew += rew\n",
    "    print(f\"Action: {action}, Reward: {rew}\")\n",
    "    env.render()\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "import pygame\n",
    "pygame.display.quit()\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea2174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
