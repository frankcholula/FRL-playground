{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ddddde2",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fc11682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x107b6f670>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# flow_matching\n",
    "from flow_matching.path.scheduler import CondOTScheduler\n",
    "from flow_matching.path import AffineProbPath\n",
    "from flow_matching.solver import Solver, ODESolver\n",
    "from flow_matching.utils import ModelWrapper\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "# minari dataset\n",
    "import minari\n",
    "\n",
    "# To avoide meshgrid warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='torch')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    print('Using gpu')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('Using cpu.')\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "faeabf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_stats(dataset):\n",
    "    loader = DataLoader(dataset, batch_size=256, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    all_obs, all_act = [], []\n",
    "    for batch in loader:\n",
    "        for i in range(batch['observations'].shape[0]):\n",
    "            length = batch['episode_lengths'][i]\n",
    "            all_obs.append(batch['observations'][i, :length])\n",
    "            all_act.append(batch['actions'][i, :length])\n",
    "\n",
    "    flat_obs = torch.cat(all_obs, dim=0)\n",
    "    flat_act = torch.cat(all_act, dim=0)\n",
    "\n",
    "    stats = {\n",
    "        \"obs_mean\": torch.mean(flat_obs, dim=0),\n",
    "        \"obs_std\": torch.std(flat_obs, dim=0),\n",
    "        \"act_mean\": torch.mean(flat_act, dim=0),\n",
    "        \"act_std\": torch.std(flat_act, dim=0)\n",
    "    }\n",
    "    # Add a small epsilon to prevent division by zero\n",
    "    stats[\"obs_std\"][stats[\"obs_std\"] < 1e-6] = 1e-6\n",
    "    stats[\"act_std\"][stats[\"act_std\"] < 1e-6] = 1e-6\n",
    "    print(\"Statistics calculation complete.\")\n",
    "    return stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c681ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 10\n",
    "obs_dim = 8\n",
    "action_dim = 2\n",
    "dataset_name = \"LunarLanderContinuous-v3/ppo-1000-deterministic-v1\"\n",
    "def visualize_chunk(ax, chunk, color, x_limits=(-0.4, 0.4), y_limits=(-0.2, 1.5), mode='line'):\n",
    "    # make sure chunk is horizon x obs_dim\n",
    "    assert chunk.shape == (horizon , obs_dim,)\n",
    "    x = chunk[:, 0].cpu().numpy()\n",
    "    y = chunk[:, 1].cpu().numpy()\n",
    "    if mode == 'line':\n",
    "        ax.plot(x, y, linestyle='-', color=color, alpha=0.7)\n",
    "    elif mode == 'scatter':\n",
    "        ax.scatter(x, y, color=color, alpha=0.7)\n",
    "    ax.set_xlim(*x_limits)\n",
    "    ax.set_ylim(*y_limits)\n",
    "    ax.grid(True)\n",
    "\n",
    "def visualize_dataset(dataset):\n",
    "    episode_lengths = []\n",
    "    aggregated_rewards = []\n",
    "\n",
    "    for eps in dataset.episode_indices:\n",
    "        episode = dataset[eps]\n",
    "        episode_lengths.append(episode.observations.shape[0])    \n",
    "        aggregated_rewards.append(np.sum(episode.rewards))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(episode_lengths, bins=50, edgecolor='black')\n",
    "    plt.title('Distribution of Episode Lengths')\n",
    "    plt.xlabel('Episode Length')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(aggregated_rewards, bins=50, edgecolor='black')\n",
    "    plt.title('Distribution of Aggregated Rewards per Episode')\n",
    "    plt.xlabel('Aggregated Reward')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Total number of episodes: {len(episode_lengths)}\")\n",
    "    print(f\"Average episode length: {np.mean(episode_lengths):.2f}\")\n",
    "    print(f\"Min episode length: {np.min(episode_lengths)}\")\n",
    "    print(f\"Max episode length: {np.max(episode_lengths)}\")\n",
    "    print(f\"Average aggregated reward: {np.mean(aggregated_rewards):.2f}\")\n",
    "    print(f\"Min aggregated reward: {np.min(aggregated_rewards):.2f}\")\n",
    "    print(f\"Max aggregated reward: {np.max(aggregated_rewards):.2f}\")\n",
    "\n",
    "minari_dataset = minari.load_dataset(dataset_id=dataset_name)\n",
    "minari_dataset_stats = get_dataset_stats(minari_dataset)\n",
    "visualize_dataset(minari_dataset)\n",
    "minari_dataset_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef1b7e9",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7640966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return torch.sigmoid(x) * x\n",
    "\n",
    "\n",
    "# TODO: need to resolve temporal locality problem maybe with a CNN later.\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, time_dim: int = 1, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.time_dim = time_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim + time_dim, hidden_dim),\n",
    "            Swish(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            Swish(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            Swish(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            Swish(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor, t: Tensor) -> Tensor:\n",
    "        sz = x.size()\n",
    "        x = x.reshape(-1, self.input_dim)\n",
    "        t = t.reshape(-1, self.time_dim).float()\n",
    "\n",
    "        t = t.reshape(-1, 1).expand(x.shape[0], 1)\n",
    "        h = torch.cat([x, t], dim=1)\n",
    "        output = self.main(h)\n",
    "\n",
    "        return output.reshape(*sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b603c1",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Our dataset is made of 1000 episodes, with each episode containing a variable number of timsteps.\n",
    "This section is used to create chunks of trajectories with the specified horizon length.\n",
    "1. Normalization and Unnormalization: We need to normalize the chunks before training and unnormalize them after training to get the correct trajectories.\n",
    "2. The collate function is used to pad the sequence to the same length within a batch when we load it using a DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3416b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    observations = [torch.as_tensor(x.observations) for x in batch]\n",
    "    actions = [torch.as_tensor(x.actions) for x in batch]\n",
    "    rewards = [torch.as_tensor(x.rewards) for x in batch]\n",
    "    terminations = [torch.as_tensor(x.terminations) for x in batch]\n",
    "    truncations = [torch.as_tensor(x.truncations) for x in batch]\n",
    "    episode_lengths = torch.tensor([len(x.actions) for x in batch], dtype=torch.long)\n",
    "\n",
    "    return {\n",
    "        \"id\": torch.Tensor([x.id for x in batch]),\n",
    "        \"observations\": torch.nn.utils.rnn.pad_sequence(\n",
    "            observations,\n",
    "            batch_first=True\n",
    "        ),\n",
    "        \"actions\": torch.nn.utils.rnn.pad_sequence(\n",
    "            actions,\n",
    "            batch_first=True\n",
    "        ),\n",
    "        \"rewards\": torch.nn.utils.rnn.pad_sequence(\n",
    "            rewards,\n",
    "            batch_first=True\n",
    "        ),\n",
    "        \"terminations\": torch.nn.utils.rnn.pad_sequence(\n",
    "            terminations,\n",
    "            batch_first=True\n",
    "        ),\n",
    "        \"truncations\": torch.nn.utils.rnn.pad_sequence(\n",
    "            truncations,\n",
    "            batch_first=True\n",
    "        ),\n",
    "        \"episode_lengths\": episode_lengths\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f6286b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trajectory_chunks(batch, horizon):\n",
    "    \"\"\"\n",
    "    Processes a padded batch to create fixed-size trajectory chunks.\n",
    "    \"\"\"\n",
    "    batch_size = batch['observations'].shape[0]\n",
    "    all_chunks = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Get the data for one episode and its true length\n",
    "        obs = batch['observations'][i]      # Shape: (max_len, 8)\n",
    "        act = batch['actions'][i]          # Shape: (max_len-1, 2)\n",
    "        length = batch['episode_lengths'][i]       # Scalar, e.g., 495\n",
    "\n",
    "        # A single episode can produce multiple chunks\n",
    "        # We slide a window of size 'horizon' over the valid part of the episode\n",
    "        for start_idx in range(length - horizon + 1):\n",
    "            end_idx = start_idx + horizon\n",
    "\n",
    "            # Slice the observation and action sequences to get a chunk\n",
    "            obs_chunk = obs[start_idx:end_idx] # Shape: (horizon, 8)\n",
    "            act_chunk = act[start_idx:end_idx] # Shape: (horizon, 2)\n",
    "            \n",
    "            # Combine them into a single (horizon, 10) tensor\n",
    "            chunk = torch.cat([obs_chunk, act_chunk], dim=-1)\n",
    "\n",
    "            # Flatten the chunk to the final 1000-D vector and add to our list\n",
    "            all_chunks.append(chunk.flatten())\n",
    "\n",
    "    if not all_chunks:\n",
    "        return None\n",
    "\n",
    "    return torch.stack(all_chunks)\n",
    "\n",
    "def create_normalized_chunks(batch, horizon, stats):\n",
    "    obs_mean, obs_std = stats['obs_mean'], stats['obs_std']\n",
    "    act_mean, act_std = stats['act_mean'], stats['act_std']\n",
    "\n",
    "    all_chunks = []\n",
    "    for i in range(batch['observations'].shape[0]):\n",
    "        obs, act, length = batch['observations'][i], batch['actions'][i], batch['episode_lengths'][i]\n",
    "        \n",
    "        if length < horizon:\n",
    "            continue\n",
    "            \n",
    "        for start_idx in range(length - horizon + 1):\n",
    "            end_idx = start_idx + horizon\n",
    "            \n",
    "            obs_chunk = obs[start_idx:end_idx]\n",
    "            act_chunk = act[start_idx:end_idx]\n",
    "            \n",
    "            # apply normalization\n",
    "            norm_obs_chunk = (obs_chunk - obs_mean) / obs_std\n",
    "            norm_act_chunk = (act_chunk - act_mean) / act_std\n",
    "\n",
    "            chunk = torch.cat([norm_obs_chunk, norm_act_chunk], dim=-1)\n",
    "            all_chunks.append(chunk.flatten())\n",
    "\n",
    "    if not all_chunks:\n",
    "        return None\n",
    "    return torch.stack(all_chunks)\n",
    "\n",
    "\n",
    "def unnormalize_trajectory(norm_trajectory_chunk, stats, horizon, obs_dim, action_dim):\n",
    "    obs_mean, obs_std = stats['obs_mean'], stats['obs_std']\n",
    "    act_mean, act_std = stats['act_mean'], stats['act_std']\n",
    "    \n",
    "    # Reshape to (horizon, obs_dim + action_dim)\n",
    "    reshaped_chunk = norm_trajectory_chunk.reshape(horizon, obs_dim + action_dim)\n",
    "    \n",
    "    norm_obs = reshaped_chunk[:, :obs_dim]\n",
    "    norm_act = reshaped_chunk[:, obs_dim:]\n",
    "    \n",
    "    # Apply the reverse transformation: (data * std) + mean\n",
    "    unnorm_obs = (norm_obs * obs_std) + obs_mean\n",
    "    unnorm_act = (norm_act * act_std) + act_mean\n",
    "    \n",
    "    return unnorm_obs, unnorm_act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d762065",
   "metadata": {},
   "source": [
    "## Trajectory Visualization from Expert Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b02a7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing with normalized chunks...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataloader = DataLoader(minari_dataset, batch_size=256, shuffle=True, collate_fn=collate_fn)\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.set_title(f'Trajectories with Horizon {horizon} from expert dataset')\n",
    "print(\"Visualizing with normalized chunks...\")\n",
    "for batch in dataloader:\n",
    "    # processed_chunks = create_trajectory_chunks(batch, 100)\n",
    "    processed_chunks = create_normalized_chunks(batch, horizon, minari_dataset_stats)\n",
    "    random_chunk = random.choice(processed_chunks)\n",
    "    assert random_chunk.shape == (horizon * (obs_dim + action_dim),)\n",
    "    random_chunk = random_chunk.reshape(horizon, obs_dim + action_dim)\n",
    "    expert_obs = random_chunk[:, :obs_dim]\n",
    "    visualize_chunk(ax, expert_obs, color=\"green\", mode=\"line\", x_limits=(-2, 2), y_limits=(-2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778c9b8",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325af361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_epoch_loss</td><td>█▆▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_epoch_loss</td><td>1.16647</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-bee-81</strong> at: <a href='https://wandb.ai/frankcholula/FRL/runs/mf48nf3z' target=\"_blank\">https://wandb.ai/frankcholula/FRL/runs/mf48nf3z</a><br> View project at: <a href='https://wandb.ai/frankcholula/FRL' target=\"_blank\">https://wandb.ai/frankcholula/FRL</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250718_184235-mf48nf3z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/frankcholula/Workspace/school/FRL-playground/wandb/run-20250718_185412-7xsiwixi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/frankcholula/FRL/runs/7xsiwixi' target=\"_blank\">devoted-lake-82</a></strong> to <a href='https://wandb.ai/frankcholula/FRL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/frankcholula/FRL' target=\"_blank\">https://wandb.ai/frankcholula/FRL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/frankcholula/FRL/runs/7xsiwixi' target=\"_blank\">https://wandb.ai/frankcholula/FRL/runs/7xsiwixi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "| Epoch     10 | 4.17 s/epoch | Loss  1.53261 \n",
      "| Epoch     20 | 3.99 s/epoch | Loss  1.42133 \n",
      "| Epoch     30 | 4.23 s/epoch | Loss  1.16972 \n",
      "| Epoch     40 | 4.07 s/epoch | Loss  0.92176 \n",
      "| Epoch     50 | 4.07 s/epoch | Loss  0.78271 \n",
      "| Epoch     60 | 4.37 s/epoch | Loss  0.72057 \n",
      "| Epoch     70 | 3.95 s/epoch | Loss  0.69422 \n",
      "| Epoch     80 | 3.94 s/epoch | Loss  0.67542 \n",
      "| Epoch     90 | 3.93 s/epoch | Loss  0.65958 \n",
      "| Epoch    100 | 3.90 s/epoch | Loss  0.64222 \n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "from src.utils.loggers import WandBLogger\n",
    "env = minari_dataset.recover_environment()\n",
    "horizon = 10\n",
    "action_dim = env.action_space.shape[0]\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "input_dim = (obs_dim + action_dim) * horizon\n",
    "\n",
    "# Training params\n",
    "lr = 0.001\n",
    "num_epochs = 100\n",
    "print_every = 10\n",
    "hidden_dim = 256\n",
    "\n",
    "config = {\n",
    "    \"horizon\": horizon,\n",
    "    \"action_dim\": action_dim,\n",
    "    \"obs_dim\": obs_dim,\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "logger = WandBLogger(config = config)\n",
    "vf = MLP(input_dim=input_dim, time_dim=1, hidden_dim=hidden_dim).to(device)\n",
    "path = AffineProbPath(scheduler=CondOTScheduler())\n",
    "optim = torch.optim.Adam(vf.parameters(), lr=lr)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    total_epoch_loss = 0.0\n",
    "    total_chunks = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch in dataloader:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # x_1 = create_trajectory_chunks(batch, horizon)\n",
    "        x_1 = create_normalized_chunks(batch, horizon, minari_dataset_stats)\n",
    "        if x_1 is None:\n",
    "            continue\n",
    "        x_1 = x_1.to(device)\n",
    "        x_0 = torch.randn_like(x_1).to(device)\n",
    "        t = torch.rand(x_1.shape[0]).to(device)\n",
    "\n",
    "        # 3. Forward pass and Loss\n",
    "        path_sample = path.sample(t=t, x_0=x_0, x_1=x_1)\n",
    "        predicted_velocity = vf(path_sample.x_t, path_sample.t)\n",
    "        loss = torch.pow(predicted_velocity - path_sample.dx_t, 2).mean()\n",
    "\n",
    "        # 4. Backward pass and Optimize\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_epoch_loss += loss.item()\n",
    "        total_chunks += 1\n",
    "\n",
    "    avg_epoch_loss = total_epoch_loss / total_chunks if total_chunks > 0 else 0\n",
    "    logger.log({\"avg_epoch_loss\": avg_epoch_loss})\n",
    "    if (epoch + 1) % print_every == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"| Epoch {epoch+1:6d} | {elapsed:.2f} s/epoch | Loss {avg_epoch_loss:8.5f} \")\n",
    "        start_time = time.time()\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b34de",
   "metadata": {},
   "source": [
    "# Overfitting Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "811e64b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>████▇▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▂▁▂▁▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.47464</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">firm-eon-98</strong> at: <a href='https://wandb.ai/frankcholula/FRL/runs/e23zsgzy' target=\"_blank\">https://wandb.ai/frankcholula/FRL/runs/e23zsgzy</a><br> View project at: <a href='https://wandb.ai/frankcholula/FRL' target=\"_blank\">https://wandb.ai/frankcholula/FRL</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250718_200837-e23zsgzy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/frankcholula/Workspace/school/FRL-playground/wandb/run-20250718_201243-g7l5liqz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/frankcholula/FRL/runs/g7l5liqz' target=\"_blank\">flowing-planet-99</a></strong> to <a href='https://wandb.ai/frankcholula/FRL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/frankcholula/FRL' target=\"_blank\">https://wandb.ai/frankcholula/FRL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/frankcholula/FRL/runs/g7l5liqz' target=\"_blank\">https://wandb.ai/frankcholula/FRL/runs/g7l5liqz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfitting to a single chunk...\n",
      "Iteration    100: Avg Loss =  2.49297\n",
      "Iteration    200: Avg Loss =  1.42179\n",
      "Iteration    300: Avg Loss =  1.19187\n",
      "Iteration    400: Avg Loss =  1.12259\n",
      "Iteration    500: Avg Loss =  1.07674\n",
      "Iteration    600: Avg Loss =  0.99779\n",
      "Iteration    700: Avg Loss =  1.04858\n",
      "Iteration    800: Avg Loss =  1.03489\n",
      "Iteration    900: Avg Loss =  1.02929\n",
      "Iteration   1000: Avg Loss =  1.05062\n",
      "Iteration   1100: Avg Loss =  1.06307\n",
      "Iteration   1200: Avg Loss =  0.99657\n",
      "Iteration   1300: Avg Loss =  1.02206\n",
      "Iteration   1400: Avg Loss =  1.01728\n",
      "Iteration   1500: Avg Loss =  1.03604\n",
      "Iteration   1600: Avg Loss =  0.99238\n",
      "Iteration   1700: Avg Loss =  1.03139\n",
      "Iteration   1800: Avg Loss =  1.02728\n",
      "Iteration   1900: Avg Loss =  1.02039\n",
      "Iteration   2000: Avg Loss =  1.01020\n",
      "Iteration   2100: Avg Loss =  1.02218\n",
      "Iteration   2200: Avg Loss =  1.00735\n",
      "Iteration   2300: Avg Loss =  0.98548\n",
      "Iteration   2400: Avg Loss =  1.00875\n",
      "Iteration   2500: Avg Loss =  1.02233\n",
      "Iteration   2600: Avg Loss =  0.98743\n",
      "Iteration   2700: Avg Loss =  1.00864\n",
      "Iteration   2800: Avg Loss =  1.01247\n",
      "Iteration   2900: Avg Loss =  1.00534\n",
      "Iteration   3000: Avg Loss =  1.00996\n",
      "Iteration   3100: Avg Loss =  0.98985\n",
      "Iteration   3200: Avg Loss =  1.00912\n",
      "Iteration   3300: Avg Loss =  1.02075\n",
      "Iteration   3400: Avg Loss =  1.01111\n",
      "Iteration   3500: Avg Loss =  1.00388\n",
      "Iteration   3600: Avg Loss =  0.99624\n",
      "Iteration   3700: Avg Loss =  1.00756\n",
      "Iteration   3800: Avg Loss =  1.01134\n",
      "Iteration   3900: Avg Loss =  1.01674\n",
      "Iteration   4000: Avg Loss =  1.01667\n",
      "Iteration   4100: Avg Loss =  1.02334\n",
      "Iteration   4200: Avg Loss =  1.01103\n",
      "Iteration   4300: Avg Loss =  0.97785\n",
      "Iteration   4400: Avg Loss =  1.03453\n",
      "Iteration   4500: Avg Loss =  0.99504\n",
      "Iteration   4600: Avg Loss =  1.01570\n",
      "Iteration   4700: Avg Loss =  0.99075\n",
      "Iteration   4800: Avg Loss =  0.97561\n",
      "Iteration   4900: Avg Loss =  1.01753\n",
      "Iteration   5000: Avg Loss =  1.00985\n",
      "Iteration   5100: Avg Loss =  1.00736\n",
      "Iteration   5200: Avg Loss =  0.99841\n",
      "Iteration   5300: Avg Loss =  1.02549\n",
      "Iteration   5400: Avg Loss =  0.98934\n",
      "Iteration   5500: Avg Loss =  1.00928\n",
      "Iteration   5600: Avg Loss =  0.99617\n",
      "Iteration   5700: Avg Loss =  1.02047\n",
      "Iteration   5800: Avg Loss =  0.99622\n",
      "Iteration   5900: Avg Loss =  1.02112\n",
      "Iteration   6000: Avg Loss =  1.00045\n",
      "Iteration   6100: Avg Loss =  0.98188\n",
      "Iteration   6200: Avg Loss =  1.03503\n",
      "Iteration   6300: Avg Loss =  1.01665\n",
      "Iteration   6400: Avg Loss =  0.98279\n",
      "Iteration   6500: Avg Loss =  0.97244\n",
      "Iteration   6600: Avg Loss =  0.97969\n",
      "Iteration   6700: Avg Loss =  0.99468\n",
      "Iteration   6800: Avg Loss =  0.99110\n",
      "Iteration   6900: Avg Loss =  0.99257\n",
      "Iteration   7000: Avg Loss =  1.00735\n",
      "Iteration   7100: Avg Loss =  1.01333\n",
      "Iteration   7200: Avg Loss =  0.97228\n",
      "Iteration   7300: Avg Loss =  1.00056\n",
      "Iteration   7400: Avg Loss =  1.00816\n",
      "Iteration   7500: Avg Loss =  0.98573\n",
      "Iteration   7600: Avg Loss =  0.98875\n",
      "Iteration   7700: Avg Loss =  0.97164\n",
      "Iteration   7800: Avg Loss =  0.98959\n",
      "Iteration   7900: Avg Loss =  1.01514\n",
      "Iteration   8000: Avg Loss =  0.97235\n",
      "Iteration   8100: Avg Loss =  1.01152\n",
      "Iteration   8200: Avg Loss =  0.99107\n",
      "Iteration   8300: Avg Loss =  0.98100\n",
      "Iteration   8400: Avg Loss =  1.00020\n",
      "Iteration   8500: Avg Loss =  0.98010\n",
      "Iteration   8600: Avg Loss =  0.97922\n",
      "Iteration   8700: Avg Loss =  0.94709\n",
      "Iteration   8800: Avg Loss =  0.96888\n",
      "Iteration   8900: Avg Loss =  0.96997\n",
      "Iteration   9000: Avg Loss =  0.94837\n",
      "Iteration   9100: Avg Loss =  0.94321\n",
      "Iteration   9200: Avg Loss =  0.94758\n",
      "Iteration   9300: Avg Loss =  0.93712\n",
      "Iteration   9400: Avg Loss =  0.94951\n",
      "Iteration   9500: Avg Loss =  0.95054\n",
      "Iteration   9600: Avg Loss =  0.91822\n",
      "Iteration   9700: Avg Loss =  0.92168\n",
      "Iteration   9800: Avg Loss =  0.90847\n",
      "Iteration   9900: Avg Loss =  0.92937\n",
      "Iteration  10000: Avg Loss =  0.93414\n",
      "Iteration  10100: Avg Loss =  0.92695\n",
      "Iteration  10200: Avg Loss =  0.91862\n",
      "Iteration  10300: Avg Loss =  0.90419\n",
      "Iteration  10400: Avg Loss =  0.90369\n",
      "Iteration  10500: Avg Loss =  0.90568\n",
      "Iteration  10600: Avg Loss =  0.90408\n",
      "Iteration  10700: Avg Loss =  0.91415\n",
      "Iteration  10800: Avg Loss =  0.90467\n",
      "Iteration  10900: Avg Loss =  0.90011\n",
      "Iteration  11000: Avg Loss =  0.89223\n",
      "Iteration  11100: Avg Loss =  0.89055\n",
      "Iteration  11200: Avg Loss =  0.91321\n",
      "Iteration  11300: Avg Loss =  0.89524\n",
      "Iteration  11400: Avg Loss =  0.87996\n",
      "Iteration  11500: Avg Loss =  0.89216\n",
      "Iteration  11600: Avg Loss =  0.90696\n",
      "Iteration  11700: Avg Loss =  0.88698\n",
      "Iteration  11800: Avg Loss =  0.89626\n",
      "Iteration  11900: Avg Loss =  0.88641\n",
      "Iteration  12000: Avg Loss =  0.87373\n",
      "Iteration  12100: Avg Loss =  0.87561\n",
      "Iteration  12200: Avg Loss =  0.86069\n",
      "Iteration  12300: Avg Loss =  0.89280\n",
      "Iteration  12400: Avg Loss =  0.86918\n",
      "Iteration  12500: Avg Loss =  0.84439\n",
      "Iteration  12600: Avg Loss =  0.85553\n",
      "Iteration  12700: Avg Loss =  0.86843\n",
      "Iteration  12800: Avg Loss =  0.86945\n",
      "Iteration  12900: Avg Loss =  0.86530\n",
      "Iteration  13000: Avg Loss =  0.83364\n",
      "Iteration  13100: Avg Loss =  0.88733\n",
      "Iteration  13200: Avg Loss =  0.83113\n",
      "Iteration  13300: Avg Loss =  0.86855\n",
      "Iteration  13400: Avg Loss =  0.84899\n",
      "Iteration  13500: Avg Loss =  0.85883\n",
      "Iteration  13600: Avg Loss =  0.81323\n",
      "Iteration  13700: Avg Loss =  0.82065\n",
      "Iteration  13800: Avg Loss =  0.83767\n",
      "Iteration  13900: Avg Loss =  0.84205\n",
      "Iteration  14000: Avg Loss =  0.86333\n",
      "Iteration  14100: Avg Loss =  0.83738\n",
      "Iteration  14200: Avg Loss =  0.82356\n",
      "Iteration  14300: Avg Loss =  0.83380\n",
      "Iteration  14400: Avg Loss =  0.83005\n",
      "Iteration  14500: Avg Loss =  0.82498\n",
      "Iteration  14600: Avg Loss =  0.83890\n",
      "Iteration  14700: Avg Loss =  0.83933\n",
      "Iteration  14800: Avg Loss =  0.81003\n",
      "Iteration  14900: Avg Loss =  0.81743\n",
      "Iteration  15000: Avg Loss =  0.81536\n",
      "Iteration  15100: Avg Loss =  0.81703\n",
      "Iteration  15200: Avg Loss =  0.83124\n",
      "Iteration  15300: Avg Loss =  0.81964\n",
      "Iteration  15400: Avg Loss =  0.79531\n",
      "Iteration  15500: Avg Loss =  0.83410\n",
      "Iteration  15600: Avg Loss =  0.81469\n",
      "Iteration  15700: Avg Loss =  0.81085\n",
      "Iteration  15800: Avg Loss =  0.81153\n",
      "Iteration  15900: Avg Loss =  0.78280\n",
      "Iteration  16000: Avg Loss =  0.82429\n",
      "Iteration  16100: Avg Loss =  0.79140\n",
      "Iteration  16200: Avg Loss =  0.78581\n",
      "Iteration  16300: Avg Loss =  0.79578\n",
      "Iteration  16400: Avg Loss =  0.78517\n",
      "Iteration  16500: Avg Loss =  0.82326\n",
      "Iteration  16600: Avg Loss =  0.77356\n",
      "Iteration  16700: Avg Loss =  0.81538\n",
      "Iteration  16800: Avg Loss =  0.77986\n",
      "Iteration  16900: Avg Loss =  0.77291\n",
      "Iteration  17000: Avg Loss =  0.79089\n",
      "Iteration  17100: Avg Loss =  0.75626\n",
      "Iteration  17200: Avg Loss =  0.75693\n",
      "Iteration  17300: Avg Loss =  0.80000\n",
      "Iteration  17400: Avg Loss =  0.76934\n",
      "Iteration  17500: Avg Loss =  0.76025\n",
      "Iteration  17600: Avg Loss =  0.80702\n",
      "Iteration  17700: Avg Loss =  0.79821\n",
      "Iteration  17800: Avg Loss =  0.75966\n",
      "Iteration  17900: Avg Loss =  0.76791\n",
      "Iteration  18000: Avg Loss =  0.75876\n",
      "Iteration  18100: Avg Loss =  0.75053\n",
      "Iteration  18200: Avg Loss =  0.76487\n",
      "Iteration  18300: Avg Loss =  0.75325\n",
      "Iteration  18400: Avg Loss =  0.74782\n",
      "Iteration  18500: Avg Loss =  0.76718\n",
      "Iteration  18600: Avg Loss =  0.76628\n",
      "Iteration  18700: Avg Loss =  0.78454\n",
      "Iteration  18800: Avg Loss =  0.75961\n",
      "Iteration  18900: Avg Loss =  0.76780\n",
      "Iteration  19000: Avg Loss =  0.74266\n",
      "Iteration  19100: Avg Loss =  0.72654\n",
      "Iteration  19200: Avg Loss =  0.75093\n",
      "Iteration  19300: Avg Loss =  0.75129\n",
      "Iteration  19400: Avg Loss =  0.74191\n",
      "Iteration  19500: Avg Loss =  0.77991\n",
      "Iteration  19600: Avg Loss =  0.73551\n",
      "Iteration  19700: Avg Loss =  0.73046\n",
      "Iteration  19800: Avg Loss =  0.73967\n",
      "Iteration  19900: Avg Loss =  0.74295\n",
      "Iteration  20000: Avg Loss =  0.73556\n",
      "Iteration  20100: Avg Loss =  0.73117\n",
      "Iteration  20200: Avg Loss =  0.74671\n",
      "Iteration  20300: Avg Loss =  0.72381\n",
      "Iteration  20400: Avg Loss =  0.72793\n",
      "Iteration  20500: Avg Loss =  0.73674\n",
      "Iteration  20600: Avg Loss =  0.72666\n",
      "Iteration  20700: Avg Loss =  0.77820\n",
      "Iteration  20800: Avg Loss =  0.72282\n",
      "Iteration  20900: Avg Loss =  0.70181\n",
      "Iteration  21000: Avg Loss =  0.70232\n",
      "Iteration  21100: Avg Loss =  0.70905\n",
      "Iteration  21200: Avg Loss =  0.73985\n",
      "Iteration  21300: Avg Loss =  0.70871\n",
      "Iteration  21400: Avg Loss =  0.73149\n",
      "Iteration  21500: Avg Loss =  0.73245\n",
      "Iteration  21600: Avg Loss =  0.71949\n",
      "Iteration  21700: Avg Loss =  0.74124\n",
      "Iteration  21800: Avg Loss =  0.73171\n",
      "Iteration  21900: Avg Loss =  0.73333\n",
      "Iteration  22000: Avg Loss =  0.72946\n",
      "Iteration  22100: Avg Loss =  0.69589\n",
      "Iteration  22200: Avg Loss =  0.69835\n",
      "Iteration  22300: Avg Loss =  0.70737\n",
      "Iteration  22400: Avg Loss =  0.70132\n",
      "Iteration  22500: Avg Loss =  0.70684\n",
      "Iteration  22600: Avg Loss =  0.69668\n",
      "Iteration  22700: Avg Loss =  0.74458\n",
      "Iteration  22800: Avg Loss =  0.72665\n",
      "Iteration  22900: Avg Loss =  0.70639\n",
      "Iteration  23000: Avg Loss =  0.71310\n",
      "Iteration  23100: Avg Loss =  0.69669\n",
      "Iteration  23200: Avg Loss =  0.70063\n",
      "Iteration  23300: Avg Loss =  0.69605\n",
      "Iteration  23400: Avg Loss =  0.72564\n",
      "Iteration  23500: Avg Loss =  0.69450\n",
      "Iteration  23600: Avg Loss =  0.66677\n",
      "Iteration  23700: Avg Loss =  0.70333\n",
      "Iteration  23800: Avg Loss =  0.69937\n",
      "Iteration  23900: Avg Loss =  0.66719\n",
      "Iteration  24000: Avg Loss =  0.69445\n",
      "Iteration  24100: Avg Loss =  0.67253\n",
      "Iteration  24200: Avg Loss =  0.69619\n",
      "Iteration  24300: Avg Loss =  0.68846\n",
      "Iteration  24400: Avg Loss =  0.67981\n",
      "Iteration  24500: Avg Loss =  0.68616\n",
      "Iteration  24600: Avg Loss =  0.70337\n",
      "Iteration  24700: Avg Loss =  0.67657\n",
      "Iteration  24800: Avg Loss =  0.66195\n",
      "Iteration  24900: Avg Loss =  0.68897\n",
      "Iteration  25000: Avg Loss =  0.69302\n",
      "Iteration  25100: Avg Loss =  0.66608\n",
      "Iteration  25200: Avg Loss =  0.67157\n",
      "Iteration  25300: Avg Loss =  0.69864\n",
      "Iteration  25400: Avg Loss =  0.67336\n",
      "Iteration  25500: Avg Loss =  0.70773\n",
      "Iteration  25600: Avg Loss =  0.66889\n",
      "Iteration  25700: Avg Loss =  0.68032\n",
      "Iteration  25800: Avg Loss =  0.72252\n",
      "Iteration  25900: Avg Loss =  0.65096\n",
      "Iteration  26000: Avg Loss =  0.66086\n",
      "Iteration  26100: Avg Loss =  0.65834\n",
      "Iteration  26200: Avg Loss =  0.68921\n",
      "Iteration  26300: Avg Loss =  0.66833\n",
      "Iteration  26400: Avg Loss =  0.68510\n",
      "Iteration  26500: Avg Loss =  0.66284\n",
      "Iteration  26600: Avg Loss =  0.65139\n",
      "Iteration  26700: Avg Loss =  0.69199\n",
      "Iteration  26800: Avg Loss =  0.68030\n",
      "Iteration  26900: Avg Loss =  0.70817\n",
      "Iteration  27000: Avg Loss =  0.64261\n",
      "Iteration  27100: Avg Loss =  0.67036\n",
      "Iteration  27200: Avg Loss =  0.65986\n",
      "Iteration  27300: Avg Loss =  0.65409\n",
      "Iteration  27400: Avg Loss =  0.69029\n",
      "Iteration  27500: Avg Loss =  0.65713\n",
      "Iteration  27600: Avg Loss =  0.66266\n",
      "Iteration  27700: Avg Loss =  0.65687\n",
      "Iteration  27800: Avg Loss =  0.66513\n",
      "Iteration  27900: Avg Loss =  0.66397\n",
      "Iteration  28000: Avg Loss =  0.64066\n",
      "Iteration  28100: Avg Loss =  0.63741\n",
      "Iteration  28200: Avg Loss =  0.67279\n",
      "Iteration  28300: Avg Loss =  0.64206\n",
      "Iteration  28400: Avg Loss =  0.64286\n",
      "Iteration  28500: Avg Loss =  0.64766\n",
      "Iteration  28600: Avg Loss =  0.66377\n",
      "Iteration  28700: Avg Loss =  0.67419\n",
      "Iteration  28800: Avg Loss =  0.65599\n",
      "Iteration  28900: Avg Loss =  0.65130\n",
      "Iteration  29000: Avg Loss =  0.65534\n",
      "Iteration  29100: Avg Loss =  0.63647\n",
      "Iteration  29200: Avg Loss =  0.65338\n",
      "Iteration  29300: Avg Loss =  0.63638\n",
      "Iteration  29400: Avg Loss =  0.64198\n",
      "Iteration  29500: Avg Loss =  0.63868\n",
      "Iteration  29600: Avg Loss =  0.64362\n",
      "Iteration  29700: Avg Loss =  0.65248\n",
      "Iteration  29800: Avg Loss =  0.68750\n",
      "Iteration  29900: Avg Loss =  0.67242\n",
      "Iteration  30000: Avg Loss =  0.66973\n",
      "Iteration  30100: Avg Loss =  0.67696\n",
      "Iteration  30200: Avg Loss =  0.64372\n",
      "Iteration  30300: Avg Loss =  0.66829\n",
      "Iteration  30400: Avg Loss =  0.63593\n",
      "Iteration  30500: Avg Loss =  0.65789\n",
      "Iteration  30600: Avg Loss =  0.61807\n",
      "Iteration  30700: Avg Loss =  0.66770\n",
      "Iteration  30800: Avg Loss =  0.63490\n",
      "Iteration  30900: Avg Loss =  0.63662\n",
      "Iteration  31000: Avg Loss =  0.65794\n",
      "Iteration  31100: Avg Loss =  0.65347\n",
      "Iteration  31200: Avg Loss =  0.61969\n",
      "Iteration  31300: Avg Loss =  0.64161\n",
      "Iteration  31400: Avg Loss =  0.63653\n",
      "Iteration  31500: Avg Loss =  0.63457\n",
      "Iteration  31600: Avg Loss =  0.62714\n",
      "Iteration  31700: Avg Loss =  0.63456\n",
      "Iteration  31800: Avg Loss =  0.60764\n",
      "Iteration  31900: Avg Loss =  0.61911\n",
      "Iteration  32000: Avg Loss =  0.62220\n",
      "Iteration  32100: Avg Loss =  0.62906\n",
      "Iteration  32200: Avg Loss =  0.64811\n",
      "Iteration  32300: Avg Loss =  0.61590\n",
      "Iteration  32400: Avg Loss =  0.62751\n",
      "Iteration  32500: Avg Loss =  0.60320\n",
      "Iteration  32600: Avg Loss =  0.61966\n",
      "Iteration  32700: Avg Loss =  0.65098\n",
      "Iteration  32800: Avg Loss =  0.61647\n",
      "Iteration  32900: Avg Loss =  0.63100\n",
      "Iteration  33000: Avg Loss =  0.63330\n",
      "Iteration  33100: Avg Loss =  0.62433\n",
      "Iteration  33200: Avg Loss =  0.65897\n",
      "Iteration  33300: Avg Loss =  0.62894\n",
      "Iteration  33400: Avg Loss =  0.62688\n",
      "Iteration  33500: Avg Loss =  0.62227\n",
      "Iteration  33600: Avg Loss =  0.61734\n",
      "Iteration  33700: Avg Loss =  0.63224\n",
      "Iteration  33800: Avg Loss =  0.62004\n",
      "Iteration  33900: Avg Loss =  0.61640\n",
      "Iteration  34000: Avg Loss =  0.62298\n",
      "Iteration  34100: Avg Loss =  0.63654\n",
      "Iteration  34200: Avg Loss =  0.61440\n",
      "Iteration  34300: Avg Loss =  0.59089\n",
      "Iteration  34400: Avg Loss =  0.63851\n",
      "Iteration  34500: Avg Loss =  0.61657\n",
      "Iteration  34600: Avg Loss =  0.62560\n",
      "Iteration  34700: Avg Loss =  0.61537\n",
      "Iteration  34800: Avg Loss =  0.60166\n",
      "Iteration  34900: Avg Loss =  0.59618\n",
      "Iteration  35000: Avg Loss =  0.61881\n",
      "Iteration  35100: Avg Loss =  0.63605\n",
      "Iteration  35200: Avg Loss =  0.60585\n",
      "Iteration  35300: Avg Loss =  0.63313\n",
      "Iteration  35400: Avg Loss =  0.61939\n",
      "Iteration  35500: Avg Loss =  0.64000\n",
      "Iteration  35600: Avg Loss =  0.59367\n",
      "Iteration  35700: Avg Loss =  0.59904\n",
      "Iteration  35800: Avg Loss =  0.61988\n",
      "Iteration  35900: Avg Loss =  0.60331\n",
      "Iteration  36000: Avg Loss =  0.64531\n",
      "Iteration  36100: Avg Loss =  0.59218\n",
      "Iteration  36200: Avg Loss =  0.59194\n",
      "Iteration  36300: Avg Loss =  0.58802\n",
      "Iteration  36400: Avg Loss =  0.60084\n",
      "Iteration  36500: Avg Loss =  0.58071\n",
      "Iteration  36600: Avg Loss =  0.61307\n",
      "Iteration  36700: Avg Loss =  0.61434\n",
      "Iteration  36800: Avg Loss =  0.62513\n",
      "Iteration  36900: Avg Loss =  0.58322\n",
      "Iteration  37000: Avg Loss =  0.60055\n",
      "Iteration  37100: Avg Loss =  0.61539\n",
      "Iteration  37200: Avg Loss =  0.60965\n",
      "Iteration  37300: Avg Loss =  0.60241\n",
      "Iteration  37400: Avg Loss =  0.56391\n",
      "Iteration  37500: Avg Loss =  0.59661\n",
      "Iteration  37600: Avg Loss =  0.58541\n",
      "Iteration  37700: Avg Loss =  0.59643\n",
      "Iteration  37800: Avg Loss =  0.57614\n",
      "Iteration  37900: Avg Loss =  0.60593\n",
      "Iteration  38000: Avg Loss =  0.59954\n",
      "Iteration  38100: Avg Loss =  0.56287\n",
      "Iteration  38200: Avg Loss =  0.60550\n",
      "Iteration  38300: Avg Loss =  0.59508\n",
      "Iteration  38400: Avg Loss =  0.56760\n",
      "Iteration  38500: Avg Loss =  0.56631\n",
      "Iteration  38600: Avg Loss =  0.59600\n",
      "Iteration  38700: Avg Loss =  0.59176\n",
      "Iteration  38800: Avg Loss =  0.58806\n",
      "Iteration  38900: Avg Loss =  0.61735\n",
      "Iteration  39000: Avg Loss =  0.58296\n",
      "Iteration  39100: Avg Loss =  0.56930\n",
      "Iteration  39200: Avg Loss =  0.59493\n",
      "Iteration  39300: Avg Loss =  0.56921\n",
      "Iteration  39400: Avg Loss =  0.59981\n",
      "Iteration  39500: Avg Loss =  0.59206\n",
      "Iteration  39600: Avg Loss =  0.60862\n",
      "Iteration  39700: Avg Loss =  0.55399\n",
      "Iteration  39800: Avg Loss =  0.60466\n",
      "Iteration  39900: Avg Loss =  0.59335\n",
      "Iteration  40000: Avg Loss =  0.60031\n",
      "Iteration  40100: Avg Loss =  0.58445\n",
      "Iteration  40200: Avg Loss =  0.60461\n",
      "Iteration  40300: Avg Loss =  0.58649\n",
      "Iteration  40400: Avg Loss =  0.56372\n",
      "Iteration  40500: Avg Loss =  0.57695\n",
      "Iteration  40600: Avg Loss =  0.56535\n",
      "Iteration  40700: Avg Loss =  0.60585\n",
      "Iteration  40800: Avg Loss =  0.55577\n",
      "Iteration  40900: Avg Loss =  0.58681\n",
      "Iteration  41000: Avg Loss =  0.59210\n",
      "Iteration  41100: Avg Loss =  0.58798\n",
      "Iteration  41200: Avg Loss =  0.58775\n",
      "Iteration  41300: Avg Loss =  0.58393\n",
      "Iteration  41400: Avg Loss =  0.58712\n",
      "Iteration  41500: Avg Loss =  0.55455\n",
      "Iteration  41600: Avg Loss =  0.57242\n",
      "Iteration  41700: Avg Loss =  0.57276\n",
      "Iteration  41800: Avg Loss =  0.57345\n",
      "Iteration  41900: Avg Loss =  0.58404\n",
      "Iteration  42000: Avg Loss =  0.60498\n",
      "Iteration  42100: Avg Loss =  0.57697\n",
      "Iteration  42200: Avg Loss =  0.56691\n",
      "Iteration  42300: Avg Loss =  0.58170\n",
      "Iteration  42400: Avg Loss =  0.57399\n",
      "Iteration  42500: Avg Loss =  0.58264\n",
      "Iteration  42600: Avg Loss =  0.58635\n",
      "Iteration  42700: Avg Loss =  0.57029\n",
      "Iteration  42800: Avg Loss =  0.57716\n",
      "Iteration  42900: Avg Loss =  0.57345\n",
      "Iteration  43000: Avg Loss =  0.54832\n",
      "Iteration  43100: Avg Loss =  0.56880\n",
      "Iteration  43200: Avg Loss =  0.60860\n",
      "Iteration  43300: Avg Loss =  0.56315\n",
      "Iteration  43400: Avg Loss =  0.56767\n",
      "Iteration  43500: Avg Loss =  0.58667\n",
      "Iteration  43600: Avg Loss =  0.57268\n",
      "Iteration  43700: Avg Loss =  0.54748\n",
      "Iteration  43800: Avg Loss =  0.53933\n",
      "Iteration  43900: Avg Loss =  0.52716\n",
      "Iteration  44000: Avg Loss =  0.56710\n",
      "Iteration  44100: Avg Loss =  0.56910\n",
      "Iteration  44200: Avg Loss =  0.55150\n",
      "Iteration  44300: Avg Loss =  0.57342\n",
      "Iteration  44400: Avg Loss =  0.58713\n",
      "Iteration  44500: Avg Loss =  0.56399\n",
      "Iteration  44600: Avg Loss =  0.53946\n",
      "Iteration  44700: Avg Loss =  0.56802\n",
      "Iteration  44800: Avg Loss =  0.55719\n",
      "Iteration  44900: Avg Loss =  0.56583\n",
      "Iteration  45000: Avg Loss =  0.53979\n",
      "Iteration  45100: Avg Loss =  0.56166\n",
      "Iteration  45200: Avg Loss =  0.53479\n",
      "Iteration  45300: Avg Loss =  0.57150\n",
      "Iteration  45400: Avg Loss =  0.55234\n",
      "Iteration  45500: Avg Loss =  0.55423\n",
      "Iteration  45600: Avg Loss =  0.53814\n",
      "Iteration  45700: Avg Loss =  0.55080\n",
      "Iteration  45800: Avg Loss =  0.56756\n",
      "Iteration  45900: Avg Loss =  0.54507\n",
      "Iteration  46000: Avg Loss =  0.55051\n",
      "Iteration  46100: Avg Loss =  0.58237\n",
      "Iteration  46200: Avg Loss =  0.54518\n",
      "Iteration  46300: Avg Loss =  0.59731\n",
      "Iteration  46400: Avg Loss =  0.55565\n",
      "Iteration  46500: Avg Loss =  0.53679\n",
      "Iteration  46600: Avg Loss =  0.54296\n",
      "Iteration  46700: Avg Loss =  0.54714\n",
      "Iteration  46800: Avg Loss =  0.52590\n",
      "Iteration  46900: Avg Loss =  0.56292\n",
      "Iteration  47000: Avg Loss =  0.55424\n",
      "Iteration  47100: Avg Loss =  0.56277\n",
      "Iteration  47200: Avg Loss =  0.53907\n",
      "Iteration  47300: Avg Loss =  0.55371\n",
      "Iteration  47400: Avg Loss =  0.54850\n",
      "Iteration  47500: Avg Loss =  0.54660\n",
      "Iteration  47600: Avg Loss =  0.56884\n",
      "Iteration  47700: Avg Loss =  0.53923\n",
      "Iteration  47800: Avg Loss =  0.52659\n",
      "Iteration  47900: Avg Loss =  0.56307\n",
      "Iteration  48000: Avg Loss =  0.52414\n",
      "Iteration  48100: Avg Loss =  0.53698\n",
      "Iteration  48200: Avg Loss =  0.54801\n",
      "Iteration  48300: Avg Loss =  0.53824\n",
      "Iteration  48400: Avg Loss =  0.54986\n",
      "Iteration  48500: Avg Loss =  0.51591\n",
      "Iteration  48600: Avg Loss =  0.55667\n",
      "Iteration  48700: Avg Loss =  0.53532\n",
      "Iteration  48800: Avg Loss =  0.52143\n",
      "Iteration  48900: Avg Loss =  0.51457\n",
      "Iteration  49000: Avg Loss =  0.55539\n",
      "Iteration  49100: Avg Loss =  0.54295\n",
      "Iteration  49200: Avg Loss =  0.53441\n",
      "Iteration  49300: Avg Loss =  0.52380\n",
      "Iteration  49400: Avg Loss =  0.56452\n",
      "Iteration  49500: Avg Loss =  0.50856\n",
      "Iteration  49600: Avg Loss =  0.57147\n",
      "Iteration  49700: Avg Loss =  0.54806\n",
      "Iteration  49800: Avg Loss =  0.53333\n",
      "Iteration  49900: Avg Loss =  0.52403\n",
      "Iteration  50000: Avg Loss =  0.52812\n",
      "Iteration  50100: Avg Loss =  0.53376\n",
      "Iteration  50200: Avg Loss =  0.55303\n",
      "Iteration  50300: Avg Loss =  0.53404\n",
      "Iteration  50400: Avg Loss =  0.56132\n",
      "Iteration  50500: Avg Loss =  0.54854\n",
      "Iteration  50600: Avg Loss =  0.53771\n",
      "Iteration  50700: Avg Loss =  0.52946\n",
      "Iteration  50800: Avg Loss =  0.52131\n",
      "Iteration  50900: Avg Loss =  0.54157\n",
      "Iteration  51000: Avg Loss =  0.50976\n",
      "Iteration  51100: Avg Loss =  0.51883\n",
      "Iteration  51200: Avg Loss =  0.54418\n",
      "Iteration  51300: Avg Loss =  0.53428\n",
      "Iteration  51400: Avg Loss =  0.51167\n",
      "Iteration  51500: Avg Loss =  0.51551\n",
      "Iteration  51600: Avg Loss =  0.54586\n",
      "Iteration  51700: Avg Loss =  0.51377\n",
      "Iteration  51800: Avg Loss =  0.50103\n",
      "Iteration  51900: Avg Loss =  0.51409\n",
      "Iteration  52000: Avg Loss =  0.53593\n",
      "Iteration  52100: Avg Loss =  0.53017\n",
      "Iteration  52200: Avg Loss =  0.51907\n",
      "Iteration  52300: Avg Loss =  0.56657\n",
      "Iteration  52400: Avg Loss =  0.52802\n",
      "Iteration  52500: Avg Loss =  0.53173\n",
      "Iteration  52600: Avg Loss =  0.53432\n",
      "Iteration  52700: Avg Loss =  0.57914\n",
      "Iteration  52800: Avg Loss =  0.53338\n",
      "Iteration  52900: Avg Loss =  0.53248\n",
      "Iteration  53000: Avg Loss =  0.55351\n",
      "Iteration  53100: Avg Loss =  0.52196\n",
      "Iteration  53200: Avg Loss =  0.51591\n",
      "Iteration  53300: Avg Loss =  0.53177\n",
      "Iteration  53400: Avg Loss =  0.55021\n",
      "Iteration  53500: Avg Loss =  0.51471\n",
      "Iteration  53600: Avg Loss =  0.52163\n",
      "Iteration  53700: Avg Loss =  0.55013\n",
      "Iteration  53800: Avg Loss =  0.50827\n",
      "Iteration  53900: Avg Loss =  0.51731\n",
      "Iteration  54000: Avg Loss =  0.53004\n",
      "Iteration  54100: Avg Loss =  0.51989\n",
      "Iteration  54200: Avg Loss =  0.52562\n",
      "Iteration  54300: Avg Loss =  0.51662\n",
      "Iteration  54400: Avg Loss =  0.51687\n",
      "Iteration  54500: Avg Loss =  0.51704\n",
      "Iteration  54600: Avg Loss =  0.53384\n",
      "Iteration  54700: Avg Loss =  0.49700\n",
      "Iteration  54800: Avg Loss =  0.53659\n",
      "Iteration  54900: Avg Loss =  0.53179\n",
      "Iteration  55000: Avg Loss =  0.52525\n",
      "Iteration  55100: Avg Loss =  0.49276\n",
      "Iteration  55200: Avg Loss =  0.50630\n",
      "Iteration  55300: Avg Loss =  0.50544\n",
      "Iteration  55400: Avg Loss =  0.52399\n",
      "Iteration  55500: Avg Loss =  0.51542\n",
      "Iteration  55600: Avg Loss =  0.51670\n",
      "Iteration  55700: Avg Loss =  0.52159\n",
      "Iteration  55800: Avg Loss =  0.50770\n",
      "Iteration  55900: Avg Loss =  0.49665\n",
      "Iteration  56000: Avg Loss =  0.52256\n",
      "Iteration  56100: Avg Loss =  0.52347\n",
      "Iteration  56200: Avg Loss =  0.53038\n",
      "Iteration  56300: Avg Loss =  0.50612\n",
      "Iteration  56400: Avg Loss =  0.50749\n",
      "Iteration  56500: Avg Loss =  0.53416\n",
      "Iteration  56600: Avg Loss =  0.51995\n",
      "Iteration  56700: Avg Loss =  0.50361\n",
      "Iteration  56800: Avg Loss =  0.53250\n",
      "Iteration  56900: Avg Loss =  0.50900\n",
      "Iteration  57000: Avg Loss =  0.50135\n",
      "Iteration  57100: Avg Loss =  0.50851\n",
      "Iteration  57200: Avg Loss =  0.51819\n",
      "Iteration  57300: Avg Loss =  0.53758\n",
      "Iteration  57400: Avg Loss =  0.49857\n",
      "Iteration  57500: Avg Loss =  0.52743\n",
      "Iteration  57600: Avg Loss =  0.47016\n",
      "Iteration  57700: Avg Loss =  0.51605\n",
      "Iteration  57800: Avg Loss =  0.49100\n",
      "Iteration  57900: Avg Loss =  0.49514\n",
      "Iteration  58000: Avg Loss =  0.49069\n",
      "Iteration  58100: Avg Loss =  0.48881\n",
      "Iteration  58200: Avg Loss =  0.49300\n",
      "Iteration  58300: Avg Loss =  0.53062\n",
      "Iteration  58400: Avg Loss =  0.51178\n",
      "Iteration  58500: Avg Loss =  0.52404\n",
      "Iteration  58600: Avg Loss =  0.51861\n",
      "Iteration  58700: Avg Loss =  0.49974\n",
      "Iteration  58800: Avg Loss =  0.49609\n",
      "Iteration  58900: Avg Loss =  0.48158\n",
      "Iteration  59000: Avg Loss =  0.49586\n",
      "Iteration  59100: Avg Loss =  0.52478\n",
      "Iteration  59200: Avg Loss =  0.50056\n",
      "Iteration  59300: Avg Loss =  0.52681\n",
      "Iteration  59400: Avg Loss =  0.49191\n",
      "Iteration  59500: Avg Loss =  0.53096\n",
      "Iteration  59600: Avg Loss =  0.50928\n",
      "Iteration  59700: Avg Loss =  0.51444\n",
      "Iteration  59800: Avg Loss =  0.52939\n",
      "Iteration  59900: Avg Loss =  0.50252\n",
      "Iteration  60000: Avg Loss =  0.51603\n",
      "Iteration  60100: Avg Loss =  0.50919\n",
      "Iteration  60200: Avg Loss =  0.53221\n",
      "Iteration  60300: Avg Loss =  0.51531\n",
      "Iteration  60400: Avg Loss =  0.51040\n",
      "Iteration  60500: Avg Loss =  0.49331\n",
      "Iteration  60600: Avg Loss =  0.50690\n",
      "Iteration  60700: Avg Loss =  0.48737\n",
      "Iteration  60800: Avg Loss =  0.51590\n",
      "Iteration  60900: Avg Loss =  0.50556\n",
      "Iteration  61000: Avg Loss =  0.48839\n",
      "Iteration  61100: Avg Loss =  0.48850\n",
      "Iteration  61200: Avg Loss =  0.50038\n",
      "Iteration  61300: Avg Loss =  0.47672\n",
      "Iteration  61400: Avg Loss =  0.52238\n",
      "Iteration  61500: Avg Loss =  0.49132\n",
      "Iteration  61600: Avg Loss =  0.53270\n",
      "Iteration  61700: Avg Loss =  0.50980\n",
      "Iteration  61800: Avg Loss =  0.50050\n",
      "Iteration  61900: Avg Loss =  0.52375\n",
      "Iteration  62000: Avg Loss =  0.49565\n",
      "Iteration  62100: Avg Loss =  0.50993\n",
      "Iteration  62200: Avg Loss =  0.51629\n",
      "Iteration  62300: Avg Loss =  0.49547\n",
      "Iteration  62400: Avg Loss =  0.50022\n",
      "Iteration  62500: Avg Loss =  0.46551\n",
      "Iteration  62600: Avg Loss =  0.49480\n",
      "Iteration  62700: Avg Loss =  0.51741\n",
      "Iteration  62800: Avg Loss =  0.51683\n",
      "Iteration  62900: Avg Loss =  0.50937\n",
      "Iteration  63000: Avg Loss =  0.51568\n",
      "Iteration  63100: Avg Loss =  0.46251\n",
      "Iteration  63200: Avg Loss =  0.51937\n",
      "Iteration  63300: Avg Loss =  0.49116\n",
      "Iteration  63400: Avg Loss =  0.48742\n",
      "Iteration  63500: Avg Loss =  0.50223\n",
      "Iteration  63600: Avg Loss =  0.46949\n",
      "Iteration  63700: Avg Loss =  0.50139\n",
      "Iteration  63800: Avg Loss =  0.49721\n",
      "Iteration  63900: Avg Loss =  0.46537\n",
      "Iteration  64000: Avg Loss =  0.48581\n",
      "Iteration  64100: Avg Loss =  0.50750\n",
      "Iteration  64200: Avg Loss =  0.50513\n",
      "Iteration  64300: Avg Loss =  0.50213\n",
      "Iteration  64400: Avg Loss =  0.53425\n",
      "Iteration  64500: Avg Loss =  0.50335\n",
      "Iteration  64600: Avg Loss =  0.50003\n",
      "Iteration  64700: Avg Loss =  0.48691\n",
      "Iteration  64800: Avg Loss =  0.48845\n",
      "Iteration  64900: Avg Loss =  0.56991\n",
      "Iteration  65000: Avg Loss =  0.50775\n",
      "Iteration  65100: Avg Loss =  0.49855\n",
      "Iteration  65200: Avg Loss =  0.50991\n",
      "Iteration  65300: Avg Loss =  0.50586\n",
      "Iteration  65400: Avg Loss =  0.49151\n",
      "Iteration  65500: Avg Loss =  0.47505\n",
      "Iteration  65600: Avg Loss =  0.50752\n",
      "Iteration  65700: Avg Loss =  0.47683\n",
      "Iteration  65800: Avg Loss =  0.51073\n",
      "Iteration  65900: Avg Loss =  0.47594\n",
      "Iteration  66000: Avg Loss =  0.50224\n",
      "Iteration  66100: Avg Loss =  0.48744\n",
      "Iteration  66200: Avg Loss =  0.47176\n",
      "Iteration  66300: Avg Loss =  0.50947\n",
      "Iteration  66400: Avg Loss =  0.49270\n",
      "Iteration  66500: Avg Loss =  0.53474\n",
      "Iteration  66600: Avg Loss =  0.49750\n",
      "Iteration  66700: Avg Loss =  0.49941\n",
      "Iteration  66800: Avg Loss =  0.51290\n",
      "Iteration  66900: Avg Loss =  0.45883\n",
      "Iteration  67000: Avg Loss =  0.47555\n",
      "Iteration  67100: Avg Loss =  0.50579\n",
      "Iteration  67200: Avg Loss =  0.50675\n",
      "Iteration  67300: Avg Loss =  0.46942\n",
      "Iteration  67400: Avg Loss =  0.49445\n",
      "Iteration  67500: Avg Loss =  0.49203\n",
      "Iteration  67600: Avg Loss =  0.49658\n",
      "Iteration  67700: Avg Loss =  0.50804\n",
      "Iteration  67800: Avg Loss =  0.46618\n",
      "Iteration  67900: Avg Loss =  0.46702\n",
      "Iteration  68000: Avg Loss =  0.46233\n",
      "Iteration  68100: Avg Loss =  0.48632\n",
      "Iteration  68200: Avg Loss =  0.49361\n",
      "Iteration  68300: Avg Loss =  0.47271\n",
      "Iteration  68400: Avg Loss =  0.48997\n",
      "Iteration  68500: Avg Loss =  0.47494\n",
      "Iteration  68600: Avg Loss =  0.47506\n",
      "Iteration  68700: Avg Loss =  0.47363\n",
      "Iteration  68800: Avg Loss =  0.51551\n",
      "Iteration  68900: Avg Loss =  0.45492\n",
      "Iteration  69000: Avg Loss =  0.48303\n",
      "Iteration  69100: Avg Loss =  0.52298\n",
      "Iteration  69200: Avg Loss =  0.49037\n",
      "Iteration  69300: Avg Loss =  0.49203\n",
      "Iteration  69400: Avg Loss =  0.46008\n",
      "Iteration  69500: Avg Loss =  0.46239\n",
      "Iteration  69600: Avg Loss =  0.47617\n",
      "Iteration  69700: Avg Loss =  0.49508\n",
      "Iteration  69800: Avg Loss =  0.48282\n",
      "Iteration  69900: Avg Loss =  0.45241\n",
      "Iteration  70000: Avg Loss =  0.48736\n",
      "Iteration  70100: Avg Loss =  0.51224\n",
      "Iteration  70200: Avg Loss =  0.49001\n",
      "Iteration  70300: Avg Loss =  0.47681\n",
      "Iteration  70400: Avg Loss =  0.51104\n",
      "Iteration  70500: Avg Loss =  0.50936\n",
      "Iteration  70600: Avg Loss =  0.47447\n",
      "Iteration  70700: Avg Loss =  0.50539\n",
      "Iteration  70800: Avg Loss =  0.49199\n",
      "Iteration  70900: Avg Loss =  0.47652\n",
      "Iteration  71000: Avg Loss =  0.47833\n",
      "Iteration  71100: Avg Loss =  0.45586\n",
      "Iteration  71200: Avg Loss =  0.47942\n",
      "Iteration  71300: Avg Loss =  0.51505\n",
      "Iteration  71400: Avg Loss =  0.47883\n",
      "Iteration  71500: Avg Loss =  0.44549\n",
      "Iteration  71600: Avg Loss =  0.46555\n",
      "Iteration  71700: Avg Loss =  0.49254\n",
      "Iteration  71800: Avg Loss =  0.49124\n",
      "Iteration  71900: Avg Loss =  0.47596\n",
      "Iteration  72000: Avg Loss =  0.47689\n",
      "Iteration  72100: Avg Loss =  0.49771\n",
      "Iteration  72200: Avg Loss =  0.45882\n",
      "Iteration  72300: Avg Loss =  0.44947\n",
      "Iteration  72400: Avg Loss =  0.44273\n",
      "Iteration  72500: Avg Loss =  0.45984\n",
      "Iteration  72600: Avg Loss =  0.46485\n",
      "Iteration  72700: Avg Loss =  0.45880\n",
      "Iteration  72800: Avg Loss =  0.46676\n",
      "Iteration  72900: Avg Loss =  0.45670\n",
      "Iteration  73000: Avg Loss =  0.49710\n",
      "Iteration  73100: Avg Loss =  0.47152\n",
      "Iteration  73200: Avg Loss =  0.43629\n",
      "Iteration  73300: Avg Loss =  0.47157\n",
      "Iteration  73400: Avg Loss =  0.50605\n",
      "Iteration  73500: Avg Loss =  0.49042\n",
      "Iteration  73600: Avg Loss =  0.46987\n",
      "Iteration  73700: Avg Loss =  0.48006\n",
      "Iteration  73800: Avg Loss =  0.45223\n",
      "Iteration  73900: Avg Loss =  0.52618\n",
      "Iteration  74000: Avg Loss =  0.49541\n",
      "Iteration  74100: Avg Loss =  0.49175\n",
      "Iteration  74200: Avg Loss =  0.45391\n",
      "Iteration  74300: Avg Loss =  0.47205\n",
      "Iteration  74400: Avg Loss =  0.48276\n",
      "Iteration  74500: Avg Loss =  0.45586\n",
      "Iteration  74600: Avg Loss =  0.43549\n",
      "Iteration  74700: Avg Loss =  0.46109\n",
      "Iteration  74800: Avg Loss =  0.46376\n",
      "Iteration  74900: Avg Loss =  0.49665\n",
      "Iteration  75000: Avg Loss =  0.45202\n",
      "Iteration  75100: Avg Loss =  0.45833\n",
      "Iteration  75200: Avg Loss =  0.46724\n",
      "Iteration  75300: Avg Loss =  0.47962\n",
      "Iteration  75400: Avg Loss =  0.48066\n",
      "Iteration  75500: Avg Loss =  0.47026\n",
      "Iteration  75600: Avg Loss =  0.43067\n",
      "Iteration  75700: Avg Loss =  0.45758\n",
      "Iteration  75800: Avg Loss =  0.44680\n",
      "Iteration  75900: Avg Loss =  0.44464\n",
      "Iteration  76000: Avg Loss =  0.46580\n",
      "Iteration  76100: Avg Loss =  0.47497\n",
      "Iteration  76200: Avg Loss =  0.45805\n",
      "Iteration  76300: Avg Loss =  0.42354\n",
      "Iteration  76400: Avg Loss =  0.47724\n",
      "Iteration  76500: Avg Loss =  0.48201\n",
      "Iteration  76600: Avg Loss =  0.47546\n",
      "Iteration  76700: Avg Loss =  0.43786\n",
      "Iteration  76800: Avg Loss =  0.45026\n",
      "Iteration  76900: Avg Loss =  0.47397\n",
      "Iteration  77000: Avg Loss =  0.47968\n",
      "Iteration  77100: Avg Loss =  0.43300\n",
      "Iteration  77200: Avg Loss =  0.45956\n",
      "Iteration  77300: Avg Loss =  0.43772\n",
      "Iteration  77400: Avg Loss =  0.47666\n",
      "Iteration  77500: Avg Loss =  0.47325\n",
      "Iteration  77600: Avg Loss =  0.47486\n",
      "Iteration  77700: Avg Loss =  0.44066\n",
      "Iteration  77800: Avg Loss =  0.41808\n",
      "Iteration  77900: Avg Loss =  0.42824\n",
      "Iteration  78000: Avg Loss =  0.44243\n",
      "Iteration  78100: Avg Loss =  0.48322\n",
      "Iteration  78200: Avg Loss =  0.47140\n",
      "Iteration  78300: Avg Loss =  0.48072\n",
      "Iteration  78400: Avg Loss =  0.44514\n",
      "Iteration  78500: Avg Loss =  0.47122\n",
      "Iteration  78600: Avg Loss =  0.48885\n",
      "Iteration  78700: Avg Loss =  0.45488\n",
      "Iteration  78800: Avg Loss =  0.46933\n",
      "Iteration  78900: Avg Loss =  0.46970\n",
      "Iteration  79000: Avg Loss =  0.47810\n",
      "Iteration  79100: Avg Loss =  0.49059\n",
      "Iteration  79200: Avg Loss =  0.46998\n",
      "Iteration  79300: Avg Loss =  0.45422\n",
      "Iteration  79400: Avg Loss =  0.43871\n",
      "Iteration  79500: Avg Loss =  0.45288\n",
      "Iteration  79600: Avg Loss =  0.46933\n",
      "Iteration  79700: Avg Loss =  0.45697\n",
      "Iteration  79800: Avg Loss =  0.43249\n",
      "Iteration  79900: Avg Loss =  0.46977\n",
      "Iteration  80000: Avg Loss =  0.47071\n",
      "Iteration  80100: Avg Loss =  0.44758\n",
      "Iteration  80200: Avg Loss =  0.44666\n",
      "Iteration  80300: Avg Loss =  0.43866\n",
      "Iteration  80400: Avg Loss =  0.45051\n",
      "Iteration  80500: Avg Loss =  0.46419\n",
      "Iteration  80600: Avg Loss =  0.45827\n",
      "Iteration  80700: Avg Loss =  0.52077\n",
      "Iteration  80800: Avg Loss =  0.40722\n",
      "Iteration  80900: Avg Loss =  0.44599\n",
      "Iteration  81000: Avg Loss =  0.41924\n",
      "Iteration  81100: Avg Loss =  0.43686\n",
      "Iteration  81200: Avg Loss =  0.46770\n",
      "Iteration  81300: Avg Loss =  0.45004\n",
      "Iteration  81400: Avg Loss =  0.42204\n",
      "Iteration  81500: Avg Loss =  0.43134\n",
      "Iteration  81600: Avg Loss =  0.48463\n",
      "Iteration  81700: Avg Loss =  0.42823\n",
      "Iteration  81800: Avg Loss =  0.46692\n",
      "Iteration  81900: Avg Loss =  0.47161\n",
      "Iteration  82000: Avg Loss =  0.44327\n",
      "Iteration  82100: Avg Loss =  0.46675\n",
      "Iteration  82200: Avg Loss =  0.43820\n",
      "Iteration  82300: Avg Loss =  0.46390\n",
      "Iteration  82400: Avg Loss =  0.45639\n",
      "Iteration  82500: Avg Loss =  0.44127\n",
      "Iteration  82600: Avg Loss =  0.43327\n",
      "Iteration  82700: Avg Loss =  0.43838\n",
      "Iteration  82800: Avg Loss =  0.44734\n",
      "Iteration  82900: Avg Loss =  0.43245\n",
      "Iteration  83000: Avg Loss =  0.45591\n",
      "Iteration  83100: Avg Loss =  0.43391\n",
      "Iteration  83200: Avg Loss =  0.46823\n",
      "Iteration  83300: Avg Loss =  0.45925\n",
      "Iteration  83400: Avg Loss =  0.44688\n",
      "Iteration  83500: Avg Loss =  0.43328\n",
      "Iteration  83600: Avg Loss =  0.45997\n",
      "Iteration  83700: Avg Loss =  0.45143\n",
      "Iteration  83800: Avg Loss =  0.45071\n",
      "Iteration  83900: Avg Loss =  0.44753\n",
      "Iteration  84000: Avg Loss =  0.42108\n",
      "Iteration  84100: Avg Loss =  0.45706\n",
      "Iteration  84200: Avg Loss =  0.45078\n",
      "Iteration  84300: Avg Loss =  0.45841\n",
      "Iteration  84400: Avg Loss =  0.44967\n",
      "Iteration  84500: Avg Loss =  0.44756\n",
      "Iteration  84600: Avg Loss =  0.46414\n",
      "Iteration  84700: Avg Loss =  0.45472\n",
      "Iteration  84800: Avg Loss =  0.45298\n",
      "Iteration  84900: Avg Loss =  0.42310\n",
      "Iteration  85000: Avg Loss =  0.45361\n",
      "Iteration  85100: Avg Loss =  0.41774\n",
      "Iteration  85200: Avg Loss =  0.44393\n",
      "Iteration  85300: Avg Loss =  0.42999\n",
      "Iteration  85400: Avg Loss =  0.46913\n",
      "Iteration  85500: Avg Loss =  0.42904\n",
      "Iteration  85600: Avg Loss =  0.44475\n",
      "Iteration  85700: Avg Loss =  0.42796\n",
      "Iteration  85800: Avg Loss =  0.41719\n",
      "Iteration  85900: Avg Loss =  0.45204\n",
      "Iteration  86000: Avg Loss =  0.43059\n",
      "Iteration  86100: Avg Loss =  0.44455\n",
      "Iteration  86200: Avg Loss =  0.46077\n",
      "Iteration  86300: Avg Loss =  0.45668\n",
      "Iteration  86400: Avg Loss =  0.43133\n",
      "Iteration  86500: Avg Loss =  0.49935\n",
      "Iteration  86600: Avg Loss =  0.44903\n",
      "Iteration  86700: Avg Loss =  0.43667\n",
      "Iteration  86800: Avg Loss =  0.46086\n",
      "Iteration  86900: Avg Loss =  0.45765\n",
      "Iteration  87000: Avg Loss =  0.42672\n",
      "Iteration  87100: Avg Loss =  0.43701\n",
      "Iteration  87200: Avg Loss =  0.42571\n",
      "Iteration  87300: Avg Loss =  0.46294\n",
      "Iteration  87400: Avg Loss =  0.44136\n",
      "Iteration  87500: Avg Loss =  0.43935\n",
      "Iteration  87600: Avg Loss =  0.44558\n",
      "Iteration  87700: Avg Loss =  0.44390\n",
      "Iteration  87800: Avg Loss =  0.45440\n",
      "Iteration  87900: Avg Loss =  0.42483\n",
      "Iteration  88000: Avg Loss =  0.42477\n",
      "Iteration  88100: Avg Loss =  0.41613\n",
      "Iteration  88200: Avg Loss =  0.43524\n",
      "Iteration  88300: Avg Loss =  0.45864\n",
      "Iteration  88400: Avg Loss =  0.46996\n",
      "Iteration  88500: Avg Loss =  0.43421\n",
      "Iteration  88600: Avg Loss =  0.46125\n",
      "Iteration  88700: Avg Loss =  0.43786\n",
      "Iteration  88800: Avg Loss =  0.42057\n",
      "Iteration  88900: Avg Loss =  0.43545\n",
      "Iteration  89000: Avg Loss =  0.43716\n",
      "Iteration  89100: Avg Loss =  0.42541\n",
      "Iteration  89200: Avg Loss =  0.44413\n",
      "Iteration  89300: Avg Loss =  0.42687\n",
      "Iteration  89400: Avg Loss =  0.42793\n",
      "Iteration  89500: Avg Loss =  0.45297\n",
      "Iteration  89600: Avg Loss =  0.41535\n",
      "Iteration  89700: Avg Loss =  0.41489\n",
      "Iteration  89800: Avg Loss =  0.43317\n",
      "Iteration  89900: Avg Loss =  0.44789\n",
      "Iteration  90000: Avg Loss =  0.46462\n",
      "Iteration  90100: Avg Loss =  0.44271\n",
      "Iteration  90200: Avg Loss =  0.44208\n",
      "Iteration  90300: Avg Loss =  0.42366\n",
      "Iteration  90400: Avg Loss =  0.43813\n",
      "Iteration  90500: Avg Loss =  0.45073\n",
      "Iteration  90600: Avg Loss =  0.44184\n",
      "Iteration  90700: Avg Loss =  0.44234\n",
      "Iteration  90800: Avg Loss =  0.44010\n",
      "Iteration  90900: Avg Loss =  0.43818\n",
      "Iteration  91000: Avg Loss =  0.43610\n",
      "Iteration  91100: Avg Loss =  0.47562\n",
      "Iteration  91200: Avg Loss =  0.44221\n",
      "Iteration  91300: Avg Loss =  0.44028\n",
      "Iteration  91400: Avg Loss =  0.42472\n",
      "Iteration  91500: Avg Loss =  0.43588\n",
      "Iteration  91600: Avg Loss =  0.41671\n",
      "Iteration  91700: Avg Loss =  0.42012\n",
      "Iteration  91800: Avg Loss =  0.43204\n",
      "Iteration  91900: Avg Loss =  0.42059\n",
      "Iteration  92000: Avg Loss =  0.45651\n",
      "Iteration  92100: Avg Loss =  0.42555\n",
      "Iteration  92200: Avg Loss =  0.41042\n",
      "Iteration  92300: Avg Loss =  0.41421\n",
      "Iteration  92400: Avg Loss =  0.42479\n",
      "Iteration  92500: Avg Loss =  0.43797\n",
      "Iteration  92600: Avg Loss =  0.44422\n",
      "Iteration  92700: Avg Loss =  0.43180\n",
      "Iteration  92800: Avg Loss =  0.44477\n",
      "Iteration  92900: Avg Loss =  0.41337\n",
      "Iteration  93000: Avg Loss =  0.45567\n",
      "Iteration  93100: Avg Loss =  0.44235\n",
      "Iteration  93200: Avg Loss =  0.40974\n",
      "Iteration  93300: Avg Loss =  0.41659\n",
      "Iteration  93400: Avg Loss =  0.42209\n",
      "Iteration  93500: Avg Loss =  0.46723\n",
      "Iteration  93600: Avg Loss =  0.43536\n",
      "Iteration  93700: Avg Loss =  0.44003\n",
      "Iteration  93800: Avg Loss =  0.42568\n",
      "Iteration  93900: Avg Loss =  0.41497\n",
      "Iteration  94000: Avg Loss =  0.39670\n",
      "Iteration  94100: Avg Loss =  0.40423\n",
      "Iteration  94200: Avg Loss =  0.38091\n",
      "Iteration  94300: Avg Loss =  0.42916\n",
      "Iteration  94400: Avg Loss =  0.43234\n",
      "Iteration  94500: Avg Loss =  0.44482\n",
      "Iteration  94600: Avg Loss =  0.41042\n",
      "Iteration  94700: Avg Loss =  0.43902\n",
      "Iteration  94800: Avg Loss =  0.41082\n",
      "Iteration  94900: Avg Loss =  0.42583\n",
      "Iteration  95000: Avg Loss =  0.43762\n",
      "Iteration  95100: Avg Loss =  0.42475\n",
      "Iteration  95200: Avg Loss =  0.38164\n",
      "Iteration  95300: Avg Loss =  0.40979\n",
      "Iteration  95400: Avg Loss =  0.43882\n",
      "Iteration  95500: Avg Loss =  0.42392\n",
      "Iteration  95600: Avg Loss =  0.42477\n",
      "Iteration  95700: Avg Loss =  0.41179\n",
      "Iteration  95800: Avg Loss =  0.40367\n",
      "Iteration  95900: Avg Loss =  0.41991\n",
      "Iteration  96000: Avg Loss =  0.40527\n",
      "Iteration  96100: Avg Loss =  0.43493\n",
      "Iteration  96200: Avg Loss =  0.38650\n",
      "Iteration  96300: Avg Loss =  0.41427\n",
      "Iteration  96400: Avg Loss =  0.39544\n",
      "Iteration  96500: Avg Loss =  0.42919\n",
      "Iteration  96600: Avg Loss =  0.42197\n",
      "Iteration  96700: Avg Loss =  0.42042\n",
      "Iteration  96800: Avg Loss =  0.42513\n",
      "Iteration  96900: Avg Loss =  0.40512\n",
      "Iteration  97000: Avg Loss =  0.43236\n",
      "Iteration  97100: Avg Loss =  0.40651\n",
      "Iteration  97200: Avg Loss =  0.40481\n",
      "Iteration  97300: Avg Loss =  0.44382\n",
      "Iteration  97400: Avg Loss =  0.41432\n",
      "Iteration  97500: Avg Loss =  0.38458\n",
      "Iteration  97600: Avg Loss =  0.43271\n",
      "Iteration  97700: Avg Loss =  0.43969\n",
      "Iteration  97800: Avg Loss =  0.41805\n",
      "Iteration  97900: Avg Loss =  0.43394\n",
      "Iteration  98000: Avg Loss =  0.38980\n",
      "Iteration  98100: Avg Loss =  0.44197\n",
      "Iteration  98200: Avg Loss =  0.42025\n",
      "Iteration  98300: Avg Loss =  0.44198\n",
      "Iteration  98400: Avg Loss =  0.43843\n",
      "Iteration  98500: Avg Loss =  0.39872\n",
      "Iteration  98600: Avg Loss =  0.43253\n",
      "Iteration  98700: Avg Loss =  0.41544\n",
      "Iteration  98800: Avg Loss =  0.40902\n",
      "Iteration  98900: Avg Loss =  0.40425\n",
      "Iteration  99000: Avg Loss =  0.40898\n",
      "Iteration  99100: Avg Loss =  0.41128\n",
      "Iteration  99200: Avg Loss =  0.42875\n",
      "Iteration  99300: Avg Loss =  0.43054\n",
      "Iteration  99400: Avg Loss =  0.40171\n",
      "Iteration  99500: Avg Loss =  0.43661\n",
      "Iteration  99600: Avg Loss =  0.41390\n",
      "Iteration  99700: Avg Loss =  0.41182\n",
      "Iteration  99800: Avg Loss =  0.42850\n",
      "Iteration  99900: Avg Loss =  0.45315\n",
      "Iteration 100000: Avg Loss =  0.40210\n",
      "Iteration 100100: Avg Loss =  0.39911\n",
      "Iteration 100200: Avg Loss =  0.39348\n",
      "Iteration 100300: Avg Loss =  0.44173\n",
      "Iteration 100400: Avg Loss =  0.44333\n",
      "Iteration 100500: Avg Loss =  0.40021\n",
      "Iteration 100600: Avg Loss =  0.40217\n",
      "Iteration 100700: Avg Loss =  0.41550\n",
      "Iteration 100800: Avg Loss =  0.41496\n",
      "Iteration 100900: Avg Loss =  0.41120\n",
      "Iteration 101000: Avg Loss =  0.42366\n",
      "Iteration 101100: Avg Loss =  0.38095\n",
      "Iteration 101200: Avg Loss =  0.44850\n",
      "Iteration 101300: Avg Loss =  0.41773\n",
      "Iteration 101400: Avg Loss =  0.41162\n",
      "Iteration 101500: Avg Loss =  0.41394\n",
      "Iteration 101600: Avg Loss =  0.43025\n",
      "Iteration 101700: Avg Loss =  0.40271\n",
      "Iteration 101800: Avg Loss =  0.41458\n",
      "Iteration 101900: Avg Loss =  0.38509\n",
      "Iteration 102000: Avg Loss =  0.39312\n",
      "Iteration 102100: Avg Loss =  0.43138\n",
      "Iteration 102200: Avg Loss =  0.42870\n",
      "Iteration 102300: Avg Loss =  0.39847\n",
      "Iteration 102400: Avg Loss =  0.46574\n",
      "Iteration 102500: Avg Loss =  0.41391\n",
      "Iteration 102600: Avg Loss =  0.41640\n",
      "Iteration 102700: Avg Loss =  0.44037\n",
      "Iteration 102800: Avg Loss =  0.41726\n",
      "Iteration 102900: Avg Loss =  0.43125\n",
      "Iteration 103000: Avg Loss =  0.40313\n",
      "Iteration 103100: Avg Loss =  0.42591\n",
      "Iteration 103200: Avg Loss =  0.42697\n",
      "Iteration 103300: Avg Loss =  0.42178\n",
      "Iteration 103400: Avg Loss =  0.42563\n",
      "Iteration 103500: Avg Loss =  0.41123\n",
      "Iteration 103600: Avg Loss =  0.36081\n",
      "Iteration 103700: Avg Loss =  0.40717\n",
      "Iteration 103800: Avg Loss =  0.40340\n",
      "Iteration 103900: Avg Loss =  0.39546\n",
      "Iteration 104000: Avg Loss =  0.42364\n",
      "Iteration 104100: Avg Loss =  0.42661\n",
      "Iteration 104200: Avg Loss =  0.37774\n",
      "Iteration 104300: Avg Loss =  0.40463\n",
      "Iteration 104400: Avg Loss =  0.42730\n",
      "Iteration 104500: Avg Loss =  0.40938\n",
      "Iteration 104600: Avg Loss =  0.39207\n",
      "Iteration 104700: Avg Loss =  0.40596\n",
      "Iteration 104800: Avg Loss =  0.40113\n",
      "Iteration 104900: Avg Loss =  0.40251\n",
      "Iteration 105000: Avg Loss =  0.41195\n",
      "Iteration 105100: Avg Loss =  0.40944\n",
      "Iteration 105200: Avg Loss =  0.39490\n",
      "Iteration 105300: Avg Loss =  0.41128\n",
      "Iteration 105400: Avg Loss =  0.40635\n",
      "Iteration 105500: Avg Loss =  0.38509\n",
      "Iteration 105600: Avg Loss =  0.41107\n",
      "Iteration 105700: Avg Loss =  0.39585\n",
      "Iteration 105800: Avg Loss =  0.45940\n",
      "Iteration 105900: Avg Loss =  0.40360\n",
      "Iteration 106000: Avg Loss =  0.39045\n",
      "Iteration 106100: Avg Loss =  0.41873\n",
      "Iteration 106200: Avg Loss =  0.41870\n",
      "Iteration 106300: Avg Loss =  0.40478\n",
      "Iteration 106400: Avg Loss =  0.39803\n",
      "Iteration 106500: Avg Loss =  0.42024\n",
      "Iteration 106600: Avg Loss =  0.39749\n",
      "Iteration 106700: Avg Loss =  0.38732\n",
      "Iteration 106800: Avg Loss =  0.37403\n",
      "Iteration 106900: Avg Loss =  0.38666\n",
      "Iteration 107000: Avg Loss =  0.41460\n",
      "Iteration 107100: Avg Loss =  0.45423\n",
      "Iteration 107200: Avg Loss =  0.38633\n",
      "Iteration 107300: Avg Loss =  0.39967\n",
      "Iteration 107400: Avg Loss =  0.38894\n",
      "Iteration 107500: Avg Loss =  0.40129\n",
      "Iteration 107600: Avg Loss =  0.41199\n",
      "Iteration 107700: Avg Loss =  0.40714\n",
      "Iteration 107800: Avg Loss =  0.43028\n",
      "Iteration 107900: Avg Loss =  0.43050\n",
      "Iteration 108000: Avg Loss =  0.39769\n",
      "Iteration 108100: Avg Loss =  0.42982\n",
      "Iteration 108200: Avg Loss =  0.40765\n",
      "Iteration 108300: Avg Loss =  0.39435\n",
      "Iteration 108400: Avg Loss =  0.41616\n",
      "Iteration 108500: Avg Loss =  0.41202\n",
      "Iteration 108600: Avg Loss =  0.38614\n",
      "Iteration 108700: Avg Loss =  0.38337\n",
      "Iteration 108800: Avg Loss =  0.41164\n",
      "Iteration 108900: Avg Loss =  0.41198\n",
      "Iteration 109000: Avg Loss =  0.40813\n",
      "Iteration 109100: Avg Loss =  0.38719\n",
      "Iteration 109200: Avg Loss =  0.40770\n",
      "Iteration 109300: Avg Loss =  0.41508\n",
      "Iteration 109400: Avg Loss =  0.40575\n",
      "Iteration 109500: Avg Loss =  0.40760\n",
      "Iteration 109600: Avg Loss =  0.41124\n",
      "Iteration 109700: Avg Loss =  0.37272\n",
      "Iteration 109800: Avg Loss =  0.40409\n",
      "Iteration 109900: Avg Loss =  0.42369\n",
      "Iteration 110000: Avg Loss =  0.42010\n",
      "Iteration 110100: Avg Loss =  0.40154\n",
      "Iteration 110200: Avg Loss =  0.41925\n",
      "Iteration 110300: Avg Loss =  0.43284\n",
      "Iteration 110400: Avg Loss =  0.39290\n",
      "Iteration 110500: Avg Loss =  0.41227\n",
      "Iteration 110600: Avg Loss =  0.40274\n",
      "Iteration 110700: Avg Loss =  0.42392\n",
      "Iteration 110800: Avg Loss =  0.41246\n",
      "Iteration 110900: Avg Loss =  0.37609\n",
      "Iteration 111000: Avg Loss =  0.36988\n",
      "Iteration 111100: Avg Loss =  0.40541\n",
      "Iteration 111200: Avg Loss =  0.40966\n",
      "Iteration 111300: Avg Loss =  0.39728\n",
      "Iteration 111400: Avg Loss =  0.42811\n",
      "Iteration 111500: Avg Loss =  0.40513\n",
      "Iteration 111600: Avg Loss =  0.39891\n",
      "Iteration 111700: Avg Loss =  0.41246\n",
      "Iteration 111800: Avg Loss =  0.42946\n",
      "Iteration 111900: Avg Loss =  0.38969\n",
      "Iteration 112000: Avg Loss =  0.41919\n",
      "Iteration 112100: Avg Loss =  0.37897\n",
      "Iteration 112200: Avg Loss =  0.42302\n",
      "Iteration 112300: Avg Loss =  0.39656\n",
      "Iteration 112400: Avg Loss =  0.40329\n",
      "Iteration 112500: Avg Loss =  0.41782\n",
      "Iteration 112600: Avg Loss =  0.39947\n",
      "Iteration 112700: Avg Loss =  0.43142\n",
      "Iteration 112800: Avg Loss =  0.39601\n",
      "Iteration 112900: Avg Loss =  0.37635\n",
      "Iteration 113000: Avg Loss =  0.42371\n",
      "Iteration 113100: Avg Loss =  0.43392\n",
      "Iteration 113200: Avg Loss =  0.39823\n",
      "Iteration 113300: Avg Loss =  0.38455\n",
      "Iteration 113400: Avg Loss =  0.35755\n",
      "Iteration 113500: Avg Loss =  0.37299\n",
      "Iteration 113600: Avg Loss =  0.36393\n",
      "Iteration 113700: Avg Loss =  0.42819\n",
      "Iteration 113800: Avg Loss =  0.38288\n",
      "Iteration 113900: Avg Loss =  0.43167\n",
      "Iteration 114000: Avg Loss =  0.40478\n",
      "Iteration 114100: Avg Loss =  0.42338\n",
      "Iteration 114200: Avg Loss =  0.38529\n",
      "Iteration 114300: Avg Loss =  0.40630\n",
      "Iteration 114400: Avg Loss =  0.41204\n",
      "Iteration 114500: Avg Loss =  0.42122\n",
      "Iteration 114600: Avg Loss =  0.43126\n",
      "Iteration 114700: Avg Loss =  0.42122\n",
      "Iteration 114800: Avg Loss =  0.41060\n",
      "Iteration 114900: Avg Loss =  0.41223\n",
      "Iteration 115000: Avg Loss =  0.39695\n",
      "Iteration 115100: Avg Loss =  0.43727\n",
      "Iteration 115200: Avg Loss =  0.41754\n",
      "Iteration 115300: Avg Loss =  0.39627\n",
      "Iteration 115400: Avg Loss =  0.41377\n",
      "Iteration 115500: Avg Loss =  0.36891\n",
      "Iteration 115600: Avg Loss =  0.42726\n",
      "Iteration 115700: Avg Loss =  0.39187\n",
      "Iteration 115800: Avg Loss =  0.37094\n",
      "Iteration 115900: Avg Loss =  0.40367\n",
      "Iteration 116000: Avg Loss =  0.42083\n",
      "Iteration 116100: Avg Loss =  0.39795\n",
      "Iteration 116200: Avg Loss =  0.37684\n",
      "Iteration 116300: Avg Loss =  0.41542\n",
      "Iteration 116400: Avg Loss =  0.40035\n",
      "Iteration 116500: Avg Loss =  0.40091\n",
      "Iteration 116600: Avg Loss =  0.40644\n",
      "Iteration 116700: Avg Loss =  0.38563\n",
      "Iteration 116800: Avg Loss =  0.39124\n",
      "Iteration 116900: Avg Loss =  0.43860\n",
      "Iteration 117000: Avg Loss =  0.36181\n",
      "Iteration 117100: Avg Loss =  0.40383\n",
      "Iteration 117200: Avg Loss =  0.43070\n",
      "Iteration 117300: Avg Loss =  0.43242\n",
      "Iteration 117400: Avg Loss =  0.40939\n",
      "Iteration 117500: Avg Loss =  0.43478\n",
      "Iteration 117600: Avg Loss =  0.42875\n",
      "Iteration 117700: Avg Loss =  0.44642\n",
      "Iteration 117800: Avg Loss =  0.39981\n",
      "Iteration 117900: Avg Loss =  0.38466\n",
      "Iteration 118000: Avg Loss =  0.37112\n",
      "Iteration 118100: Avg Loss =  0.39050\n",
      "Iteration 118200: Avg Loss =  0.38530\n",
      "Iteration 118300: Avg Loss =  0.40203\n",
      "Iteration 118400: Avg Loss =  0.41768\n",
      "Iteration 118500: Avg Loss =  0.37736\n",
      "Iteration 118600: Avg Loss =  0.40276\n",
      "Iteration 118700: Avg Loss =  0.40400\n",
      "Iteration 118800: Avg Loss =  0.39244\n",
      "Iteration 118900: Avg Loss =  0.39967\n",
      "Iteration 119000: Avg Loss =  0.38639\n",
      "Iteration 119100: Avg Loss =  0.34522\n",
      "Iteration 119200: Avg Loss =  0.44107\n",
      "Iteration 119300: Avg Loss =  0.40177\n",
      "Iteration 119400: Avg Loss =  0.39694\n",
      "Iteration 119500: Avg Loss =  0.37708\n",
      "Iteration 119600: Avg Loss =  0.36749\n",
      "Iteration 119700: Avg Loss =  0.43516\n",
      "Iteration 119800: Avg Loss =  0.36561\n",
      "Iteration 119900: Avg Loss =  0.39285\n",
      "Iteration 120000: Avg Loss =  0.39242\n",
      "Iteration 120100: Avg Loss =  0.40170\n",
      "Iteration 120200: Avg Loss =  0.36947\n",
      "Iteration 120300: Avg Loss =  0.44225\n",
      "Iteration 120400: Avg Loss =  0.36301\n",
      "Iteration 120500: Avg Loss =  0.39934\n",
      "Iteration 120600: Avg Loss =  0.38791\n",
      "Iteration 120700: Avg Loss =  0.38081\n",
      "Iteration 120800: Avg Loss =  0.38885\n",
      "Iteration 120900: Avg Loss =  0.40780\n",
      "Iteration 121000: Avg Loss =  0.39942\n",
      "Iteration 121100: Avg Loss =  0.37141\n",
      "Iteration 121200: Avg Loss =  0.37319\n",
      "Iteration 121300: Avg Loss =  0.40364\n",
      "Iteration 121400: Avg Loss =  0.40701\n",
      "Iteration 121500: Avg Loss =  0.40107\n",
      "Iteration 121600: Avg Loss =  0.38000\n",
      "Iteration 121700: Avg Loss =  0.41955\n",
      "Iteration 121800: Avg Loss =  0.38557\n",
      "Iteration 121900: Avg Loss =  0.38767\n",
      "Iteration 122000: Avg Loss =  0.39533\n",
      "Iteration 122100: Avg Loss =  0.38709\n",
      "Iteration 122200: Avg Loss =  0.37525\n",
      "Iteration 122300: Avg Loss =  0.38369\n",
      "Iteration 122400: Avg Loss =  0.36612\n",
      "Iteration 122500: Avg Loss =  0.38871\n",
      "Iteration 122600: Avg Loss =  0.39913\n",
      "Iteration 122700: Avg Loss =  0.40645\n",
      "Iteration 122800: Avg Loss =  0.40234\n",
      "Iteration 122900: Avg Loss =  0.40155\n",
      "Iteration 123000: Avg Loss =  0.40979\n",
      "Iteration 123100: Avg Loss =  0.39470\n",
      "Iteration 123200: Avg Loss =  0.38399\n",
      "Iteration 123300: Avg Loss =  0.42630\n",
      "Iteration 123400: Avg Loss =  0.40063\n",
      "Iteration 123500: Avg Loss =  0.38464\n",
      "Iteration 123600: Avg Loss =  0.41217\n",
      "Iteration 123700: Avg Loss =  0.41988\n",
      "Iteration 123800: Avg Loss =  0.38655\n",
      "Iteration 123900: Avg Loss =  0.39944\n",
      "Iteration 124000: Avg Loss =  0.42594\n",
      "Iteration 124100: Avg Loss =  0.40511\n",
      "Iteration 124200: Avg Loss =  0.39549\n",
      "Iteration 124300: Avg Loss =  0.38646\n",
      "Iteration 124400: Avg Loss =  0.40229\n",
      "Iteration 124500: Avg Loss =  0.37451\n",
      "Iteration 124600: Avg Loss =  0.37709\n",
      "Iteration 124700: Avg Loss =  0.39964\n",
      "Iteration 124800: Avg Loss =  0.37573\n",
      "Iteration 124900: Avg Loss =  0.39176\n",
      "Iteration 125000: Avg Loss =  0.35809\n",
      "Iteration 125100: Avg Loss =  0.37456\n",
      "Iteration 125200: Avg Loss =  0.43788\n",
      "Iteration 125300: Avg Loss =  0.40880\n",
      "Iteration 125400: Avg Loss =  0.38200\n",
      "Iteration 125500: Avg Loss =  0.37813\n",
      "Iteration 125600: Avg Loss =  0.43646\n",
      "Iteration 125700: Avg Loss =  0.44007\n",
      "Iteration 125800: Avg Loss =  0.40491\n",
      "Iteration 125900: Avg Loss =  0.38151\n",
      "Iteration 126000: Avg Loss =  0.39610\n",
      "Iteration 126100: Avg Loss =  0.37370\n",
      "Iteration 126200: Avg Loss =  0.36507\n",
      "Iteration 126300: Avg Loss =  0.39580\n",
      "Iteration 126400: Avg Loss =  0.39957\n",
      "Iteration 126500: Avg Loss =  0.37827\n",
      "Iteration 126600: Avg Loss =  0.39013\n",
      "Iteration 126700: Avg Loss =  0.38609\n",
      "Iteration 126800: Avg Loss =  0.39135\n",
      "Iteration 126900: Avg Loss =  0.38191\n",
      "Iteration 127000: Avg Loss =  0.38168\n",
      "Iteration 127100: Avg Loss =  0.40407\n",
      "Iteration 127200: Avg Loss =  0.41793\n",
      "Iteration 127300: Avg Loss =  0.41609\n",
      "Iteration 127400: Avg Loss =  0.39994\n",
      "Iteration 127500: Avg Loss =  0.39115\n",
      "Iteration 127600: Avg Loss =  0.39465\n",
      "Iteration 127700: Avg Loss =  0.38836\n",
      "Iteration 127800: Avg Loss =  0.38433\n",
      "Iteration 127900: Avg Loss =  0.37117\n",
      "Iteration 128000: Avg Loss =  0.38054\n",
      "Iteration 128100: Avg Loss =  0.38684\n",
      "Iteration 128200: Avg Loss =  0.35043\n",
      "Iteration 128300: Avg Loss =  0.39188\n",
      "Iteration 128400: Avg Loss =  0.37244\n",
      "Iteration 128500: Avg Loss =  0.40908\n",
      "Iteration 128600: Avg Loss =  0.39244\n",
      "Iteration 128700: Avg Loss =  0.37437\n",
      "Iteration 128800: Avg Loss =  0.38472\n",
      "Iteration 128900: Avg Loss =  0.39258\n",
      "Iteration 129000: Avg Loss =  0.38789\n",
      "Iteration 129100: Avg Loss =  0.40332\n",
      "Iteration 129200: Avg Loss =  0.38175\n",
      "Iteration 129300: Avg Loss =  0.38753\n",
      "Iteration 129400: Avg Loss =  0.41702\n",
      "Iteration 129500: Avg Loss =  0.38762\n",
      "Iteration 129600: Avg Loss =  0.36977\n",
      "Iteration 129700: Avg Loss =  0.34833\n",
      "Iteration 129800: Avg Loss =  0.38741\n",
      "Iteration 129900: Avg Loss =  0.40629\n",
      "Iteration 130000: Avg Loss =  0.40764\n",
      "Iteration 130100: Avg Loss =  0.38091\n",
      "Iteration 130200: Avg Loss =  0.38398\n",
      "Iteration 130300: Avg Loss =  0.38820\n",
      "Iteration 130400: Avg Loss =  0.37232\n",
      "Iteration 130500: Avg Loss =  0.37811\n",
      "Iteration 130600: Avg Loss =  0.36849\n",
      "Iteration 130700: Avg Loss =  0.38703\n",
      "Iteration 130800: Avg Loss =  0.35968\n",
      "Iteration 130900: Avg Loss =  0.34315\n",
      "Iteration 131000: Avg Loss =  0.39040\n",
      "Iteration 131100: Avg Loss =  0.37213\n",
      "Iteration 131200: Avg Loss =  0.40146\n",
      "Iteration 131300: Avg Loss =  0.40206\n",
      "Iteration 131400: Avg Loss =  0.38162\n",
      "Iteration 131500: Avg Loss =  0.39149\n",
      "Iteration 131600: Avg Loss =  0.39338\n",
      "Iteration 131700: Avg Loss =  0.36095\n",
      "Iteration 131800: Avg Loss =  0.35580\n",
      "Iteration 131900: Avg Loss =  0.35620\n",
      "Iteration 132000: Avg Loss =  0.39005\n",
      "Iteration 132100: Avg Loss =  0.39779\n",
      "Iteration 132200: Avg Loss =  0.39649\n",
      "Iteration 132300: Avg Loss =  0.40800\n",
      "Iteration 132400: Avg Loss =  0.37343\n",
      "Iteration 132500: Avg Loss =  0.40764\n",
      "Iteration 132600: Avg Loss =  0.40362\n",
      "Iteration 132700: Avg Loss =  0.41097\n",
      "Iteration 132800: Avg Loss =  0.37044\n",
      "Iteration 132900: Avg Loss =  0.33993\n",
      "Iteration 133000: Avg Loss =  0.36975\n",
      "Iteration 133100: Avg Loss =  0.37655\n",
      "Iteration 133200: Avg Loss =  0.41301\n",
      "Iteration 133300: Avg Loss =  0.38580\n",
      "Iteration 133400: Avg Loss =  0.40176\n",
      "Iteration 133500: Avg Loss =  0.38047\n",
      "Iteration 133600: Avg Loss =  0.36625\n",
      "Iteration 133700: Avg Loss =  0.37131\n",
      "Iteration 133800: Avg Loss =  0.37386\n",
      "Iteration 133900: Avg Loss =  0.38455\n",
      "Iteration 134000: Avg Loss =  0.39431\n",
      "Iteration 134100: Avg Loss =  0.40707\n",
      "Iteration 134200: Avg Loss =  0.41410\n",
      "Iteration 134300: Avg Loss =  0.38711\n",
      "Iteration 134400: Avg Loss =  0.36556\n",
      "Iteration 134500: Avg Loss =  0.36028\n",
      "Iteration 134600: Avg Loss =  0.38161\n",
      "Iteration 134700: Avg Loss =  0.35794\n",
      "Iteration 134800: Avg Loss =  0.38108\n",
      "Iteration 134900: Avg Loss =  0.37577\n",
      "Iteration 135000: Avg Loss =  0.39043\n",
      "Iteration 135100: Avg Loss =  0.34752\n",
      "Iteration 135200: Avg Loss =  0.36851\n",
      "Iteration 135300: Avg Loss =  0.39778\n",
      "Iteration 135400: Avg Loss =  0.32980\n",
      "Iteration 135500: Avg Loss =  0.35568\n",
      "Iteration 135600: Avg Loss =  0.38587\n",
      "Iteration 135700: Avg Loss =  0.36292\n",
      "Iteration 135800: Avg Loss =  0.34839\n",
      "Iteration 135900: Avg Loss =  0.39831\n",
      "Iteration 136000: Avg Loss =  0.35304\n",
      "Iteration 136100: Avg Loss =  0.39426\n",
      "Iteration 136200: Avg Loss =  0.33198\n",
      "Iteration 136300: Avg Loss =  0.37733\n",
      "Iteration 136400: Avg Loss =  0.36640\n",
      "Iteration 136500: Avg Loss =  0.38350\n",
      "Iteration 136600: Avg Loss =  0.35430\n",
      "Iteration 136700: Avg Loss =  0.35699\n",
      "Iteration 136800: Avg Loss =  0.38850\n",
      "Iteration 136900: Avg Loss =  0.39081\n",
      "Iteration 137000: Avg Loss =  0.41642\n",
      "Iteration 137100: Avg Loss =  0.35657\n",
      "Iteration 137200: Avg Loss =  0.37012\n",
      "Iteration 137300: Avg Loss =  0.38146\n",
      "Iteration 137400: Avg Loss =  0.37783\n",
      "Iteration 137500: Avg Loss =  0.36269\n",
      "Iteration 137600: Avg Loss =  0.37239\n",
      "Iteration 137700: Avg Loss =  0.37684\n",
      "Iteration 137800: Avg Loss =  0.39842\n",
      "Iteration 137900: Avg Loss =  0.39293\n",
      "Iteration 138000: Avg Loss =  0.37361\n",
      "Iteration 138100: Avg Loss =  0.41998\n",
      "Iteration 138200: Avg Loss =  0.35917\n",
      "Iteration 138300: Avg Loss =  0.34668\n",
      "Iteration 138400: Avg Loss =  0.37145\n",
      "Iteration 138500: Avg Loss =  0.34980\n",
      "Iteration 138600: Avg Loss =  0.39478\n",
      "Iteration 138700: Avg Loss =  0.38733\n",
      "Iteration 138800: Avg Loss =  0.36623\n",
      "Iteration 138900: Avg Loss =  0.39124\n",
      "Iteration 139000: Avg Loss =  0.36645\n",
      "Iteration 139100: Avg Loss =  0.35470\n",
      "Iteration 139200: Avg Loss =  0.38555\n",
      "Iteration 139300: Avg Loss =  0.40953\n",
      "Iteration 139400: Avg Loss =  0.39027\n",
      "Iteration 139500: Avg Loss =  0.39128\n",
      "Iteration 139600: Avg Loss =  0.36977\n",
      "Iteration 139700: Avg Loss =  0.37186\n",
      "Iteration 139800: Avg Loss =  0.35560\n",
      "Iteration 139900: Avg Loss =  0.35480\n",
      "Iteration 140000: Avg Loss =  0.36735\n",
      "Iteration 140100: Avg Loss =  0.39307\n",
      "Iteration 140200: Avg Loss =  0.39726\n",
      "Iteration 140300: Avg Loss =  0.35991\n",
      "Iteration 140400: Avg Loss =  0.40731\n",
      "Iteration 140500: Avg Loss =  0.37459\n",
      "Iteration 140600: Avg Loss =  0.38614\n",
      "Iteration 140700: Avg Loss =  0.38518\n",
      "Iteration 140800: Avg Loss =  0.38394\n",
      "Iteration 140900: Avg Loss =  0.36725\n",
      "Iteration 141000: Avg Loss =  0.35100\n",
      "Iteration 141100: Avg Loss =  0.32039\n",
      "Iteration 141200: Avg Loss =  0.35437\n",
      "Iteration 141300: Avg Loss =  0.33487\n",
      "Iteration 141400: Avg Loss =  0.43609\n",
      "Iteration 141500: Avg Loss =  0.38106\n",
      "Iteration 141600: Avg Loss =  0.38205\n",
      "Iteration 141700: Avg Loss =  0.37669\n",
      "Iteration 141800: Avg Loss =  0.36316\n",
      "Iteration 141900: Avg Loss =  0.33690\n",
      "Iteration 142000: Avg Loss =  0.33835\n",
      "Iteration 142100: Avg Loss =  0.37167\n",
      "Iteration 142200: Avg Loss =  0.35793\n",
      "Iteration 142300: Avg Loss =  0.34230\n",
      "Iteration 142400: Avg Loss =  0.38869\n",
      "Iteration 142500: Avg Loss =  0.39292\n",
      "Iteration 142600: Avg Loss =  0.32023\n",
      "Iteration 142700: Avg Loss =  0.36879\n",
      "Iteration 142800: Avg Loss =  0.34453\n",
      "Iteration 142900: Avg Loss =  0.36347\n",
      "Iteration 143000: Avg Loss =  0.34941\n",
      "Iteration 143100: Avg Loss =  0.37840\n",
      "Iteration 143200: Avg Loss =  0.36608\n",
      "Iteration 143300: Avg Loss =  0.37535\n",
      "Iteration 143400: Avg Loss =  0.35647\n",
      "Iteration 143500: Avg Loss =  0.39695\n",
      "Iteration 143600: Avg Loss =  0.37651\n",
      "Iteration 143700: Avg Loss =  0.40737\n",
      "Iteration 143800: Avg Loss =  0.35729\n",
      "Iteration 143900: Avg Loss =  0.36149\n",
      "Iteration 144000: Avg Loss =  0.37585\n",
      "Iteration 144100: Avg Loss =  0.34794\n",
      "Iteration 144200: Avg Loss =  0.34364\n",
      "Iteration 144300: Avg Loss =  0.33819\n",
      "Iteration 144400: Avg Loss =  0.38693\n",
      "Iteration 144500: Avg Loss =  0.34130\n",
      "Iteration 144600: Avg Loss =  0.36046\n",
      "Iteration 144700: Avg Loss =  0.40952\n",
      "Iteration 144800: Avg Loss =  0.36504\n",
      "Iteration 144900: Avg Loss =  0.38184\n",
      "Iteration 145000: Avg Loss =  0.36022\n",
      "Iteration 145100: Avg Loss =  0.41534\n",
      "Iteration 145200: Avg Loss =  0.36503\n",
      "Iteration 145300: Avg Loss =  0.34445\n",
      "Iteration 145400: Avg Loss =  0.38722\n",
      "Iteration 145500: Avg Loss =  0.39272\n",
      "Iteration 145600: Avg Loss =  0.37160\n",
      "Iteration 145700: Avg Loss =  0.35689\n",
      "Iteration 145800: Avg Loss =  0.35030\n",
      "Iteration 145900: Avg Loss =  0.36624\n",
      "Iteration 146000: Avg Loss =  0.35808\n",
      "Iteration 146100: Avg Loss =  0.38341\n",
      "Iteration 146200: Avg Loss =  0.34438\n",
      "Iteration 146300: Avg Loss =  0.37160\n",
      "Iteration 146400: Avg Loss =  0.36777\n",
      "Iteration 146500: Avg Loss =  0.35984\n",
      "Iteration 146600: Avg Loss =  0.34797\n",
      "Iteration 146700: Avg Loss =  0.33225\n",
      "Iteration 146800: Avg Loss =  0.38627\n",
      "Iteration 146900: Avg Loss =  0.33840\n",
      "Iteration 147000: Avg Loss =  0.40004\n",
      "Iteration 147100: Avg Loss =  0.35255\n",
      "Iteration 147200: Avg Loss =  0.33278\n",
      "Iteration 147300: Avg Loss =  0.39395\n",
      "Iteration 147400: Avg Loss =  0.36266\n",
      "Iteration 147500: Avg Loss =  0.34628\n",
      "Iteration 147600: Avg Loss =  0.36078\n",
      "Iteration 147700: Avg Loss =  0.36570\n",
      "Iteration 147800: Avg Loss =  0.35908\n",
      "Iteration 147900: Avg Loss =  0.36894\n",
      "Iteration 148000: Avg Loss =  0.37882\n",
      "Iteration 148100: Avg Loss =  0.35242\n",
      "Iteration 148200: Avg Loss =  0.39667\n",
      "Iteration 148300: Avg Loss =  0.33027\n",
      "Iteration 148400: Avg Loss =  0.37240\n",
      "Iteration 148500: Avg Loss =  0.37625\n",
      "Iteration 148600: Avg Loss =  0.38769\n",
      "Iteration 148700: Avg Loss =  0.37804\n",
      "Iteration 148800: Avg Loss =  0.36017\n",
      "Iteration 148900: Avg Loss =  0.34657\n",
      "Iteration 149000: Avg Loss =  0.33014\n",
      "Iteration 149100: Avg Loss =  0.38620\n",
      "Iteration 149200: Avg Loss =  0.34885\n",
      "Iteration 149300: Avg Loss =  0.35498\n",
      "Iteration 149400: Avg Loss =  0.39048\n",
      "Iteration 149500: Avg Loss =  0.37547\n",
      "Iteration 149600: Avg Loss =  0.35407\n",
      "Iteration 149700: Avg Loss =  0.35268\n",
      "Iteration 149800: Avg Loss =  0.36846\n",
      "Iteration 149900: Avg Loss =  0.34918\n",
      "Iteration 150000: Avg Loss =  0.36509\n",
      "Iteration 150100: Avg Loss =  0.32556\n",
      "Iteration 150200: Avg Loss =  0.35517\n",
      "Iteration 150300: Avg Loss =  0.35111\n",
      "Iteration 150400: Avg Loss =  0.32225\n",
      "Iteration 150500: Avg Loss =  0.32973\n",
      "Iteration 150600: Avg Loss =  0.37344\n",
      "Iteration 150700: Avg Loss =  0.36014\n",
      "Iteration 150800: Avg Loss =  0.41722\n",
      "Iteration 150900: Avg Loss =  0.35013\n",
      "Iteration 151000: Avg Loss =  0.34980\n",
      "Iteration 151100: Avg Loss =  0.38608\n",
      "Iteration 151200: Avg Loss =  0.36733\n",
      "Iteration 151300: Avg Loss =  0.32972\n",
      "Iteration 151400: Avg Loss =  0.33490\n",
      "Iteration 151500: Avg Loss =  0.34605\n",
      "Iteration 151600: Avg Loss =  0.34310\n",
      "Iteration 151700: Avg Loss =  0.40574\n",
      "Iteration 151800: Avg Loss =  0.35686\n",
      "Iteration 151900: Avg Loss =  0.34436\n",
      "Iteration 152000: Avg Loss =  0.32084\n",
      "Iteration 152100: Avg Loss =  0.39214\n",
      "Iteration 152200: Avg Loss =  0.37838\n",
      "Iteration 152300: Avg Loss =  0.35176\n",
      "Iteration 152400: Avg Loss =  0.35719\n",
      "Iteration 152500: Avg Loss =  0.38758\n",
      "Iteration 152600: Avg Loss =  0.34788\n",
      "Iteration 152700: Avg Loss =  0.40235\n",
      "Iteration 152800: Avg Loss =  0.32633\n",
      "Iteration 152900: Avg Loss =  0.33393\n",
      "Iteration 153000: Avg Loss =  0.39056\n",
      "Iteration 153100: Avg Loss =  0.38084\n",
      "Iteration 153200: Avg Loss =  0.31329\n",
      "Iteration 153300: Avg Loss =  0.36069\n",
      "Iteration 153400: Avg Loss =  0.35344\n",
      "Iteration 153500: Avg Loss =  0.34401\n",
      "Iteration 153600: Avg Loss =  0.33578\n",
      "Iteration 153700: Avg Loss =  0.34856\n",
      "Iteration 153800: Avg Loss =  0.34953\n",
      "Iteration 153900: Avg Loss =  0.38408\n",
      "Iteration 154000: Avg Loss =  0.31563\n",
      "Iteration 154100: Avg Loss =  0.34943\n",
      "Iteration 154200: Avg Loss =  0.33581\n",
      "Iteration 154300: Avg Loss =  0.35319\n",
      "Iteration 154400: Avg Loss =  0.35535\n",
      "Iteration 154500: Avg Loss =  0.39221\n",
      "Iteration 154600: Avg Loss =  0.35290\n",
      "Iteration 154700: Avg Loss =  0.40554\n",
      "Iteration 154800: Avg Loss =  0.36361\n",
      "Iteration 154900: Avg Loss =  0.38258\n",
      "Iteration 155000: Avg Loss =  0.34080\n",
      "Iteration 155100: Avg Loss =  0.39214\n",
      "Iteration 155200: Avg Loss =  0.40236\n",
      "Iteration 155300: Avg Loss =  0.34632\n",
      "Iteration 155400: Avg Loss =  0.36915\n",
      "Iteration 155500: Avg Loss =  0.36160\n",
      "Iteration 155600: Avg Loss =  0.33352\n",
      "Iteration 155700: Avg Loss =  0.36403\n",
      "Iteration 155800: Avg Loss =  0.33711\n",
      "Iteration 155900: Avg Loss =  0.32437\n",
      "Iteration 156000: Avg Loss =  0.32965\n",
      "Iteration 156100: Avg Loss =  0.34527\n",
      "Iteration 156200: Avg Loss =  0.34528\n",
      "Iteration 156300: Avg Loss =  0.32973\n",
      "Iteration 156400: Avg Loss =  0.34574\n",
      "Iteration 156500: Avg Loss =  0.36642\n",
      "Iteration 156600: Avg Loss =  0.36088\n",
      "Iteration 156700: Avg Loss =  0.32358\n",
      "Iteration 156800: Avg Loss =  0.36708\n",
      "Iteration 156900: Avg Loss =  0.35170\n",
      "Iteration 157000: Avg Loss =  0.34804\n",
      "Iteration 157100: Avg Loss =  0.33842\n",
      "Iteration 157200: Avg Loss =  0.34473\n",
      "Iteration 157300: Avg Loss =  0.35206\n",
      "Iteration 157400: Avg Loss =  0.37369\n",
      "Iteration 157500: Avg Loss =  0.37713\n",
      "Iteration 157600: Avg Loss =  0.35066\n",
      "Iteration 157700: Avg Loss =  0.35620\n",
      "Iteration 157800: Avg Loss =  0.36741\n",
      "Iteration 157900: Avg Loss =  0.35646\n",
      "Iteration 158000: Avg Loss =  0.35493\n",
      "Iteration 158100: Avg Loss =  0.33321\n",
      "Iteration 158200: Avg Loss =  0.33387\n",
      "Iteration 158300: Avg Loss =  0.35271\n",
      "Iteration 158400: Avg Loss =  0.38732\n",
      "Iteration 158500: Avg Loss =  0.37633\n",
      "Iteration 158600: Avg Loss =  0.39475\n",
      "Iteration 158700: Avg Loss =  0.41956\n",
      "Iteration 158800: Avg Loss =  0.34150\n",
      "Iteration 158900: Avg Loss =  0.36668\n",
      "Iteration 159000: Avg Loss =  0.31972\n",
      "Iteration 159100: Avg Loss =  0.34547\n",
      "Iteration 159200: Avg Loss =  0.35841\n",
      "Iteration 159300: Avg Loss =  0.36185\n",
      "Iteration 159400: Avg Loss =  0.31325\n",
      "Iteration 159500: Avg Loss =  0.37761\n",
      "Iteration 159600: Avg Loss =  0.40282\n",
      "Iteration 159700: Avg Loss =  0.34726\n",
      "Iteration 159800: Avg Loss =  0.37981\n",
      "Iteration 159900: Avg Loss =  0.37871\n",
      "Iteration 160000: Avg Loss =  0.34453\n",
      "Iteration 160100: Avg Loss =  0.35366\n",
      "Iteration 160200: Avg Loss =  0.35390\n",
      "Iteration 160300: Avg Loss =  0.34602\n",
      "Iteration 160400: Avg Loss =  0.31002\n",
      "Iteration 160500: Avg Loss =  0.34851\n",
      "Iteration 160600: Avg Loss =  0.34069\n",
      "Iteration 160700: Avg Loss =  0.37409\n",
      "Iteration 160800: Avg Loss =  0.33585\n",
      "Iteration 160900: Avg Loss =  0.33246\n",
      "Iteration 161000: Avg Loss =  0.35047\n",
      "Iteration 161100: Avg Loss =  0.34084\n",
      "Iteration 161200: Avg Loss =  0.33927\n",
      "Iteration 161300: Avg Loss =  0.35090\n",
      "Iteration 161400: Avg Loss =  0.37483\n",
      "Iteration 161500: Avg Loss =  0.35520\n",
      "Iteration 161600: Avg Loss =  0.33982\n",
      "Iteration 161700: Avg Loss =  0.33133\n",
      "Iteration 161800: Avg Loss =  0.35147\n",
      "Iteration 161900: Avg Loss =  0.31558\n",
      "Iteration 162000: Avg Loss =  0.37024\n",
      "Iteration 162100: Avg Loss =  0.35226\n",
      "Iteration 162200: Avg Loss =  0.36155\n",
      "Iteration 162300: Avg Loss =  0.34643\n",
      "Iteration 162400: Avg Loss =  0.34879\n",
      "Iteration 162500: Avg Loss =  0.36747\n",
      "Iteration 162600: Avg Loss =  0.32720\n",
      "Iteration 162700: Avg Loss =  0.36822\n",
      "Iteration 162800: Avg Loss =  0.36754\n",
      "Iteration 162900: Avg Loss =  0.34982\n",
      "Iteration 163000: Avg Loss =  0.33059\n",
      "Iteration 163100: Avg Loss =  0.32313\n",
      "Iteration 163200: Avg Loss =  0.34009\n",
      "Iteration 163300: Avg Loss =  0.35476\n",
      "Iteration 163400: Avg Loss =  0.37815\n",
      "Iteration 163500: Avg Loss =  0.34567\n",
      "Iteration 163600: Avg Loss =  0.32135\n",
      "Iteration 163700: Avg Loss =  0.34756\n",
      "Iteration 163800: Avg Loss =  0.33795\n",
      "Iteration 163900: Avg Loss =  0.38129\n",
      "Iteration 164000: Avg Loss =  0.35684\n",
      "Iteration 164100: Avg Loss =  0.39522\n",
      "Iteration 164200: Avg Loss =  0.37488\n",
      "Iteration 164300: Avg Loss =  0.37960\n",
      "Iteration 164400: Avg Loss =  0.35592\n",
      "Iteration 164500: Avg Loss =  0.33076\n",
      "Iteration 164600: Avg Loss =  0.35740\n",
      "Iteration 164700: Avg Loss =  0.37814\n",
      "Iteration 164800: Avg Loss =  0.35340\n",
      "Iteration 164900: Avg Loss =  0.31971\n",
      "Iteration 165000: Avg Loss =  0.35007\n",
      "Iteration 165100: Avg Loss =  0.35862\n",
      "Iteration 165200: Avg Loss =  0.35345\n",
      "Iteration 165300: Avg Loss =  0.34942\n",
      "Iteration 165400: Avg Loss =  0.33247\n",
      "Iteration 165500: Avg Loss =  0.34634\n",
      "Iteration 165600: Avg Loss =  0.35133\n",
      "Iteration 165700: Avg Loss =  0.38284\n",
      "Iteration 165800: Avg Loss =  0.36680\n",
      "Iteration 165900: Avg Loss =  0.35653\n",
      "Iteration 166000: Avg Loss =  0.32671\n",
      "Iteration 166100: Avg Loss =  0.34930\n",
      "Iteration 166200: Avg Loss =  0.38016\n",
      "Iteration 166300: Avg Loss =  0.36351\n",
      "Iteration 166400: Avg Loss =  0.32645\n",
      "Iteration 166500: Avg Loss =  0.32315\n",
      "Iteration 166600: Avg Loss =  0.37169\n",
      "Iteration 166700: Avg Loss =  0.37110\n",
      "Iteration 166800: Avg Loss =  0.34627\n",
      "Iteration 166900: Avg Loss =  0.36157\n",
      "Iteration 167000: Avg Loss =  0.34759\n",
      "Iteration 167100: Avg Loss =  0.35114\n",
      "Iteration 167200: Avg Loss =  0.32967\n",
      "Iteration 167300: Avg Loss =  0.34173\n",
      "Iteration 167400: Avg Loss =  0.34783\n",
      "Iteration 167500: Avg Loss =  0.36025\n",
      "Iteration 167600: Avg Loss =  0.36571\n",
      "Iteration 167700: Avg Loss =  0.32982\n",
      "Iteration 167800: Avg Loss =  0.35323\n",
      "Iteration 167900: Avg Loss =  0.34784\n",
      "Iteration 168000: Avg Loss =  0.34798\n",
      "Iteration 168100: Avg Loss =  0.35958\n",
      "Iteration 168200: Avg Loss =  0.35053\n",
      "Iteration 168300: Avg Loss =  0.34972\n",
      "Iteration 168400: Avg Loss =  0.30840\n",
      "Iteration 168500: Avg Loss =  0.35486\n",
      "Iteration 168600: Avg Loss =  0.32011\n",
      "Iteration 168700: Avg Loss =  0.36113\n",
      "Iteration 168800: Avg Loss =  0.35920\n",
      "Iteration 168900: Avg Loss =  0.34246\n",
      "Iteration 169000: Avg Loss =  0.35528\n",
      "Iteration 169100: Avg Loss =  0.32502\n",
      "Iteration 169200: Avg Loss =  0.34874\n",
      "Iteration 169300: Avg Loss =  0.35898\n",
      "Iteration 169400: Avg Loss =  0.35599\n",
      "Iteration 169500: Avg Loss =  0.34611\n",
      "Iteration 169600: Avg Loss =  0.34608\n",
      "Iteration 169700: Avg Loss =  0.39478\n",
      "Iteration 169800: Avg Loss =  0.31462\n",
      "Iteration 169900: Avg Loss =  0.37155\n",
      "Iteration 170000: Avg Loss =  0.29814\n",
      "Iteration 170100: Avg Loss =  0.31101\n",
      "Iteration 170200: Avg Loss =  0.37143\n",
      "Iteration 170300: Avg Loss =  0.34278\n",
      "Iteration 170400: Avg Loss =  0.34021\n",
      "Iteration 170500: Avg Loss =  0.33075\n",
      "Iteration 170600: Avg Loss =  0.36110\n",
      "Iteration 170700: Avg Loss =  0.32176\n",
      "Iteration 170800: Avg Loss =  0.30107\n",
      "Iteration 170900: Avg Loss =  0.37095\n",
      "Iteration 171000: Avg Loss =  0.36551\n",
      "Iteration 171100: Avg Loss =  0.32561\n",
      "Iteration 171200: Avg Loss =  0.36583\n",
      "Iteration 171300: Avg Loss =  0.37457\n",
      "Iteration 171400: Avg Loss =  0.37498\n",
      "Iteration 171500: Avg Loss =  0.34264\n",
      "Iteration 171600: Avg Loss =  0.37313\n",
      "Iteration 171700: Avg Loss =  0.36713\n",
      "Iteration 171800: Avg Loss =  0.35258\n",
      "Iteration 171900: Avg Loss =  0.36411\n",
      "Iteration 172000: Avg Loss =  0.34757\n",
      "Iteration 172100: Avg Loss =  0.35581\n",
      "Iteration 172200: Avg Loss =  0.35985\n",
      "Iteration 172300: Avg Loss =  0.31861\n",
      "Iteration 172400: Avg Loss =  0.32125\n",
      "Iteration 172500: Avg Loss =  0.39516\n",
      "Iteration 172600: Avg Loss =  0.35370\n",
      "Iteration 172700: Avg Loss =  0.35038\n",
      "Iteration 172800: Avg Loss =  0.33401\n",
      "Iteration 172900: Avg Loss =  0.35018\n",
      "Iteration 173000: Avg Loss =  0.37245\n",
      "Iteration 173100: Avg Loss =  0.31988\n",
      "Iteration 173200: Avg Loss =  0.38128\n",
      "Iteration 173300: Avg Loss =  0.34255\n",
      "Iteration 173400: Avg Loss =  0.32309\n",
      "Iteration 173500: Avg Loss =  0.33231\n",
      "Iteration 173600: Avg Loss =  0.35343\n",
      "Iteration 173700: Avg Loss =  0.34217\n",
      "Iteration 173800: Avg Loss =  0.31399\n",
      "Iteration 173900: Avg Loss =  0.32251\n",
      "Iteration 174000: Avg Loss =  0.42367\n",
      "Iteration 174100: Avg Loss =  0.32488\n",
      "Iteration 174200: Avg Loss =  0.34803\n",
      "Iteration 174300: Avg Loss =  0.33696\n",
      "Iteration 174400: Avg Loss =  0.35132\n",
      "Iteration 174500: Avg Loss =  0.30961\n",
      "Iteration 174600: Avg Loss =  0.33133\n",
      "Iteration 174700: Avg Loss =  0.34899\n",
      "Iteration 174800: Avg Loss =  0.35690\n",
      "Iteration 174900: Avg Loss =  0.31309\n",
      "Iteration 175000: Avg Loss =  0.34210\n",
      "Iteration 175100: Avg Loss =  0.33726\n",
      "Iteration 175200: Avg Loss =  0.39238\n",
      "Iteration 175300: Avg Loss =  0.36406\n",
      "Iteration 175400: Avg Loss =  0.33951\n",
      "Iteration 175500: Avg Loss =  0.32711\n",
      "Iteration 175600: Avg Loss =  0.33214\n",
      "Iteration 175700: Avg Loss =  0.29460\n",
      "Iteration 175800: Avg Loss =  0.32171\n",
      "Iteration 175900: Avg Loss =  0.32571\n",
      "Iteration 176000: Avg Loss =  0.36451\n",
      "Iteration 176100: Avg Loss =  0.30590\n",
      "Iteration 176200: Avg Loss =  0.31704\n",
      "Iteration 176300: Avg Loss =  0.34633\n",
      "Iteration 176400: Avg Loss =  0.31482\n",
      "Iteration 176500: Avg Loss =  0.34202\n",
      "Iteration 176600: Avg Loss =  0.30527\n",
      "Iteration 176700: Avg Loss =  0.37131\n",
      "Iteration 176800: Avg Loss =  0.35457\n",
      "Iteration 176900: Avg Loss =  0.38797\n",
      "Iteration 177000: Avg Loss =  0.35141\n",
      "Iteration 177100: Avg Loss =  0.36068\n",
      "Iteration 177200: Avg Loss =  0.37070\n",
      "Iteration 177300: Avg Loss =  0.34386\n",
      "Iteration 177400: Avg Loss =  0.32631\n",
      "Iteration 177500: Avg Loss =  0.38268\n",
      "Iteration 177600: Avg Loss =  0.31837\n",
      "Iteration 177700: Avg Loss =  0.33518\n",
      "Iteration 177800: Avg Loss =  0.29335\n",
      "Iteration 177900: Avg Loss =  0.28976\n",
      "Iteration 178000: Avg Loss =  0.34195\n",
      "Iteration 178100: Avg Loss =  0.36295\n",
      "Iteration 178200: Avg Loss =  0.32288\n",
      "Iteration 178300: Avg Loss =  0.33405\n",
      "Iteration 178400: Avg Loss =  0.32204\n",
      "Iteration 178500: Avg Loss =  0.35685\n",
      "Iteration 178600: Avg Loss =  0.34174\n",
      "Iteration 178700: Avg Loss =  0.35329\n",
      "Iteration 178800: Avg Loss =  0.35723\n",
      "Iteration 178900: Avg Loss =  0.30383\n",
      "Iteration 179000: Avg Loss =  0.34725\n",
      "Iteration 179100: Avg Loss =  0.35286\n",
      "Iteration 179200: Avg Loss =  0.32846\n",
      "Iteration 179300: Avg Loss =  0.30405\n",
      "Iteration 179400: Avg Loss =  0.35303\n",
      "Iteration 179500: Avg Loss =  0.32456\n",
      "Iteration 179600: Avg Loss =  0.34483\n",
      "Iteration 179700: Avg Loss =  0.36338\n",
      "Iteration 179800: Avg Loss =  0.33714\n",
      "Iteration 179900: Avg Loss =  0.35718\n",
      "Iteration 180000: Avg Loss =  0.34868\n",
      "Iteration 180100: Avg Loss =  0.33732\n",
      "Iteration 180200: Avg Loss =  0.39302\n",
      "Iteration 180300: Avg Loss =  0.33306\n",
      "Iteration 180400: Avg Loss =  0.35322\n",
      "Iteration 180500: Avg Loss =  0.32252\n",
      "Iteration 180600: Avg Loss =  0.34200\n",
      "Iteration 180700: Avg Loss =  0.33982\n",
      "Iteration 180800: Avg Loss =  0.37574\n",
      "Iteration 180900: Avg Loss =  0.31346\n",
      "Iteration 181000: Avg Loss =  0.29804\n",
      "Iteration 181100: Avg Loss =  0.34537\n",
      "Iteration 181200: Avg Loss =  0.36638\n",
      "Iteration 181300: Avg Loss =  0.31757\n",
      "Iteration 181400: Avg Loss =  0.31717\n",
      "Iteration 181500: Avg Loss =  0.35347\n",
      "Iteration 181600: Avg Loss =  0.35418\n",
      "Iteration 181700: Avg Loss =  0.37169\n",
      "Iteration 181800: Avg Loss =  0.34450\n",
      "Iteration 181900: Avg Loss =  0.32765\n",
      "Iteration 182000: Avg Loss =  0.33713\n",
      "Iteration 182100: Avg Loss =  0.33771\n",
      "Iteration 182200: Avg Loss =  0.34984\n",
      "Iteration 182300: Avg Loss =  0.34539\n",
      "Iteration 182400: Avg Loss =  0.35241\n",
      "Iteration 182500: Avg Loss =  0.35713\n",
      "Iteration 182600: Avg Loss =  0.36364\n",
      "Iteration 182700: Avg Loss =  0.34213\n",
      "Iteration 182800: Avg Loss =  0.37645\n",
      "Iteration 182900: Avg Loss =  0.33264\n",
      "Iteration 183000: Avg Loss =  0.36322\n",
      "Iteration 183100: Avg Loss =  0.31716\n",
      "Iteration 183200: Avg Loss =  0.31754\n",
      "Iteration 183300: Avg Loss =  0.32770\n",
      "Iteration 183400: Avg Loss =  0.31496\n",
      "Iteration 183500: Avg Loss =  0.35661\n",
      "Iteration 183600: Avg Loss =  0.36739\n",
      "Iteration 183700: Avg Loss =  0.34051\n",
      "Iteration 183800: Avg Loss =  0.34943\n",
      "Iteration 183900: Avg Loss =  0.33880\n",
      "Iteration 184000: Avg Loss =  0.29570\n",
      "Iteration 184100: Avg Loss =  0.31426\n",
      "Iteration 184200: Avg Loss =  0.34704\n",
      "Iteration 184300: Avg Loss =  0.34883\n",
      "Iteration 184400: Avg Loss =  0.35363\n",
      "Iteration 184500: Avg Loss =  0.33533\n",
      "Iteration 184600: Avg Loss =  0.35015\n",
      "Iteration 184700: Avg Loss =  0.34254\n",
      "Iteration 184800: Avg Loss =  0.33071\n",
      "Iteration 184900: Avg Loss =  0.32825\n",
      "Iteration 185000: Avg Loss =  0.34249\n",
      "Iteration 185100: Avg Loss =  0.34108\n",
      "Iteration 185200: Avg Loss =  0.37585\n",
      "Iteration 185300: Avg Loss =  0.34780\n",
      "Iteration 185400: Avg Loss =  0.32427\n",
      "Iteration 185500: Avg Loss =  0.34628\n",
      "Iteration 185600: Avg Loss =  0.31934\n",
      "Iteration 185700: Avg Loss =  0.29132\n",
      "Iteration 185800: Avg Loss =  0.31792\n",
      "Iteration 185900: Avg Loss =  0.33176\n",
      "Iteration 186000: Avg Loss =  0.33321\n",
      "Iteration 186100: Avg Loss =  0.32758\n",
      "Iteration 186200: Avg Loss =  0.30742\n",
      "Iteration 186300: Avg Loss =  0.31979\n",
      "Iteration 186400: Avg Loss =  0.32659\n",
      "Iteration 186500: Avg Loss =  0.32108\n",
      "Iteration 186600: Avg Loss =  0.32741\n",
      "Iteration 186700: Avg Loss =  0.40064\n",
      "Iteration 186800: Avg Loss =  0.32431\n",
      "Iteration 186900: Avg Loss =  0.33071\n",
      "Iteration 187000: Avg Loss =  0.36028\n",
      "Iteration 187100: Avg Loss =  0.34825\n",
      "Iteration 187200: Avg Loss =  0.32553\n",
      "Iteration 187300: Avg Loss =  0.34724\n",
      "Iteration 187400: Avg Loss =  0.33031\n",
      "Iteration 187500: Avg Loss =  0.33884\n",
      "Iteration 187600: Avg Loss =  0.32346\n",
      "Iteration 187700: Avg Loss =  0.32839\n",
      "Iteration 187800: Avg Loss =  0.37158\n",
      "Iteration 187900: Avg Loss =  0.31212\n",
      "Iteration 188000: Avg Loss =  0.31255\n",
      "Iteration 188100: Avg Loss =  0.30265\n",
      "Iteration 188200: Avg Loss =  0.30788\n",
      "Iteration 188300: Avg Loss =  0.35627\n",
      "Iteration 188400: Avg Loss =  0.32476\n",
      "Iteration 188500: Avg Loss =  0.29711\n",
      "Iteration 188600: Avg Loss =  0.36124\n",
      "Iteration 188700: Avg Loss =  0.31888\n",
      "Iteration 188800: Avg Loss =  0.33754\n",
      "Iteration 188900: Avg Loss =  0.37132\n",
      "Iteration 189000: Avg Loss =  0.34137\n",
      "Iteration 189100: Avg Loss =  0.31767\n",
      "Iteration 189200: Avg Loss =  0.32997\n",
      "Iteration 189300: Avg Loss =  0.37946\n",
      "Iteration 189400: Avg Loss =  0.34285\n",
      "Iteration 189500: Avg Loss =  0.35371\n",
      "Iteration 189600: Avg Loss =  0.34498\n",
      "Iteration 189700: Avg Loss =  0.34612\n",
      "Iteration 189800: Avg Loss =  0.30809\n",
      "Iteration 189900: Avg Loss =  0.34500\n",
      "Iteration 190000: Avg Loss =  0.35153\n",
      "Iteration 190100: Avg Loss =  0.34533\n",
      "Iteration 190200: Avg Loss =  0.33816\n",
      "Iteration 190300: Avg Loss =  0.33441\n",
      "Iteration 190400: Avg Loss =  0.36558\n",
      "Iteration 190500: Avg Loss =  0.34369\n",
      "Iteration 190600: Avg Loss =  0.31473\n",
      "Iteration 190700: Avg Loss =  0.35350\n",
      "Iteration 190800: Avg Loss =  0.30459\n",
      "Iteration 190900: Avg Loss =  0.33486\n",
      "Iteration 191000: Avg Loss =  0.36549\n",
      "Iteration 191100: Avg Loss =  0.36975\n",
      "Iteration 191200: Avg Loss =  0.32525\n",
      "Iteration 191300: Avg Loss =  0.33313\n",
      "Iteration 191400: Avg Loss =  0.33656\n",
      "Iteration 191500: Avg Loss =  0.33261\n",
      "Iteration 191600: Avg Loss =  0.34771\n",
      "Iteration 191700: Avg Loss =  0.32184\n",
      "Iteration 191800: Avg Loss =  0.34179\n",
      "Iteration 191900: Avg Loss =  0.31741\n",
      "Iteration 192000: Avg Loss =  0.33968\n",
      "Iteration 192100: Avg Loss =  0.32169\n",
      "Iteration 192200: Avg Loss =  0.32357\n",
      "Iteration 192300: Avg Loss =  0.32395\n",
      "Iteration 192400: Avg Loss =  0.35803\n",
      "Iteration 192500: Avg Loss =  0.35064\n",
      "Iteration 192600: Avg Loss =  0.32939\n",
      "Iteration 192700: Avg Loss =  0.33167\n",
      "Iteration 192800: Avg Loss =  0.32760\n",
      "Iteration 192900: Avg Loss =  0.32032\n",
      "Iteration 193000: Avg Loss =  0.32796\n",
      "Iteration 193100: Avg Loss =  0.29206\n",
      "Iteration 193200: Avg Loss =  0.31678\n",
      "Iteration 193300: Avg Loss =  0.26944\n",
      "Iteration 193400: Avg Loss =  0.31673\n",
      "Iteration 193500: Avg Loss =  0.32133\n",
      "Iteration 193600: Avg Loss =  0.35170\n",
      "Iteration 193700: Avg Loss =  0.32459\n",
      "Iteration 193800: Avg Loss =  0.33365\n",
      "Iteration 193900: Avg Loss =  0.33676\n",
      "Iteration 194000: Avg Loss =  0.35312\n",
      "Iteration 194100: Avg Loss =  0.28895\n",
      "Iteration 194200: Avg Loss =  0.35476\n",
      "Iteration 194300: Avg Loss =  0.32898\n",
      "Iteration 194400: Avg Loss =  0.34121\n",
      "Iteration 194500: Avg Loss =  0.34190\n",
      "Iteration 194600: Avg Loss =  0.36850\n",
      "Iteration 194700: Avg Loss =  0.30893\n",
      "Iteration 194800: Avg Loss =  0.35094\n",
      "Iteration 194900: Avg Loss =  0.36010\n",
      "Iteration 195000: Avg Loss =  0.35030\n",
      "Iteration 195100: Avg Loss =  0.35122\n",
      "Iteration 195200: Avg Loss =  0.38310\n",
      "Iteration 195300: Avg Loss =  0.38800\n",
      "Iteration 195400: Avg Loss =  0.34268\n",
      "Iteration 195500: Avg Loss =  0.31558\n",
      "Iteration 195600: Avg Loss =  0.32313\n",
      "Iteration 195700: Avg Loss =  0.33893\n",
      "Iteration 195800: Avg Loss =  0.31985\n",
      "Iteration 195900: Avg Loss =  0.37523\n",
      "Iteration 196000: Avg Loss =  0.32729\n",
      "Iteration 196100: Avg Loss =  0.32870\n",
      "Iteration 196200: Avg Loss =  0.35201\n",
      "Iteration 196300: Avg Loss =  0.31990\n",
      "Iteration 196400: Avg Loss =  0.29631\n",
      "Iteration 196500: Avg Loss =  0.30460\n",
      "Iteration 196600: Avg Loss =  0.28954\n",
      "Iteration 196700: Avg Loss =  0.33561\n",
      "Iteration 196800: Avg Loss =  0.28849\n",
      "Iteration 196900: Avg Loss =  0.34972\n",
      "Iteration 197000: Avg Loss =  0.31947\n",
      "Iteration 197100: Avg Loss =  0.32555\n",
      "Iteration 197200: Avg Loss =  0.31404\n",
      "Iteration 197300: Avg Loss =  0.30468\n",
      "Iteration 197400: Avg Loss =  0.29420\n",
      "Iteration 197500: Avg Loss =  0.29201\n",
      "Iteration 197600: Avg Loss =  0.29460\n",
      "Iteration 197700: Avg Loss =  0.37530\n",
      "Iteration 197800: Avg Loss =  0.30464\n",
      "Iteration 197900: Avg Loss =  0.34799\n",
      "Iteration 198000: Avg Loss =  0.36411\n",
      "Iteration 198100: Avg Loss =  0.33881\n",
      "Iteration 198200: Avg Loss =  0.36940\n",
      "Iteration 198300: Avg Loss =  0.33822\n",
      "Iteration 198400: Avg Loss =  0.30384\n",
      "Iteration 198500: Avg Loss =  0.28619\n",
      "Iteration 198600: Avg Loss =  0.31667\n",
      "Iteration 198700: Avg Loss =  0.30258\n",
      "Iteration 198800: Avg Loss =  0.37754\n",
      "Iteration 198900: Avg Loss =  0.32504\n",
      "Iteration 199000: Avg Loss =  0.30177\n",
      "Iteration 199100: Avg Loss =  0.34197\n",
      "Iteration 199200: Avg Loss =  0.36797\n",
      "Iteration 199300: Avg Loss =  0.34872\n",
      "Iteration 199400: Avg Loss =  0.36372\n",
      "Iteration 199500: Avg Loss =  0.34286\n",
      "Iteration 199600: Avg Loss =  0.31084\n",
      "Iteration 199700: Avg Loss =  0.29424\n",
      "Iteration 199800: Avg Loss =  0.34483\n",
      "Iteration 199900: Avg Loss =  0.33817\n",
      "Iteration 200000: Avg Loss =  0.29150\n",
      "Iteration 200100: Avg Loss =  0.30929\n",
      "Iteration 200200: Avg Loss =  0.41313\n",
      "Iteration 200300: Avg Loss =  0.31459\n",
      "Iteration 200400: Avg Loss =  0.35019\n",
      "Iteration 200500: Avg Loss =  0.33501\n",
      "Iteration 200600: Avg Loss =  0.30417\n",
      "Iteration 200700: Avg Loss =  0.36525\n",
      "Iteration 200800: Avg Loss =  0.30735\n",
      "Iteration 200900: Avg Loss =  0.36413\n",
      "Iteration 201000: Avg Loss =  0.35205\n",
      "Iteration 201100: Avg Loss =  0.35587\n",
      "Iteration 201200: Avg Loss =  0.31825\n",
      "Iteration 201300: Avg Loss =  0.31892\n",
      "Iteration 201400: Avg Loss =  0.36461\n",
      "Iteration 201500: Avg Loss =  0.32592\n",
      "Iteration 201600: Avg Loss =  0.30314\n",
      "Iteration 201700: Avg Loss =  0.32190\n",
      "Iteration 201800: Avg Loss =  0.34671\n",
      "Iteration 201900: Avg Loss =  0.31082\n",
      "Iteration 202000: Avg Loss =  0.28159\n",
      "Iteration 202100: Avg Loss =  0.34429\n",
      "Iteration 202200: Avg Loss =  0.34079\n",
      "Iteration 202300: Avg Loss =  0.29599\n",
      "Iteration 202400: Avg Loss =  0.31659\n",
      "Iteration 202500: Avg Loss =  0.36206\n",
      "Iteration 202600: Avg Loss =  0.30873\n",
      "Iteration 202700: Avg Loss =  0.31680\n",
      "Iteration 202800: Avg Loss =  0.35219\n",
      "Iteration 202900: Avg Loss =  0.31208\n",
      "Iteration 203000: Avg Loss =  0.31392\n",
      "Iteration 203100: Avg Loss =  0.33281\n",
      "Iteration 203200: Avg Loss =  0.34258\n",
      "Iteration 203300: Avg Loss =  0.27880\n",
      "Iteration 203400: Avg Loss =  0.31306\n",
      "Iteration 203500: Avg Loss =  0.29170\n",
      "Iteration 203600: Avg Loss =  0.30514\n",
      "Iteration 203700: Avg Loss =  0.29570\n",
      "Iteration 203800: Avg Loss =  0.31616\n",
      "Iteration 203900: Avg Loss =  0.31473\n",
      "Iteration 204000: Avg Loss =  0.30257\n",
      "Iteration 204100: Avg Loss =  0.31257\n",
      "Iteration 204200: Avg Loss =  0.31569\n",
      "Iteration 204300: Avg Loss =  0.31471\n",
      "Iteration 204400: Avg Loss =  0.31598\n",
      "Iteration 204500: Avg Loss =  0.31314\n",
      "Iteration 204600: Avg Loss =  0.34717\n",
      "Iteration 204700: Avg Loss =  0.31548\n",
      "Iteration 204800: Avg Loss =  0.35241\n",
      "Iteration 204900: Avg Loss =  0.36458\n",
      "Iteration 205000: Avg Loss =  0.30568\n",
      "Iteration 205100: Avg Loss =  0.33678\n",
      "Iteration 205200: Avg Loss =  0.30843\n",
      "Iteration 205300: Avg Loss =  0.30277\n",
      "Iteration 205400: Avg Loss =  0.35534\n",
      "Iteration 205500: Avg Loss =  0.34598\n",
      "Iteration 205600: Avg Loss =  0.29733\n",
      "Iteration 205700: Avg Loss =  0.33171\n",
      "Iteration 205800: Avg Loss =  0.26292\n",
      "Iteration 205900: Avg Loss =  0.31401\n",
      "Iteration 206000: Avg Loss =  0.32538\n",
      "Iteration 206100: Avg Loss =  0.32225\n",
      "Iteration 206200: Avg Loss =  0.28780\n",
      "Iteration 206300: Avg Loss =  0.32161\n",
      "Iteration 206400: Avg Loss =  0.31895\n",
      "Iteration 206500: Avg Loss =  0.30195\n",
      "Iteration 206600: Avg Loss =  0.35624\n",
      "Iteration 206700: Avg Loss =  0.30137\n",
      "Iteration 206800: Avg Loss =  0.31646\n",
      "Iteration 206900: Avg Loss =  0.30039\n",
      "Iteration 207000: Avg Loss =  0.31561\n",
      "Iteration 207100: Avg Loss =  0.30812\n",
      "Iteration 207200: Avg Loss =  0.29184\n",
      "Iteration 207300: Avg Loss =  0.34245\n",
      "Iteration 207400: Avg Loss =  0.29209\n",
      "Iteration 207500: Avg Loss =  0.31482\n",
      "Iteration 207600: Avg Loss =  0.31402\n",
      "Iteration 207700: Avg Loss =  0.32616\n",
      "Iteration 207800: Avg Loss =  0.30452\n",
      "Iteration 207900: Avg Loss =  0.30568\n",
      "Iteration 208000: Avg Loss =  0.34762\n",
      "Iteration 208100: Avg Loss =  0.33203\n",
      "Iteration 208200: Avg Loss =  0.32648\n",
      "Iteration 208300: Avg Loss =  0.28789\n",
      "Iteration 208400: Avg Loss =  0.33395\n",
      "Iteration 208500: Avg Loss =  0.32122\n",
      "Iteration 208600: Avg Loss =  0.31259\n",
      "Iteration 208700: Avg Loss =  0.32560\n",
      "Iteration 208800: Avg Loss =  0.28159\n",
      "Iteration 208900: Avg Loss =  0.32389\n",
      "Iteration 209000: Avg Loss =  0.35074\n",
      "Iteration 209100: Avg Loss =  0.33736\n",
      "Iteration 209200: Avg Loss =  0.37304\n",
      "Iteration 209300: Avg Loss =  0.29451\n",
      "Iteration 209400: Avg Loss =  0.31549\n",
      "Iteration 209500: Avg Loss =  0.34288\n",
      "Iteration 209600: Avg Loss =  0.30419\n",
      "Iteration 209700: Avg Loss =  0.36208\n",
      "Iteration 209800: Avg Loss =  0.32332\n",
      "Iteration 209900: Avg Loss =  0.31325\n",
      "Iteration 210000: Avg Loss =  0.32757\n",
      "Iteration 210100: Avg Loss =  0.31113\n",
      "Iteration 210200: Avg Loss =  0.30853\n",
      "Iteration 210300: Avg Loss =  0.31437\n",
      "Iteration 210400: Avg Loss =  0.35723\n",
      "Iteration 210500: Avg Loss =  0.33795\n",
      "Iteration 210600: Avg Loss =  0.29318\n",
      "Iteration 210700: Avg Loss =  0.32377\n",
      "Iteration 210800: Avg Loss =  0.31625\n",
      "Iteration 210900: Avg Loss =  0.33840\n",
      "Iteration 211000: Avg Loss =  0.32755\n",
      "Iteration 211100: Avg Loss =  0.29150\n",
      "Iteration 211200: Avg Loss =  0.28821\n",
      "Iteration 211300: Avg Loss =  0.29901\n",
      "Iteration 211400: Avg Loss =  0.31543\n",
      "Iteration 211500: Avg Loss =  0.29269\n",
      "Iteration 211600: Avg Loss =  0.32013\n",
      "Iteration 211700: Avg Loss =  0.33025\n",
      "Iteration 211800: Avg Loss =  0.33624\n",
      "Iteration 211900: Avg Loss =  0.31955\n",
      "Iteration 212000: Avg Loss =  0.32043\n",
      "Iteration 212100: Avg Loss =  0.31971\n",
      "Iteration 212200: Avg Loss =  0.31471\n",
      "Iteration 212300: Avg Loss =  0.33481\n",
      "Iteration 212400: Avg Loss =  0.32354\n",
      "Iteration 212500: Avg Loss =  0.30083\n",
      "Iteration 212600: Avg Loss =  0.32442\n",
      "Iteration 212700: Avg Loss =  0.31732\n",
      "Iteration 212800: Avg Loss =  0.30146\n",
      "Iteration 212900: Avg Loss =  0.28221\n",
      "Iteration 213000: Avg Loss =  0.31614\n",
      "Iteration 213100: Avg Loss =  0.28901\n",
      "Iteration 213200: Avg Loss =  0.29579\n",
      "Iteration 213300: Avg Loss =  0.32514\n",
      "Iteration 213400: Avg Loss =  0.28911\n",
      "Iteration 213500: Avg Loss =  0.32982\n",
      "Iteration 213600: Avg Loss =  0.30929\n",
      "Iteration 213700: Avg Loss =  0.29106\n",
      "Iteration 213800: Avg Loss =  0.33892\n",
      "Iteration 213900: Avg Loss =  0.30771\n",
      "Iteration 214000: Avg Loss =  0.29688\n",
      "Iteration 214100: Avg Loss =  0.32964\n",
      "Iteration 214200: Avg Loss =  0.30205\n",
      "Iteration 214300: Avg Loss =  0.34463\n",
      "Iteration 214400: Avg Loss =  0.28234\n",
      "Iteration 214500: Avg Loss =  0.32959\n",
      "Iteration 214600: Avg Loss =  0.31630\n",
      "Iteration 214700: Avg Loss =  0.32940\n",
      "Iteration 214800: Avg Loss =  0.32747\n",
      "Iteration 214900: Avg Loss =  0.34041\n",
      "Iteration 215000: Avg Loss =  0.34082\n",
      "Iteration 215100: Avg Loss =  0.32065\n",
      "Iteration 215200: Avg Loss =  0.31364\n",
      "Iteration 215300: Avg Loss =  0.34869\n",
      "Iteration 215400: Avg Loss =  0.30873\n",
      "Iteration 215500: Avg Loss =  0.30359\n",
      "Iteration 215600: Avg Loss =  0.31399\n",
      "Iteration 215700: Avg Loss =  0.33797\n",
      "Iteration 215800: Avg Loss =  0.30266\n",
      "Iteration 215900: Avg Loss =  0.28323\n",
      "Iteration 216000: Avg Loss =  0.33896\n",
      "Iteration 216100: Avg Loss =  0.32546\n",
      "Iteration 216200: Avg Loss =  0.28588\n",
      "Iteration 216300: Avg Loss =  0.34101\n",
      "Iteration 216400: Avg Loss =  0.31637\n",
      "Iteration 216500: Avg Loss =  0.29791\n",
      "Iteration 216600: Avg Loss =  0.34995\n",
      "Iteration 216700: Avg Loss =  0.28504\n",
      "Iteration 216800: Avg Loss =  0.30327\n",
      "Iteration 216900: Avg Loss =  0.30084\n",
      "Iteration 217000: Avg Loss =  0.32305\n",
      "Iteration 217100: Avg Loss =  0.31221\n",
      "Iteration 217200: Avg Loss =  0.33839\n",
      "Iteration 217300: Avg Loss =  0.32838\n",
      "Iteration 217400: Avg Loss =  0.30824\n",
      "Iteration 217500: Avg Loss =  0.32259\n",
      "Iteration 217600: Avg Loss =  0.30628\n",
      "Iteration 217700: Avg Loss =  0.28344\n",
      "Iteration 217800: Avg Loss =  0.37746\n",
      "Iteration 217900: Avg Loss =  0.34284\n",
      "Iteration 218000: Avg Loss =  0.34444\n",
      "Iteration 218100: Avg Loss =  0.31578\n",
      "Iteration 218200: Avg Loss =  0.30279\n",
      "Iteration 218300: Avg Loss =  0.32572\n",
      "Iteration 218400: Avg Loss =  0.34201\n",
      "Iteration 218500: Avg Loss =  0.31471\n",
      "Iteration 218600: Avg Loss =  0.33019\n",
      "Iteration 218700: Avg Loss =  0.28699\n",
      "Iteration 218800: Avg Loss =  0.31429\n",
      "Iteration 218900: Avg Loss =  0.34409\n",
      "Iteration 219000: Avg Loss =  0.29936\n",
      "Iteration 219100: Avg Loss =  0.33198\n",
      "Iteration 219200: Avg Loss =  0.33597\n",
      "Iteration 219300: Avg Loss =  0.29006\n",
      "Iteration 219400: Avg Loss =  0.32845\n",
      "Iteration 219500: Avg Loss =  0.33583\n",
      "Iteration 219600: Avg Loss =  0.32515\n",
      "Iteration 219700: Avg Loss =  0.36503\n",
      "Iteration 219800: Avg Loss =  0.31133\n",
      "Iteration 219900: Avg Loss =  0.38875\n",
      "Iteration 220000: Avg Loss =  0.32335\n",
      "Iteration 220100: Avg Loss =  0.34801\n",
      "Iteration 220200: Avg Loss =  0.34932\n",
      "Iteration 220300: Avg Loss =  0.31817\n",
      "Iteration 220400: Avg Loss =  0.36391\n",
      "Iteration 220500: Avg Loss =  0.33176\n",
      "Iteration 220600: Avg Loss =  0.30465\n",
      "Iteration 220700: Avg Loss =  0.36447\n",
      "Iteration 220800: Avg Loss =  0.28232\n",
      "Iteration 220900: Avg Loss =  0.30418\n",
      "Iteration 221000: Avg Loss =  0.35412\n",
      "Iteration 221100: Avg Loss =  0.34220\n",
      "Iteration 221200: Avg Loss =  0.30641\n",
      "Iteration 221300: Avg Loss =  0.32959\n",
      "Iteration 221400: Avg Loss =  0.35318\n",
      "Iteration 221500: Avg Loss =  0.29234\n",
      "Iteration 221600: Avg Loss =  0.32052\n",
      "Iteration 221700: Avg Loss =  0.31581\n",
      "Iteration 221800: Avg Loss =  0.29975\n",
      "Iteration 221900: Avg Loss =  0.34436\n",
      "Iteration 222000: Avg Loss =  0.31791\n",
      "Iteration 222100: Avg Loss =  0.35265\n",
      "Iteration 222200: Avg Loss =  0.29404\n",
      "Iteration 222300: Avg Loss =  0.31548\n",
      "Iteration 222400: Avg Loss =  0.32937\n",
      "Iteration 222500: Avg Loss =  0.30774\n",
      "Iteration 222600: Avg Loss =  0.32790\n",
      "Iteration 222700: Avg Loss =  0.29500\n",
      "Iteration 222800: Avg Loss =  0.31893\n",
      "Iteration 222900: Avg Loss =  0.31836\n",
      "Iteration 223000: Avg Loss =  0.36225\n",
      "Iteration 223100: Avg Loss =  0.37410\n",
      "Iteration 223200: Avg Loss =  0.30229\n",
      "Iteration 223300: Avg Loss =  0.34316\n",
      "Iteration 223400: Avg Loss =  0.34716\n",
      "Iteration 223500: Avg Loss =  0.33180\n",
      "Iteration 223600: Avg Loss =  0.32334\n",
      "Iteration 223700: Avg Loss =  0.33457\n",
      "Iteration 223800: Avg Loss =  0.34284\n",
      "Iteration 223900: Avg Loss =  0.32689\n",
      "Iteration 224000: Avg Loss =  0.29744\n",
      "Iteration 224100: Avg Loss =  0.30224\n",
      "Iteration 224200: Avg Loss =  0.32320\n",
      "Iteration 224300: Avg Loss =  0.30926\n",
      "Iteration 224400: Avg Loss =  0.34285\n",
      "Iteration 224500: Avg Loss =  0.32232\n",
      "Iteration 224600: Avg Loss =  0.32263\n",
      "Iteration 224700: Avg Loss =  0.35481\n",
      "Iteration 224800: Avg Loss =  0.28692\n",
      "Iteration 224900: Avg Loss =  0.32687\n",
      "Iteration 225000: Avg Loss =  0.33567\n",
      "Iteration 225100: Avg Loss =  0.34510\n",
      "Iteration 225200: Avg Loss =  0.34057\n",
      "Iteration 225300: Avg Loss =  0.30273\n",
      "Iteration 225400: Avg Loss =  0.27874\n",
      "Iteration 225500: Avg Loss =  0.29217\n",
      "Iteration 225600: Avg Loss =  0.30346\n",
      "Iteration 225700: Avg Loss =  0.29951\n",
      "Iteration 225800: Avg Loss =  0.30605\n",
      "Iteration 225900: Avg Loss =  0.27929\n",
      "Iteration 226000: Avg Loss =  0.34423\n",
      "Iteration 226100: Avg Loss =  0.31188\n",
      "Iteration 226200: Avg Loss =  0.27002\n",
      "Iteration 226300: Avg Loss =  0.31285\n",
      "Iteration 226400: Avg Loss =  0.31741\n",
      "Iteration 226500: Avg Loss =  0.36181\n",
      "Iteration 226600: Avg Loss =  0.30831\n",
      "Iteration 226700: Avg Loss =  0.32326\n",
      "Iteration 226800: Avg Loss =  0.33756\n",
      "Iteration 226900: Avg Loss =  0.35235\n",
      "Iteration 227000: Avg Loss =  0.31675\n",
      "Iteration 227100: Avg Loss =  0.33096\n",
      "Iteration 227200: Avg Loss =  0.33522\n",
      "Iteration 227300: Avg Loss =  0.27153\n",
      "Iteration 227400: Avg Loss =  0.28631\n",
      "Iteration 227500: Avg Loss =  0.30752\n",
      "Iteration 227600: Avg Loss =  0.31666\n",
      "Iteration 227700: Avg Loss =  0.28409\n",
      "Iteration 227800: Avg Loss =  0.31500\n",
      "Iteration 227900: Avg Loss =  0.28797\n",
      "Iteration 228000: Avg Loss =  0.34203\n",
      "Iteration 228100: Avg Loss =  0.29368\n",
      "Iteration 228200: Avg Loss =  0.34063\n",
      "Iteration 228300: Avg Loss =  0.27293\n",
      "Iteration 228400: Avg Loss =  0.31721\n",
      "Iteration 228500: Avg Loss =  0.29837\n",
      "Iteration 228600: Avg Loss =  0.31425\n",
      "Iteration 228700: Avg Loss =  0.27704\n",
      "Iteration 228800: Avg Loss =  0.31208\n",
      "Iteration 228900: Avg Loss =  0.29637\n",
      "Iteration 229000: Avg Loss =  0.31590\n",
      "Iteration 229100: Avg Loss =  0.34635\n",
      "Iteration 229200: Avg Loss =  0.27088\n",
      "Iteration 229300: Avg Loss =  0.31103\n",
      "Iteration 229400: Avg Loss =  0.30285\n",
      "Iteration 229500: Avg Loss =  0.30424\n",
      "Iteration 229600: Avg Loss =  0.32414\n",
      "Iteration 229700: Avg Loss =  0.33708\n",
      "Iteration 229800: Avg Loss =  0.32320\n",
      "Iteration 229900: Avg Loss =  0.34672\n",
      "Iteration 230000: Avg Loss =  0.30257\n",
      "Iteration 230100: Avg Loss =  0.33042\n",
      "Iteration 230200: Avg Loss =  0.30911\n",
      "Iteration 230300: Avg Loss =  0.30206\n",
      "Iteration 230400: Avg Loss =  0.34235\n",
      "Iteration 230500: Avg Loss =  0.32422\n",
      "Iteration 230600: Avg Loss =  0.32458\n",
      "Iteration 230700: Avg Loss =  0.31272\n",
      "Iteration 230800: Avg Loss =  0.30655\n",
      "Iteration 230900: Avg Loss =  0.31801\n",
      "Iteration 231000: Avg Loss =  0.31767\n",
      "Iteration 231100: Avg Loss =  0.29261\n",
      "Iteration 231200: Avg Loss =  0.32841\n",
      "Iteration 231300: Avg Loss =  0.31559\n",
      "Iteration 231400: Avg Loss =  0.29859\n",
      "Iteration 231500: Avg Loss =  0.35188\n",
      "Iteration 231600: Avg Loss =  0.33277\n",
      "Iteration 231700: Avg Loss =  0.25561\n",
      "Iteration 231800: Avg Loss =  0.28878\n",
      "Iteration 231900: Avg Loss =  0.31701\n",
      "Iteration 232000: Avg Loss =  0.32440\n",
      "Iteration 232100: Avg Loss =  0.33489\n",
      "Iteration 232200: Avg Loss =  0.33067\n",
      "Iteration 232300: Avg Loss =  0.29058\n",
      "Iteration 232400: Avg Loss =  0.33249\n",
      "Iteration 232500: Avg Loss =  0.33865\n",
      "Iteration 232600: Avg Loss =  0.31619\n",
      "Iteration 232700: Avg Loss =  0.33814\n",
      "Iteration 232800: Avg Loss =  0.30688\n",
      "Iteration 232900: Avg Loss =  0.30391\n",
      "Iteration 233000: Avg Loss =  0.35719\n",
      "Iteration 233100: Avg Loss =  0.31925\n",
      "Iteration 233200: Avg Loss =  0.29452\n",
      "Iteration 233300: Avg Loss =  0.32747\n",
      "Iteration 233400: Avg Loss =  0.32522\n",
      "Iteration 233500: Avg Loss =  0.30445\n",
      "Iteration 233600: Avg Loss =  0.33902\n",
      "Iteration 233700: Avg Loss =  0.36095\n",
      "Iteration 233800: Avg Loss =  0.34052\n",
      "Iteration 233900: Avg Loss =  0.31247\n",
      "Iteration 234000: Avg Loss =  0.28704\n",
      "Iteration 234100: Avg Loss =  0.29421\n",
      "Iteration 234200: Avg Loss =  0.30979\n",
      "Iteration 234300: Avg Loss =  0.34896\n",
      "Iteration 234400: Avg Loss =  0.33490\n",
      "Iteration 234500: Avg Loss =  0.30316\n",
      "Iteration 234600: Avg Loss =  0.32582\n",
      "Iteration 234700: Avg Loss =  0.30848\n",
      "Iteration 234800: Avg Loss =  0.30561\n",
      "Iteration 234900: Avg Loss =  0.31833\n",
      "Iteration 235000: Avg Loss =  0.30505\n",
      "Iteration 235100: Avg Loss =  0.33599\n",
      "Iteration 235200: Avg Loss =  0.30275\n",
      "Iteration 235300: Avg Loss =  0.26711\n",
      "Iteration 235400: Avg Loss =  0.30179\n",
      "Iteration 235500: Avg Loss =  0.33407\n",
      "Iteration 235600: Avg Loss =  0.31154\n",
      "Iteration 235700: Avg Loss =  0.30957\n",
      "Iteration 235800: Avg Loss =  0.31568\n",
      "Iteration 235900: Avg Loss =  0.30192\n",
      "Iteration 236000: Avg Loss =  0.29832\n",
      "Iteration 236100: Avg Loss =  0.34938\n",
      "Iteration 236200: Avg Loss =  0.33835\n",
      "Iteration 236300: Avg Loss =  0.31251\n",
      "Iteration 236400: Avg Loss =  0.33077\n",
      "Iteration 236500: Avg Loss =  0.31583\n",
      "Iteration 236600: Avg Loss =  0.29760\n",
      "Iteration 236700: Avg Loss =  0.30382\n",
      "Iteration 236800: Avg Loss =  0.33093\n",
      "Iteration 236900: Avg Loss =  0.32341\n",
      "Iteration 237000: Avg Loss =  0.30266\n",
      "Iteration 237100: Avg Loss =  0.30602\n",
      "Iteration 237200: Avg Loss =  0.30565\n",
      "Iteration 237300: Avg Loss =  0.31071\n",
      "Iteration 237400: Avg Loss =  0.30986\n",
      "Iteration 237500: Avg Loss =  0.30454\n",
      "Iteration 237600: Avg Loss =  0.31756\n",
      "Iteration 237700: Avg Loss =  0.31865\n",
      "Iteration 237800: Avg Loss =  0.32244\n",
      "Iteration 237900: Avg Loss =  0.30071\n",
      "Iteration 238000: Avg Loss =  0.24667\n",
      "Iteration 238100: Avg Loss =  0.32727\n",
      "Iteration 238200: Avg Loss =  0.31566\n",
      "Iteration 238300: Avg Loss =  0.31135\n",
      "Iteration 238400: Avg Loss =  0.32934\n",
      "Iteration 238500: Avg Loss =  0.29970\n",
      "Iteration 238600: Avg Loss =  0.31560\n",
      "Iteration 238700: Avg Loss =  0.31671\n",
      "Iteration 238800: Avg Loss =  0.32687\n",
      "Iteration 238900: Avg Loss =  0.29793\n",
      "Iteration 239000: Avg Loss =  0.34484\n",
      "Iteration 239100: Avg Loss =  0.32704\n",
      "Iteration 239200: Avg Loss =  0.30210\n",
      "Iteration 239300: Avg Loss =  0.29027\n",
      "Iteration 239400: Avg Loss =  0.33386\n",
      "Iteration 239500: Avg Loss =  0.32581\n",
      "Iteration 239600: Avg Loss =  0.29951\n",
      "Iteration 239700: Avg Loss =  0.30425\n",
      "Iteration 239800: Avg Loss =  0.35229\n",
      "Iteration 239900: Avg Loss =  0.31998\n",
      "Iteration 240000: Avg Loss =  0.32206\n",
      "Iteration 240100: Avg Loss =  0.29334\n",
      "Iteration 240200: Avg Loss =  0.29592\n",
      "Iteration 240300: Avg Loss =  0.30958\n",
      "Iteration 240400: Avg Loss =  0.27777\n",
      "Iteration 240500: Avg Loss =  0.29758\n",
      "Iteration 240600: Avg Loss =  0.33308\n",
      "Iteration 240700: Avg Loss =  0.34026\n",
      "Iteration 240800: Avg Loss =  0.30450\n",
      "Iteration 240900: Avg Loss =  0.31060\n",
      "Iteration 241000: Avg Loss =  0.28455\n",
      "Iteration 241100: Avg Loss =  0.33418\n",
      "Iteration 241200: Avg Loss =  0.32861\n",
      "Iteration 241300: Avg Loss =  0.32131\n",
      "Iteration 241400: Avg Loss =  0.28208\n",
      "Iteration 241500: Avg Loss =  0.29038\n",
      "Iteration 241600: Avg Loss =  0.31951\n",
      "Iteration 241700: Avg Loss =  0.34414\n",
      "Iteration 241800: Avg Loss =  0.30099\n",
      "Iteration 241900: Avg Loss =  0.29424\n",
      "Iteration 242000: Avg Loss =  0.30738\n",
      "Iteration 242100: Avg Loss =  0.30447\n",
      "Iteration 242200: Avg Loss =  0.30506\n",
      "Iteration 242300: Avg Loss =  0.34573\n",
      "Iteration 242400: Avg Loss =  0.33376\n",
      "Iteration 242500: Avg Loss =  0.27366\n",
      "Iteration 242600: Avg Loss =  0.32530\n",
      "Iteration 242700: Avg Loss =  0.32852\n",
      "Iteration 242800: Avg Loss =  0.27972\n",
      "Iteration 242900: Avg Loss =  0.28058\n",
      "Iteration 243000: Avg Loss =  0.32241\n",
      "Iteration 243100: Avg Loss =  0.31237\n",
      "Iteration 243200: Avg Loss =  0.34123\n",
      "Iteration 243300: Avg Loss =  0.29905\n",
      "Iteration 243400: Avg Loss =  0.29880\n",
      "Iteration 243500: Avg Loss =  0.29095\n",
      "Iteration 243600: Avg Loss =  0.32870\n",
      "Iteration 243700: Avg Loss =  0.31906\n",
      "Iteration 243800: Avg Loss =  0.30191\n",
      "Iteration 243900: Avg Loss =  0.29887\n",
      "Iteration 244000: Avg Loss =  0.28804\n",
      "Iteration 244100: Avg Loss =  0.28211\n",
      "Iteration 244200: Avg Loss =  0.28959\n",
      "Iteration 244300: Avg Loss =  0.27816\n",
      "Iteration 244400: Avg Loss =  0.30612\n",
      "Iteration 244500: Avg Loss =  0.30807\n",
      "Iteration 244600: Avg Loss =  0.32579\n",
      "Iteration 244700: Avg Loss =  0.28471\n",
      "Iteration 244800: Avg Loss =  0.32922\n",
      "Iteration 244900: Avg Loss =  0.29840\n",
      "Iteration 245000: Avg Loss =  0.36148\n",
      "Iteration 245100: Avg Loss =  0.35602\n",
      "Iteration 245200: Avg Loss =  0.31491\n",
      "Iteration 245300: Avg Loss =  0.31440\n",
      "Iteration 245400: Avg Loss =  0.28777\n",
      "Iteration 245500: Avg Loss =  0.33418\n",
      "Iteration 245600: Avg Loss =  0.30908\n",
      "Iteration 245700: Avg Loss =  0.29918\n",
      "Iteration 245800: Avg Loss =  0.26026\n",
      "Iteration 245900: Avg Loss =  0.31222\n",
      "Iteration 246000: Avg Loss =  0.31306\n",
      "Iteration 246100: Avg Loss =  0.30171\n",
      "Iteration 246200: Avg Loss =  0.29413\n",
      "Iteration 246300: Avg Loss =  0.29127\n",
      "Iteration 246400: Avg Loss =  0.29738\n",
      "Iteration 246500: Avg Loss =  0.29431\n",
      "Iteration 246600: Avg Loss =  0.30257\n",
      "Iteration 246700: Avg Loss =  0.32737\n",
      "Iteration 246800: Avg Loss =  0.28455\n",
      "Iteration 246900: Avg Loss =  0.28716\n",
      "Iteration 247000: Avg Loss =  0.29467\n",
      "Iteration 247100: Avg Loss =  0.30568\n",
      "Iteration 247200: Avg Loss =  0.31280\n",
      "Iteration 247300: Avg Loss =  0.31403\n",
      "Iteration 247400: Avg Loss =  0.28438\n",
      "Iteration 247500: Avg Loss =  0.30132\n",
      "Iteration 247600: Avg Loss =  0.28572\n",
      "Iteration 247700: Avg Loss =  0.29348\n",
      "Iteration 247800: Avg Loss =  0.31620\n",
      "Iteration 247900: Avg Loss =  0.30285\n",
      "Iteration 248000: Avg Loss =  0.30425\n",
      "Iteration 248100: Avg Loss =  0.27858\n",
      "Iteration 248200: Avg Loss =  0.27418\n",
      "Iteration 248300: Avg Loss =  0.31707\n",
      "Iteration 248400: Avg Loss =  0.34026\n",
      "Iteration 248500: Avg Loss =  0.29830\n",
      "Iteration 248600: Avg Loss =  0.30040\n",
      "Iteration 248700: Avg Loss =  0.33444\n",
      "Iteration 248800: Avg Loss =  0.28528\n",
      "Iteration 248900: Avg Loss =  0.31083\n",
      "Iteration 249000: Avg Loss =  0.31456\n",
      "Iteration 249100: Avg Loss =  0.32260\n",
      "Iteration 249200: Avg Loss =  0.29221\n",
      "Iteration 249300: Avg Loss =  0.29007\n",
      "Iteration 249400: Avg Loss =  0.27035\n",
      "Iteration 249500: Avg Loss =  0.30733\n",
      "Iteration 249600: Avg Loss =  0.28759\n",
      "Iteration 249700: Avg Loss =  0.32395\n",
      "Iteration 249800: Avg Loss =  0.30671\n",
      "Iteration 249900: Avg Loss =  0.28810\n",
      "Iteration 250000: Avg Loss =  0.30301\n",
      "Iteration 250100: Avg Loss =  0.29784\n",
      "Iteration 250200: Avg Loss =  0.29607\n",
      "Iteration 250300: Avg Loss =  0.28974\n",
      "Iteration 250400: Avg Loss =  0.28638\n",
      "Iteration 250500: Avg Loss =  0.29392\n",
      "Iteration 250600: Avg Loss =  0.30137\n",
      "Iteration 250700: Avg Loss =  0.34983\n",
      "Iteration 250800: Avg Loss =  0.31091\n",
      "Iteration 250900: Avg Loss =  0.30980\n",
      "Iteration 251000: Avg Loss =  0.27208\n",
      "Iteration 251100: Avg Loss =  0.29007\n",
      "Iteration 251200: Avg Loss =  0.32835\n",
      "Iteration 251300: Avg Loss =  0.32229\n",
      "Iteration 251400: Avg Loss =  0.30960\n",
      "Iteration 251500: Avg Loss =  0.29698\n",
      "Iteration 251600: Avg Loss =  0.30883\n",
      "Iteration 251700: Avg Loss =  0.32256\n",
      "Iteration 251800: Avg Loss =  0.32773\n",
      "Iteration 251900: Avg Loss =  0.29430\n",
      "Iteration 252000: Avg Loss =  0.31157\n",
      "Iteration 252100: Avg Loss =  0.29458\n",
      "Iteration 252200: Avg Loss =  0.30643\n",
      "Iteration 252300: Avg Loss =  0.30571\n",
      "Iteration 252400: Avg Loss =  0.31528\n",
      "Iteration 252500: Avg Loss =  0.32166\n",
      "Iteration 252600: Avg Loss =  0.31567\n",
      "Iteration 252700: Avg Loss =  0.34505\n",
      "Iteration 252800: Avg Loss =  0.31773\n",
      "Iteration 252900: Avg Loss =  0.29062\n",
      "Iteration 253000: Avg Loss =  0.26777\n",
      "Iteration 253100: Avg Loss =  0.28317\n",
      "Iteration 253200: Avg Loss =  0.30145\n",
      "Iteration 253300: Avg Loss =  0.30866\n",
      "Iteration 253400: Avg Loss =  0.27601\n",
      "Iteration 253500: Avg Loss =  0.32201\n",
      "Iteration 253600: Avg Loss =  0.34153\n",
      "Iteration 253700: Avg Loss =  0.27142\n",
      "Iteration 253800: Avg Loss =  0.28361\n",
      "Iteration 253900: Avg Loss =  0.28296\n",
      "Iteration 254000: Avg Loss =  0.29290\n",
      "Iteration 254100: Avg Loss =  0.30594\n",
      "Iteration 254200: Avg Loss =  0.25964\n",
      "Iteration 254300: Avg Loss =  0.29350\n",
      "Iteration 254400: Avg Loss =  0.31455\n",
      "Iteration 254500: Avg Loss =  0.30920\n",
      "Iteration 254600: Avg Loss =  0.30131\n",
      "Iteration 254700: Avg Loss =  0.31110\n",
      "Iteration 254800: Avg Loss =  0.30331\n",
      "Iteration 254900: Avg Loss =  0.28831\n",
      "Iteration 255000: Avg Loss =  0.30194\n",
      "Iteration 255100: Avg Loss =  0.27364\n",
      "Iteration 255200: Avg Loss =  0.29215\n",
      "Iteration 255300: Avg Loss =  0.30139\n",
      "Iteration 255400: Avg Loss =  0.28036\n",
      "Iteration 255500: Avg Loss =  0.27400\n",
      "Iteration 255600: Avg Loss =  0.29047\n",
      "Iteration 255700: Avg Loss =  0.33746\n",
      "Iteration 255800: Avg Loss =  0.31216\n",
      "Iteration 255900: Avg Loss =  0.36977\n",
      "Iteration 256000: Avg Loss =  0.29534\n",
      "Iteration 256100: Avg Loss =  0.26248\n",
      "Iteration 256200: Avg Loss =  0.31043\n",
      "Iteration 256300: Avg Loss =  0.27618\n",
      "Iteration 256400: Avg Loss =  0.27950\n",
      "Iteration 256500: Avg Loss =  0.28654\n",
      "Iteration 256600: Avg Loss =  0.29976\n",
      "Iteration 256700: Avg Loss =  0.30753\n",
      "Iteration 256800: Avg Loss =  0.25290\n",
      "Iteration 256900: Avg Loss =  0.28972\n",
      "Iteration 257000: Avg Loss =  0.32512\n",
      "Iteration 257100: Avg Loss =  0.27581\n",
      "Iteration 257200: Avg Loss =  0.31889\n",
      "Iteration 257300: Avg Loss =  0.32018\n",
      "Iteration 257400: Avg Loss =  0.31168\n",
      "Iteration 257500: Avg Loss =  0.31789\n",
      "Iteration 257600: Avg Loss =  0.30836\n",
      "Iteration 257700: Avg Loss =  0.28986\n",
      "Iteration 257800: Avg Loss =  0.28487\n",
      "Iteration 257900: Avg Loss =  0.34646\n",
      "Iteration 258000: Avg Loss =  0.31064\n",
      "Iteration 258100: Avg Loss =  0.29215\n",
      "Iteration 258200: Avg Loss =  0.31779\n",
      "Iteration 258300: Avg Loss =  0.31163\n",
      "Iteration 258400: Avg Loss =  0.29128\n",
      "Iteration 258500: Avg Loss =  0.26815\n",
      "Iteration 258600: Avg Loss =  0.32115\n",
      "Iteration 258700: Avg Loss =  0.28818\n",
      "Iteration 258800: Avg Loss =  0.30397\n",
      "Iteration 258900: Avg Loss =  0.28456\n",
      "Iteration 259000: Avg Loss =  0.29060\n",
      "Iteration 259100: Avg Loss =  0.29739\n",
      "Iteration 259200: Avg Loss =  0.29754\n",
      "Iteration 259300: Avg Loss =  0.26673\n",
      "Iteration 259400: Avg Loss =  0.27994\n",
      "Iteration 259500: Avg Loss =  0.27586\n",
      "Iteration 259600: Avg Loss =  0.28402\n",
      "Iteration 259700: Avg Loss =  0.31953\n",
      "Iteration 259800: Avg Loss =  0.31222\n",
      "Iteration 259900: Avg Loss =  0.31469\n",
      "Iteration 260000: Avg Loss =  0.29535\n",
      "Iteration 260100: Avg Loss =  0.36513\n",
      "Iteration 260200: Avg Loss =  0.26102\n",
      "Iteration 260300: Avg Loss =  0.36838\n",
      "Iteration 260400: Avg Loss =  0.28248\n",
      "Iteration 260500: Avg Loss =  0.29300\n",
      "Iteration 260600: Avg Loss =  0.28929\n",
      "Iteration 260700: Avg Loss =  0.26242\n",
      "Iteration 260800: Avg Loss =  0.26113\n",
      "Iteration 260900: Avg Loss =  0.29470\n",
      "Iteration 261000: Avg Loss =  0.29591\n",
      "Iteration 261100: Avg Loss =  0.31253\n",
      "Iteration 261200: Avg Loss =  0.31125\n",
      "Iteration 261300: Avg Loss =  0.33631\n",
      "Iteration 261400: Avg Loss =  0.26407\n",
      "Iteration 261500: Avg Loss =  0.27162\n",
      "Iteration 261600: Avg Loss =  0.25281\n",
      "Iteration 261700: Avg Loss =  0.27388\n",
      "Iteration 261800: Avg Loss =  0.34542\n",
      "Iteration 261900: Avg Loss =  0.34609\n",
      "Iteration 262000: Avg Loss =  0.30365\n",
      "Iteration 262100: Avg Loss =  0.27998\n",
      "Iteration 262200: Avg Loss =  0.27710\n",
      "Iteration 262300: Avg Loss =  0.31054\n",
      "Iteration 262400: Avg Loss =  0.29573\n",
      "Iteration 262500: Avg Loss =  0.28220\n",
      "Iteration 262600: Avg Loss =  0.28678\n",
      "Iteration 262700: Avg Loss =  0.31997\n",
      "Iteration 262800: Avg Loss =  0.27097\n",
      "Iteration 262900: Avg Loss =  0.32829\n",
      "Iteration 263000: Avg Loss =  0.26849\n",
      "Iteration 263100: Avg Loss =  0.29301\n",
      "Iteration 263200: Avg Loss =  0.34842\n",
      "Iteration 263300: Avg Loss =  0.32391\n",
      "Iteration 263400: Avg Loss =  0.31778\n",
      "Iteration 263500: Avg Loss =  0.30850\n",
      "Iteration 263600: Avg Loss =  0.26103\n",
      "Iteration 263700: Avg Loss =  0.29543\n",
      "Iteration 263800: Avg Loss =  0.27562\n",
      "Iteration 263900: Avg Loss =  0.24651\n",
      "Iteration 264000: Avg Loss =  0.31847\n",
      "Iteration 264100: Avg Loss =  0.34644\n",
      "Iteration 264200: Avg Loss =  0.34710\n",
      "Iteration 264300: Avg Loss =  0.33967\n",
      "Iteration 264400: Avg Loss =  0.33146\n",
      "Iteration 264500: Avg Loss =  0.28067\n",
      "Iteration 264600: Avg Loss =  0.30795\n",
      "Iteration 264700: Avg Loss =  0.28297\n",
      "Iteration 264800: Avg Loss =  0.29192\n",
      "Iteration 264900: Avg Loss =  0.34367\n",
      "Iteration 265000: Avg Loss =  0.31677\n",
      "Iteration 265100: Avg Loss =  0.27576\n",
      "Iteration 265200: Avg Loss =  0.31984\n",
      "Iteration 265300: Avg Loss =  0.26543\n",
      "Iteration 265400: Avg Loss =  0.31137\n",
      "Iteration 265500: Avg Loss =  0.32721\n",
      "Iteration 265600: Avg Loss =  0.26912\n",
      "Iteration 265700: Avg Loss =  0.26727\n",
      "Iteration 265800: Avg Loss =  0.28644\n",
      "Iteration 265900: Avg Loss =  0.27112\n",
      "Iteration 266000: Avg Loss =  0.31018\n",
      "Iteration 266100: Avg Loss =  0.29649\n",
      "Iteration 266200: Avg Loss =  0.29555\n",
      "Iteration 266300: Avg Loss =  0.28196\n",
      "Iteration 266400: Avg Loss =  0.31149\n",
      "Iteration 266500: Avg Loss =  0.28792\n",
      "Iteration 266600: Avg Loss =  0.30982\n",
      "Iteration 266700: Avg Loss =  0.28327\n",
      "Iteration 266800: Avg Loss =  0.33019\n",
      "Iteration 266900: Avg Loss =  0.29910\n",
      "Iteration 267000: Avg Loss =  0.26947\n",
      "Iteration 267100: Avg Loss =  0.28528\n",
      "Iteration 267200: Avg Loss =  0.34903\n",
      "Iteration 267300: Avg Loss =  0.31884\n",
      "Iteration 267400: Avg Loss =  0.27903\n",
      "Iteration 267500: Avg Loss =  0.31780\n",
      "Iteration 267600: Avg Loss =  0.32620\n",
      "Iteration 267700: Avg Loss =  0.31327\n",
      "Iteration 267800: Avg Loss =  0.31458\n",
      "Iteration 267900: Avg Loss =  0.29685\n",
      "Iteration 268000: Avg Loss =  0.28644\n",
      "Iteration 268100: Avg Loss =  0.29068\n",
      "Iteration 268200: Avg Loss =  0.31422\n",
      "Iteration 268300: Avg Loss =  0.26672\n",
      "Iteration 268400: Avg Loss =  0.28636\n",
      "Iteration 268500: Avg Loss =  0.29379\n",
      "Iteration 268600: Avg Loss =  0.33234\n",
      "Iteration 268700: Avg Loss =  0.30784\n",
      "Iteration 268800: Avg Loss =  0.33112\n",
      "Iteration 268900: Avg Loss =  0.29419\n",
      "Iteration 269000: Avg Loss =  0.28546\n",
      "Iteration 269100: Avg Loss =  0.29159\n",
      "Iteration 269200: Avg Loss =  0.33906\n",
      "Iteration 269300: Avg Loss =  0.27645\n",
      "Iteration 269400: Avg Loss =  0.28540\n",
      "Iteration 269500: Avg Loss =  0.33771\n",
      "Iteration 269600: Avg Loss =  0.30349\n",
      "Iteration 269700: Avg Loss =  0.30368\n",
      "Iteration 269800: Avg Loss =  0.27698\n",
      "Iteration 269900: Avg Loss =  0.34747\n",
      "Iteration 270000: Avg Loss =  0.28306\n",
      "Iteration 270100: Avg Loss =  0.28688\n",
      "Iteration 270200: Avg Loss =  0.32570\n",
      "Iteration 270300: Avg Loss =  0.29375\n",
      "Iteration 270400: Avg Loss =  0.27557\n",
      "Iteration 270500: Avg Loss =  0.30870\n",
      "Iteration 270600: Avg Loss =  0.28733\n",
      "Iteration 270700: Avg Loss =  0.32893\n",
      "Iteration 270800: Avg Loss =  0.31758\n",
      "Iteration 270900: Avg Loss =  0.30001\n",
      "Iteration 271000: Avg Loss =  0.28200\n",
      "Iteration 271100: Avg Loss =  0.30148\n",
      "Iteration 271200: Avg Loss =  0.29308\n",
      "Iteration 271300: Avg Loss =  0.31159\n",
      "Iteration 271400: Avg Loss =  0.31919\n",
      "Iteration 271500: Avg Loss =  0.31004\n",
      "Iteration 271600: Avg Loss =  0.28595\n",
      "Iteration 271700: Avg Loss =  0.29376\n",
      "Iteration 271800: Avg Loss =  0.29314\n",
      "Iteration 271900: Avg Loss =  0.34360\n",
      "Iteration 272000: Avg Loss =  0.30212\n",
      "Iteration 272100: Avg Loss =  0.28920\n",
      "Iteration 272200: Avg Loss =  0.31029\n",
      "Iteration 272300: Avg Loss =  0.27169\n",
      "Iteration 272400: Avg Loss =  0.26831\n",
      "Iteration 272500: Avg Loss =  0.31010\n",
      "Iteration 272600: Avg Loss =  0.29992\n",
      "Iteration 272700: Avg Loss =  0.31141\n",
      "Iteration 272800: Avg Loss =  0.32617\n",
      "Iteration 272900: Avg Loss =  0.27101\n",
      "Iteration 273000: Avg Loss =  0.28413\n",
      "Iteration 273100: Avg Loss =  0.34345\n",
      "Iteration 273200: Avg Loss =  0.33432\n",
      "Iteration 273300: Avg Loss =  0.30897\n",
      "Iteration 273400: Avg Loss =  0.30331\n",
      "Iteration 273500: Avg Loss =  0.28569\n",
      "Iteration 273600: Avg Loss =  0.31154\n",
      "Iteration 273700: Avg Loss =  0.26454\n",
      "Iteration 273800: Avg Loss =  0.30465\n",
      "Iteration 273900: Avg Loss =  0.30166\n",
      "Iteration 274000: Avg Loss =  0.28915\n",
      "Iteration 274100: Avg Loss =  0.26699\n",
      "Iteration 274200: Avg Loss =  0.31309\n",
      "Iteration 274300: Avg Loss =  0.32774\n",
      "Iteration 274400: Avg Loss =  0.32987\n",
      "Iteration 274500: Avg Loss =  0.31486\n",
      "Iteration 274600: Avg Loss =  0.33540\n",
      "Iteration 274700: Avg Loss =  0.29909\n",
      "Iteration 274800: Avg Loss =  0.28686\n",
      "Iteration 274900: Avg Loss =  0.30826\n",
      "Iteration 275000: Avg Loss =  0.28438\n",
      "Iteration 275100: Avg Loss =  0.30901\n",
      "Iteration 275200: Avg Loss =  0.30332\n",
      "Iteration 275300: Avg Loss =  0.32786\n",
      "Iteration 275400: Avg Loss =  0.31222\n",
      "Iteration 275500: Avg Loss =  0.29239\n",
      "Iteration 275600: Avg Loss =  0.32199\n",
      "Iteration 275700: Avg Loss =  0.32076\n",
      "Iteration 275800: Avg Loss =  0.26619\n",
      "Iteration 275900: Avg Loss =  0.29262\n",
      "Iteration 276000: Avg Loss =  0.29022\n",
      "Iteration 276100: Avg Loss =  0.29806\n",
      "Iteration 276200: Avg Loss =  0.28549\n",
      "Iteration 276300: Avg Loss =  0.33512\n",
      "Iteration 276400: Avg Loss =  0.32135\n",
      "Iteration 276500: Avg Loss =  0.29351\n",
      "Iteration 276600: Avg Loss =  0.33065\n",
      "Iteration 276700: Avg Loss =  0.29901\n",
      "Iteration 276800: Avg Loss =  0.27684\n",
      "Iteration 276900: Avg Loss =  0.27488\n",
      "Iteration 277000: Avg Loss =  0.30004\n",
      "Iteration 277100: Avg Loss =  0.28094\n",
      "Iteration 277200: Avg Loss =  0.26694\n",
      "Iteration 277300: Avg Loss =  0.33759\n",
      "Iteration 277400: Avg Loss =  0.29675\n",
      "Iteration 277500: Avg Loss =  0.29828\n",
      "Iteration 277600: Avg Loss =  0.29754\n",
      "Iteration 277700: Avg Loss =  0.32920\n",
      "Iteration 277800: Avg Loss =  0.30610\n",
      "Iteration 277900: Avg Loss =  0.30871\n",
      "Iteration 278000: Avg Loss =  0.24628\n",
      "Iteration 278100: Avg Loss =  0.31063\n",
      "Iteration 278200: Avg Loss =  0.29796\n",
      "Iteration 278300: Avg Loss =  0.27376\n",
      "Iteration 278400: Avg Loss =  0.25578\n",
      "Iteration 278500: Avg Loss =  0.29658\n",
      "Iteration 278600: Avg Loss =  0.33882\n",
      "Iteration 278700: Avg Loss =  0.25725\n",
      "Iteration 278800: Avg Loss =  0.30489\n",
      "Iteration 278900: Avg Loss =  0.31643\n",
      "Iteration 279000: Avg Loss =  0.28188\n",
      "Iteration 279100: Avg Loss =  0.26464\n",
      "Iteration 279200: Avg Loss =  0.27358\n",
      "Iteration 279300: Avg Loss =  0.26912\n",
      "Iteration 279400: Avg Loss =  0.32298\n",
      "Iteration 279500: Avg Loss =  0.28138\n",
      "Iteration 279600: Avg Loss =  0.31817\n",
      "Iteration 279700: Avg Loss =  0.26375\n",
      "Iteration 279800: Avg Loss =  0.32713\n",
      "Iteration 279900: Avg Loss =  0.30224\n",
      "Iteration 280000: Avg Loss =  0.26952\n",
      "Iteration 280100: Avg Loss =  0.30956\n",
      "Iteration 280200: Avg Loss =  0.26973\n",
      "Iteration 280300: Avg Loss =  0.30842\n",
      "Iteration 280400: Avg Loss =  0.29405\n",
      "Iteration 280500: Avg Loss =  0.29208\n",
      "Iteration 280600: Avg Loss =  0.29121\n",
      "Iteration 280700: Avg Loss =  0.29738\n",
      "Iteration 280800: Avg Loss =  0.27621\n",
      "Iteration 280900: Avg Loss =  0.30413\n",
      "Iteration 281000: Avg Loss =  0.27481\n",
      "Iteration 281100: Avg Loss =  0.27717\n",
      "Iteration 281200: Avg Loss =  0.32269\n",
      "Iteration 281300: Avg Loss =  0.28286\n",
      "Iteration 281400: Avg Loss =  0.26556\n",
      "Iteration 281500: Avg Loss =  0.27724\n",
      "Iteration 281600: Avg Loss =  0.28994\n",
      "Iteration 281700: Avg Loss =  0.29535\n",
      "Iteration 281800: Avg Loss =  0.28035\n",
      "Iteration 281900: Avg Loss =  0.30686\n",
      "Iteration 282000: Avg Loss =  0.29193\n",
      "Iteration 282100: Avg Loss =  0.29849\n",
      "Iteration 282200: Avg Loss =  0.29852\n",
      "Iteration 282300: Avg Loss =  0.33316\n",
      "Iteration 282400: Avg Loss =  0.28515\n",
      "Iteration 282500: Avg Loss =  0.30981\n",
      "Iteration 282600: Avg Loss =  0.31035\n",
      "Iteration 282700: Avg Loss =  0.29215\n",
      "Iteration 282800: Avg Loss =  0.29751\n",
      "Iteration 282900: Avg Loss =  0.27284\n",
      "Iteration 283000: Avg Loss =  0.26409\n",
      "Iteration 283100: Avg Loss =  0.25314\n",
      "Iteration 283200: Avg Loss =  0.29709\n",
      "Iteration 283300: Avg Loss =  0.27004\n",
      "Iteration 283400: Avg Loss =  0.29411\n",
      "Iteration 283500: Avg Loss =  0.26722\n",
      "Iteration 283600: Avg Loss =  0.32696\n",
      "Iteration 283700: Avg Loss =  0.30243\n",
      "Iteration 283800: Avg Loss =  0.28282\n",
      "Iteration 283900: Avg Loss =  0.28240\n",
      "Iteration 284000: Avg Loss =  0.26181\n",
      "Iteration 284100: Avg Loss =  0.31718\n",
      "Iteration 284200: Avg Loss =  0.32729\n",
      "Iteration 284300: Avg Loss =  0.24175\n",
      "Iteration 284400: Avg Loss =  0.28113\n",
      "Iteration 284500: Avg Loss =  0.33959\n",
      "Iteration 284600: Avg Loss =  0.29331\n",
      "Iteration 284700: Avg Loss =  0.28975\n",
      "Iteration 284800: Avg Loss =  0.28307\n",
      "Iteration 284900: Avg Loss =  0.33148\n",
      "Iteration 285000: Avg Loss =  0.29189\n",
      "Iteration 285100: Avg Loss =  0.23800\n",
      "Iteration 285200: Avg Loss =  0.28817\n",
      "Iteration 285300: Avg Loss =  0.29677\n",
      "Iteration 285400: Avg Loss =  0.27407\n",
      "Iteration 285500: Avg Loss =  0.30839\n",
      "Iteration 285600: Avg Loss =  0.28202\n",
      "Iteration 285700: Avg Loss =  0.27404\n",
      "Iteration 285800: Avg Loss =  0.30828\n",
      "Iteration 285900: Avg Loss =  0.31918\n",
      "Iteration 286000: Avg Loss =  0.30157\n",
      "Iteration 286100: Avg Loss =  0.28546\n",
      "Iteration 286200: Avg Loss =  0.34186\n",
      "Iteration 286300: Avg Loss =  0.26724\n",
      "Iteration 286400: Avg Loss =  0.30637\n",
      "Iteration 286500: Avg Loss =  0.26772\n",
      "Iteration 286600: Avg Loss =  0.30481\n",
      "Iteration 286700: Avg Loss =  0.29716\n",
      "Iteration 286800: Avg Loss =  0.30803\n",
      "Iteration 286900: Avg Loss =  0.31900\n",
      "Iteration 287000: Avg Loss =  0.27930\n",
      "Iteration 287100: Avg Loss =  0.29076\n",
      "Iteration 287200: Avg Loss =  0.31534\n",
      "Iteration 287300: Avg Loss =  0.28244\n",
      "Iteration 287400: Avg Loss =  0.27015\n",
      "Iteration 287500: Avg Loss =  0.29082\n",
      "Iteration 287600: Avg Loss =  0.26650\n",
      "Iteration 287700: Avg Loss =  0.29424\n",
      "Iteration 287800: Avg Loss =  0.29522\n",
      "Iteration 287900: Avg Loss =  0.30252\n",
      "Iteration 288000: Avg Loss =  0.28125\n",
      "Iteration 288100: Avg Loss =  0.32948\n",
      "Iteration 288200: Avg Loss =  0.31298\n",
      "Iteration 288300: Avg Loss =  0.28761\n",
      "Iteration 288400: Avg Loss =  0.29762\n",
      "Iteration 288500: Avg Loss =  0.33447\n",
      "Iteration 288600: Avg Loss =  0.27966\n",
      "Iteration 288700: Avg Loss =  0.33937\n",
      "Iteration 288800: Avg Loss =  0.26292\n",
      "Iteration 288900: Avg Loss =  0.27066\n",
      "Iteration 289000: Avg Loss =  0.30885\n",
      "Iteration 289100: Avg Loss =  0.29570\n",
      "Iteration 289200: Avg Loss =  0.26355\n",
      "Iteration 289300: Avg Loss =  0.29071\n",
      "Iteration 289400: Avg Loss =  0.27823\n",
      "Iteration 289500: Avg Loss =  0.29098\n",
      "Iteration 289600: Avg Loss =  0.32006\n",
      "Iteration 289700: Avg Loss =  0.30476\n",
      "Iteration 289800: Avg Loss =  0.29293\n",
      "Iteration 289900: Avg Loss =  0.31423\n",
      "Iteration 290000: Avg Loss =  0.32775\n",
      "Iteration 290100: Avg Loss =  0.26591\n",
      "Iteration 290200: Avg Loss =  0.27437\n",
      "Iteration 290300: Avg Loss =  0.30664\n",
      "Iteration 290400: Avg Loss =  0.27519\n",
      "Iteration 290500: Avg Loss =  0.31116\n",
      "Iteration 290600: Avg Loss =  0.31670\n",
      "Iteration 290700: Avg Loss =  0.31254\n",
      "Iteration 290800: Avg Loss =  0.29931\n",
      "Iteration 290900: Avg Loss =  0.31459\n",
      "Iteration 291000: Avg Loss =  0.31758\n",
      "Iteration 291100: Avg Loss =  0.28729\n",
      "Iteration 291200: Avg Loss =  0.30503\n",
      "Iteration 291300: Avg Loss =  0.28875\n",
      "Iteration 291400: Avg Loss =  0.27415\n",
      "Iteration 291500: Avg Loss =  0.27691\n",
      "Iteration 291600: Avg Loss =  0.28840\n",
      "Iteration 291700: Avg Loss =  0.29695\n",
      "Iteration 291800: Avg Loss =  0.31191\n",
      "Iteration 291900: Avg Loss =  0.30271\n",
      "Iteration 292000: Avg Loss =  0.27983\n",
      "Iteration 292100: Avg Loss =  0.32503\n",
      "Iteration 292200: Avg Loss =  0.28424\n",
      "Iteration 292300: Avg Loss =  0.28330\n",
      "Iteration 292400: Avg Loss =  0.29653\n",
      "Iteration 292500: Avg Loss =  0.26724\n",
      "Iteration 292600: Avg Loss =  0.27227\n",
      "Iteration 292700: Avg Loss =  0.28797\n",
      "Iteration 292800: Avg Loss =  0.34066\n",
      "Iteration 292900: Avg Loss =  0.32297\n",
      "Iteration 293000: Avg Loss =  0.31625\n",
      "Iteration 293100: Avg Loss =  0.29100\n",
      "Iteration 293200: Avg Loss =  0.29355\n",
      "Iteration 293300: Avg Loss =  0.30072\n",
      "Iteration 293400: Avg Loss =  0.27581\n",
      "Iteration 293500: Avg Loss =  0.29983\n",
      "Iteration 293600: Avg Loss =  0.28696\n",
      "Iteration 293700: Avg Loss =  0.29509\n",
      "Iteration 293800: Avg Loss =  0.30776\n",
      "Iteration 293900: Avg Loss =  0.27547\n",
      "Iteration 294000: Avg Loss =  0.29613\n",
      "Iteration 294100: Avg Loss =  0.30153\n",
      "Iteration 294200: Avg Loss =  0.29048\n",
      "Iteration 294300: Avg Loss =  0.29722\n",
      "Iteration 294400: Avg Loss =  0.24576\n",
      "Iteration 294500: Avg Loss =  0.29370\n",
      "Iteration 294600: Avg Loss =  0.26366\n",
      "Iteration 294700: Avg Loss =  0.27852\n",
      "Iteration 294800: Avg Loss =  0.31050\n",
      "Iteration 294900: Avg Loss =  0.28083\n",
      "Iteration 295000: Avg Loss =  0.29142\n",
      "Iteration 295100: Avg Loss =  0.24377\n",
      "Iteration 295200: Avg Loss =  0.28875\n",
      "Iteration 295300: Avg Loss =  0.27353\n",
      "Iteration 295400: Avg Loss =  0.27910\n",
      "Iteration 295500: Avg Loss =  0.27008\n",
      "Iteration 295600: Avg Loss =  0.28275\n",
      "Iteration 295700: Avg Loss =  0.30924\n",
      "Iteration 295800: Avg Loss =  0.28793\n",
      "Iteration 295900: Avg Loss =  0.28264\n",
      "Iteration 296000: Avg Loss =  0.30972\n",
      "Iteration 296100: Avg Loss =  0.23300\n",
      "Iteration 296200: Avg Loss =  0.30865\n",
      "Iteration 296300: Avg Loss =  0.28948\n",
      "Iteration 296400: Avg Loss =  0.33870\n",
      "Iteration 296500: Avg Loss =  0.31846\n",
      "Iteration 296600: Avg Loss =  0.33442\n",
      "Iteration 296700: Avg Loss =  0.30209\n",
      "Iteration 296800: Avg Loss =  0.28816\n",
      "Iteration 296900: Avg Loss =  0.31444\n",
      "Iteration 297000: Avg Loss =  0.31842\n",
      "Iteration 297100: Avg Loss =  0.27013\n",
      "Iteration 297200: Avg Loss =  0.30961\n",
      "Iteration 297300: Avg Loss =  0.30535\n",
      "Iteration 297400: Avg Loss =  0.25579\n",
      "Iteration 297500: Avg Loss =  0.31128\n",
      "Iteration 297600: Avg Loss =  0.31597\n",
      "Iteration 297700: Avg Loss =  0.27094\n",
      "Iteration 297800: Avg Loss =  0.28975\n",
      "Iteration 297900: Avg Loss =  0.26729\n",
      "Iteration 298000: Avg Loss =  0.28625\n",
      "Iteration 298100: Avg Loss =  0.30472\n",
      "Iteration 298200: Avg Loss =  0.29537\n",
      "Iteration 298300: Avg Loss =  0.27250\n",
      "Iteration 298400: Avg Loss =  0.30109\n",
      "Iteration 298500: Avg Loss =  0.25241\n",
      "Iteration 298600: Avg Loss =  0.26655\n",
      "Iteration 298700: Avg Loss =  0.25499\n",
      "Iteration 298800: Avg Loss =  0.31828\n",
      "Iteration 298900: Avg Loss =  0.32424\n",
      "Iteration 299000: Avg Loss =  0.26799\n",
      "Iteration 299100: Avg Loss =  0.29516\n",
      "Iteration 299200: Avg Loss =  0.26201\n",
      "Iteration 299300: Avg Loss =  0.27756\n",
      "Iteration 299400: Avg Loss =  0.31658\n",
      "Iteration 299500: Avg Loss =  0.36881\n",
      "Iteration 299600: Avg Loss =  0.28545\n",
      "Iteration 299700: Avg Loss =  0.32350\n",
      "Iteration 299800: Avg Loss =  0.28307\n",
      "Iteration 299900: Avg Loss =  0.30249\n",
      "Iteration 300000: Avg Loss =  0.28918\n",
      "Iteration 300100: Avg Loss =  0.29632\n",
      "Iteration 300200: Avg Loss =  0.31775\n",
      "Iteration 300300: Avg Loss =  0.25845\n",
      "Iteration 300400: Avg Loss =  0.29408\n",
      "Iteration 300500: Avg Loss =  0.23520\n",
      "Iteration 300600: Avg Loss =  0.27787\n",
      "Iteration 300700: Avg Loss =  0.30965\n",
      "Iteration 300800: Avg Loss =  0.28595\n",
      "Iteration 300900: Avg Loss =  0.31041\n",
      "Iteration 301000: Avg Loss =  0.24288\n",
      "Iteration 301100: Avg Loss =  0.27933\n",
      "Iteration 301200: Avg Loss =  0.25721\n",
      "Iteration 301300: Avg Loss =  0.27709\n",
      "Iteration 301400: Avg Loss =  0.24874\n",
      "Iteration 301500: Avg Loss =  0.25690\n",
      "Iteration 301600: Avg Loss =  0.27237\n",
      "Iteration 301700: Avg Loss =  0.28660\n",
      "Iteration 301800: Avg Loss =  0.28083\n",
      "Iteration 301900: Avg Loss =  0.30623\n",
      "Iteration 302000: Avg Loss =  0.26581\n",
      "Iteration 302100: Avg Loss =  0.30682\n",
      "Iteration 302200: Avg Loss =  0.29782\n",
      "Iteration 302300: Avg Loss =  0.26628\n",
      "Iteration 302400: Avg Loss =  0.33213\n",
      "Iteration 302500: Avg Loss =  0.32421\n",
      "Iteration 302600: Avg Loss =  0.29186\n",
      "Iteration 302700: Avg Loss =  0.30154\n",
      "Iteration 302800: Avg Loss =  0.25207\n",
      "Iteration 302900: Avg Loss =  0.29033\n",
      "Iteration 303000: Avg Loss =  0.28829\n",
      "Iteration 303100: Avg Loss =  0.29644\n",
      "Iteration 303200: Avg Loss =  0.30168\n",
      "Iteration 303300: Avg Loss =  0.27951\n",
      "Iteration 303400: Avg Loss =  0.26576\n",
      "Iteration 303500: Avg Loss =  0.26800\n",
      "Iteration 303600: Avg Loss =  0.27295\n",
      "Iteration 303700: Avg Loss =  0.26910\n",
      "Iteration 303800: Avg Loss =  0.28252\n",
      "Iteration 303900: Avg Loss =  0.26814\n",
      "Iteration 304000: Avg Loss =  0.27734\n",
      "Iteration 304100: Avg Loss =  0.31207\n",
      "Iteration 304200: Avg Loss =  0.28136\n",
      "Iteration 304300: Avg Loss =  0.31145\n",
      "Iteration 304400: Avg Loss =  0.29783\n",
      "Iteration 304500: Avg Loss =  0.26729\n",
      "Iteration 304600: Avg Loss =  0.27349\n",
      "Iteration 304700: Avg Loss =  0.27909\n",
      "Iteration 304800: Avg Loss =  0.31233\n",
      "Iteration 304900: Avg Loss =  0.25059\n",
      "Iteration 305000: Avg Loss =  0.30992\n",
      "Iteration 305100: Avg Loss =  0.25645\n",
      "Iteration 305200: Avg Loss =  0.27725\n",
      "Iteration 305300: Avg Loss =  0.29683\n",
      "Iteration 305400: Avg Loss =  0.33141\n",
      "Iteration 305500: Avg Loss =  0.27683\n",
      "Iteration 305600: Avg Loss =  0.27923\n",
      "Iteration 305700: Avg Loss =  0.25259\n",
      "Iteration 305800: Avg Loss =  0.25256\n",
      "Iteration 305900: Avg Loss =  0.27566\n",
      "Iteration 306000: Avg Loss =  0.29668\n",
      "Iteration 306100: Avg Loss =  0.28272\n",
      "Iteration 306200: Avg Loss =  0.28861\n",
      "Iteration 306300: Avg Loss =  0.31867\n",
      "Iteration 306400: Avg Loss =  0.29169\n",
      "Iteration 306500: Avg Loss =  0.28028\n",
      "Iteration 306600: Avg Loss =  0.28101\n",
      "Iteration 306700: Avg Loss =  0.26397\n",
      "Iteration 306800: Avg Loss =  0.29430\n",
      "Iteration 306900: Avg Loss =  0.29078\n",
      "Iteration 307000: Avg Loss =  0.27809\n",
      "Iteration 307100: Avg Loss =  0.27597\n",
      "Iteration 307200: Avg Loss =  0.24069\n",
      "Iteration 307300: Avg Loss =  0.29940\n",
      "Iteration 307400: Avg Loss =  0.26352\n",
      "Iteration 307500: Avg Loss =  0.26387\n",
      "Iteration 307600: Avg Loss =  0.29748\n",
      "Iteration 307700: Avg Loss =  0.26654\n",
      "Iteration 307800: Avg Loss =  0.29091\n",
      "Iteration 307900: Avg Loss =  0.29713\n",
      "Iteration 308000: Avg Loss =  0.27914\n",
      "Iteration 308100: Avg Loss =  0.29408\n",
      "Iteration 308200: Avg Loss =  0.33608\n",
      "Iteration 308300: Avg Loss =  0.27927\n",
      "Iteration 308400: Avg Loss =  0.27464\n",
      "Iteration 308500: Avg Loss =  0.23518\n",
      "Iteration 308600: Avg Loss =  0.31671\n",
      "Iteration 308700: Avg Loss =  0.28686\n",
      "Iteration 308800: Avg Loss =  0.30219\n",
      "Iteration 308900: Avg Loss =  0.29828\n",
      "Iteration 309000: Avg Loss =  0.28236\n",
      "Iteration 309100: Avg Loss =  0.29412\n",
      "Iteration 309200: Avg Loss =  0.29583\n",
      "Iteration 309300: Avg Loss =  0.30513\n",
      "Iteration 309400: Avg Loss =  0.23490\n",
      "Iteration 309500: Avg Loss =  0.29921\n",
      "Iteration 309600: Avg Loss =  0.25127\n",
      "Iteration 309700: Avg Loss =  0.28010\n",
      "Iteration 309800: Avg Loss =  0.27021\n",
      "Iteration 309900: Avg Loss =  0.32036\n",
      "Iteration 310000: Avg Loss =  0.31098\n",
      "Iteration 310100: Avg Loss =  0.26625\n",
      "Iteration 310200: Avg Loss =  0.35052\n",
      "Iteration 310300: Avg Loss =  0.25142\n",
      "Iteration 310400: Avg Loss =  0.29058\n",
      "Iteration 310500: Avg Loss =  0.26130\n",
      "Iteration 310600: Avg Loss =  0.27840\n",
      "Iteration 310700: Avg Loss =  0.27948\n",
      "Iteration 310800: Avg Loss =  0.27051\n",
      "Iteration 310900: Avg Loss =  0.30519\n",
      "Iteration 311000: Avg Loss =  0.27160\n",
      "Iteration 311100: Avg Loss =  0.26298\n",
      "Iteration 311200: Avg Loss =  0.31771\n",
      "Iteration 311300: Avg Loss =  0.33412\n",
      "Iteration 311400: Avg Loss =  0.25918\n",
      "Iteration 311500: Avg Loss =  0.27149\n",
      "Iteration 311600: Avg Loss =  0.25601\n",
      "Iteration 311700: Avg Loss =  0.27009\n",
      "Iteration 311800: Avg Loss =  0.25941\n",
      "Iteration 311900: Avg Loss =  0.26371\n",
      "Iteration 312000: Avg Loss =  0.30939\n",
      "Iteration 312100: Avg Loss =  0.27702\n",
      "Iteration 312200: Avg Loss =  0.30462\n",
      "Iteration 312300: Avg Loss =  0.31169\n",
      "Iteration 312400: Avg Loss =  0.29058\n",
      "Iteration 312500: Avg Loss =  0.28633\n",
      "Iteration 312600: Avg Loss =  0.27862\n",
      "Iteration 312700: Avg Loss =  0.30005\n",
      "Iteration 312800: Avg Loss =  0.30978\n",
      "Iteration 312900: Avg Loss =  0.29051\n",
      "Iteration 313000: Avg Loss =  0.27113\n",
      "Iteration 313100: Avg Loss =  0.32055\n",
      "Iteration 313200: Avg Loss =  0.24654\n",
      "Iteration 313300: Avg Loss =  0.30094\n",
      "Iteration 313400: Avg Loss =  0.26840\n",
      "Iteration 313500: Avg Loss =  0.26098\n",
      "Iteration 313600: Avg Loss =  0.29921\n",
      "Iteration 313700: Avg Loss =  0.27844\n",
      "Iteration 313800: Avg Loss =  0.27667\n",
      "Iteration 313900: Avg Loss =  0.26896\n",
      "Iteration 314000: Avg Loss =  0.27494\n",
      "Iteration 314100: Avg Loss =  0.29158\n",
      "Iteration 314200: Avg Loss =  0.26468\n",
      "Iteration 314300: Avg Loss =  0.32882\n",
      "Iteration 314400: Avg Loss =  0.24773\n",
      "Iteration 314500: Avg Loss =  0.28316\n",
      "Iteration 314600: Avg Loss =  0.25213\n",
      "Iteration 314700: Avg Loss =  0.26805\n",
      "Iteration 314800: Avg Loss =  0.27275\n",
      "Iteration 314900: Avg Loss =  0.28447\n",
      "Iteration 315000: Avg Loss =  0.29588\n",
      "Iteration 315100: Avg Loss =  0.27466\n",
      "Iteration 315200: Avg Loss =  0.28166\n",
      "Iteration 315300: Avg Loss =  0.27409\n",
      "Iteration 315400: Avg Loss =  0.30501\n",
      "Iteration 315500: Avg Loss =  0.24859\n",
      "Iteration 315600: Avg Loss =  0.28890\n",
      "Iteration 315700: Avg Loss =  0.26762\n",
      "Iteration 315800: Avg Loss =  0.27954\n",
      "Iteration 315900: Avg Loss =  0.27860\n",
      "Iteration 316000: Avg Loss =  0.27085\n",
      "Iteration 316100: Avg Loss =  0.25178\n",
      "Iteration 316200: Avg Loss =  0.30085\n",
      "Iteration 316300: Avg Loss =  0.26811\n",
      "Iteration 316400: Avg Loss =  0.31235\n",
      "Iteration 316500: Avg Loss =  0.28827\n",
      "Iteration 316600: Avg Loss =  0.25997\n",
      "Iteration 316700: Avg Loss =  0.26482\n",
      "Iteration 316800: Avg Loss =  0.29644\n",
      "Iteration 316900: Avg Loss =  0.27562\n",
      "Iteration 317000: Avg Loss =  0.33725\n",
      "Iteration 317100: Avg Loss =  0.28375\n",
      "Iteration 317200: Avg Loss =  0.27056\n",
      "Iteration 317300: Avg Loss =  0.26139\n",
      "Iteration 317400: Avg Loss =  0.30830\n",
      "Iteration 317500: Avg Loss =  0.31251\n",
      "Iteration 317600: Avg Loss =  0.26758\n",
      "Iteration 317700: Avg Loss =  0.26898\n",
      "Iteration 317800: Avg Loss =  0.26591\n",
      "Iteration 317900: Avg Loss =  0.30148\n",
      "Iteration 318000: Avg Loss =  0.26191\n",
      "Iteration 318100: Avg Loss =  0.26646\n",
      "Iteration 318200: Avg Loss =  0.25455\n",
      "Iteration 318300: Avg Loss =  0.28968\n",
      "Iteration 318400: Avg Loss =  0.25841\n",
      "Iteration 318500: Avg Loss =  0.27992\n",
      "Iteration 318600: Avg Loss =  0.28451\n",
      "Iteration 318700: Avg Loss =  0.26877\n",
      "Iteration 318800: Avg Loss =  0.29166\n",
      "Iteration 318900: Avg Loss =  0.27984\n",
      "Iteration 319000: Avg Loss =  0.27230\n",
      "Iteration 319100: Avg Loss =  0.26184\n",
      "Iteration 319200: Avg Loss =  0.24646\n",
      "Iteration 319300: Avg Loss =  0.26296\n",
      "Iteration 319400: Avg Loss =  0.32778\n",
      "Iteration 319500: Avg Loss =  0.28636\n",
      "Iteration 319600: Avg Loss =  0.23141\n",
      "Iteration 319700: Avg Loss =  0.28094\n",
      "Iteration 319800: Avg Loss =  0.29347\n",
      "Iteration 319900: Avg Loss =  0.30256\n",
      "Iteration 320000: Avg Loss =  0.31338\n",
      "Iteration 320100: Avg Loss =  0.27781\n",
      "Iteration 320200: Avg Loss =  0.34266\n",
      "Iteration 320300: Avg Loss =  0.24348\n",
      "Iteration 320400: Avg Loss =  0.28442\n",
      "Iteration 320500: Avg Loss =  0.29596\n",
      "Iteration 320600: Avg Loss =  0.26560\n",
      "Iteration 320700: Avg Loss =  0.27411\n",
      "Iteration 320800: Avg Loss =  0.28098\n",
      "Iteration 320900: Avg Loss =  0.31226\n",
      "Iteration 321000: Avg Loss =  0.25060\n",
      "Iteration 321100: Avg Loss =  0.29558\n",
      "Iteration 321200: Avg Loss =  0.27714\n",
      "Iteration 321300: Avg Loss =  0.27784\n",
      "Iteration 321400: Avg Loss =  0.27078\n",
      "Iteration 321500: Avg Loss =  0.28424\n",
      "Iteration 321600: Avg Loss =  0.31180\n",
      "Iteration 321700: Avg Loss =  0.29251\n",
      "Iteration 321800: Avg Loss =  0.25406\n",
      "Iteration 321900: Avg Loss =  0.26781\n",
      "Iteration 322000: Avg Loss =  0.29155\n",
      "Iteration 322100: Avg Loss =  0.29421\n",
      "Iteration 322200: Avg Loss =  0.27631\n",
      "Iteration 322300: Avg Loss =  0.27984\n",
      "Iteration 322400: Avg Loss =  0.27578\n",
      "Iteration 322500: Avg Loss =  0.25328\n",
      "Iteration 322600: Avg Loss =  0.22845\n",
      "Iteration 322700: Avg Loss =  0.25986\n",
      "Iteration 322800: Avg Loss =  0.31014\n",
      "Iteration 322900: Avg Loss =  0.29950\n",
      "Iteration 323000: Avg Loss =  0.28108\n",
      "Iteration 323100: Avg Loss =  0.27334\n",
      "Iteration 323200: Avg Loss =  0.25227\n",
      "Iteration 323300: Avg Loss =  0.26911\n",
      "Iteration 323400: Avg Loss =  0.24760\n",
      "Iteration 323500: Avg Loss =  0.28043\n",
      "Iteration 323600: Avg Loss =  0.26933\n",
      "Iteration 323700: Avg Loss =  0.28334\n",
      "Iteration 323800: Avg Loss =  0.27397\n",
      "Iteration 323900: Avg Loss =  0.23653\n",
      "Iteration 324000: Avg Loss =  0.23825\n",
      "Iteration 324100: Avg Loss =  0.26161\n",
      "Iteration 324200: Avg Loss =  0.33657\n",
      "Iteration 324300: Avg Loss =  0.31341\n",
      "Iteration 324400: Avg Loss =  0.27630\n",
      "Iteration 324500: Avg Loss =  0.26647\n",
      "Iteration 324600: Avg Loss =  0.25181\n",
      "Iteration 324700: Avg Loss =  0.24364\n",
      "Iteration 324800: Avg Loss =  0.27330\n",
      "Iteration 324900: Avg Loss =  0.24777\n",
      "Iteration 325000: Avg Loss =  0.31542\n",
      "Iteration 325100: Avg Loss =  0.29215\n",
      "Iteration 325200: Avg Loss =  0.27893\n",
      "Iteration 325300: Avg Loss =  0.32757\n",
      "Iteration 325400: Avg Loss =  0.26936\n",
      "Iteration 325500: Avg Loss =  0.26891\n",
      "Iteration 325600: Avg Loss =  0.25644\n",
      "Iteration 325700: Avg Loss =  0.32144\n",
      "Iteration 325800: Avg Loss =  0.31748\n",
      "Iteration 325900: Avg Loss =  0.30041\n",
      "Iteration 326000: Avg Loss =  0.28195\n",
      "Iteration 326100: Avg Loss =  0.27722\n",
      "Iteration 326200: Avg Loss =  0.26822\n",
      "Iteration 326300: Avg Loss =  0.25666\n",
      "Iteration 326400: Avg Loss =  0.24099\n",
      "Iteration 326500: Avg Loss =  0.33846\n",
      "Iteration 326600: Avg Loss =  0.26856\n",
      "Iteration 326700: Avg Loss =  0.29227\n",
      "Iteration 326800: Avg Loss =  0.28952\n",
      "Iteration 326900: Avg Loss =  0.25326\n",
      "Iteration 327000: Avg Loss =  0.27583\n",
      "Iteration 327100: Avg Loss =  0.28327\n",
      "Iteration 327200: Avg Loss =  0.27363\n",
      "Iteration 327300: Avg Loss =  0.27932\n",
      "Iteration 327400: Avg Loss =  0.30755\n",
      "Iteration 327500: Avg Loss =  0.27554\n",
      "Iteration 327600: Avg Loss =  0.27942\n",
      "Iteration 327700: Avg Loss =  0.28671\n",
      "Iteration 327800: Avg Loss =  0.25688\n",
      "Iteration 327900: Avg Loss =  0.28109\n",
      "Iteration 328000: Avg Loss =  0.26830\n",
      "Iteration 328100: Avg Loss =  0.24554\n",
      "Iteration 328200: Avg Loss =  0.30209\n",
      "Iteration 328300: Avg Loss =  0.25806\n",
      "Iteration 328400: Avg Loss =  0.28276\n",
      "Iteration 328500: Avg Loss =  0.25600\n",
      "Iteration 328600: Avg Loss =  0.29886\n",
      "Iteration 328700: Avg Loss =  0.22420\n",
      "Iteration 328800: Avg Loss =  0.22451\n",
      "Iteration 328900: Avg Loss =  0.25728\n",
      "Iteration 329000: Avg Loss =  0.32457\n",
      "Iteration 329100: Avg Loss =  0.32404\n",
      "Iteration 329200: Avg Loss =  0.28300\n",
      "Iteration 329300: Avg Loss =  0.29225\n",
      "Iteration 329400: Avg Loss =  0.26850\n",
      "Iteration 329500: Avg Loss =  0.26805\n",
      "Iteration 329600: Avg Loss =  0.30149\n",
      "Iteration 329700: Avg Loss =  0.26536\n",
      "Iteration 329800: Avg Loss =  0.23960\n",
      "Iteration 329900: Avg Loss =  0.29955\n",
      "Iteration 330000: Avg Loss =  0.27727\n",
      "Iteration 330100: Avg Loss =  0.26240\n",
      "Iteration 330200: Avg Loss =  0.26050\n",
      "Iteration 330300: Avg Loss =  0.28890\n",
      "Iteration 330400: Avg Loss =  0.29476\n",
      "Iteration 330500: Avg Loss =  0.25437\n",
      "Iteration 330600: Avg Loss =  0.26161\n",
      "Iteration 330700: Avg Loss =  0.26332\n",
      "Iteration 330800: Avg Loss =  0.27220\n",
      "Iteration 330900: Avg Loss =  0.27245\n",
      "Iteration 331000: Avg Loss =  0.28269\n",
      "Iteration 331100: Avg Loss =  0.25391\n",
      "Iteration 331200: Avg Loss =  0.26401\n",
      "Iteration 331300: Avg Loss =  0.23908\n",
      "Iteration 331400: Avg Loss =  0.30135\n",
      "Iteration 331500: Avg Loss =  0.29101\n",
      "Iteration 331600: Avg Loss =  0.23463\n",
      "Iteration 331700: Avg Loss =  0.25195\n",
      "Iteration 331800: Avg Loss =  0.29186\n",
      "Iteration 331900: Avg Loss =  0.26847\n",
      "Iteration 332000: Avg Loss =  0.26668\n",
      "Iteration 332100: Avg Loss =  0.28034\n",
      "Iteration 332200: Avg Loss =  0.31654\n",
      "Iteration 332300: Avg Loss =  0.23553\n",
      "Iteration 332400: Avg Loss =  0.26290\n",
      "Iteration 332500: Avg Loss =  0.26090\n",
      "Iteration 332600: Avg Loss =  0.27686\n",
      "Iteration 332700: Avg Loss =  0.32007\n",
      "Iteration 332800: Avg Loss =  0.25224\n",
      "Iteration 332900: Avg Loss =  0.28528\n",
      "Iteration 333000: Avg Loss =  0.26521\n",
      "Iteration 333100: Avg Loss =  0.24637\n",
      "Iteration 333200: Avg Loss =  0.28550\n",
      "Iteration 333300: Avg Loss =  0.30672\n",
      "Iteration 333400: Avg Loss =  0.28283\n",
      "Iteration 333500: Avg Loss =  0.24623\n",
      "Iteration 333600: Avg Loss =  0.28599\n",
      "Iteration 333700: Avg Loss =  0.31602\n",
      "Iteration 333800: Avg Loss =  0.28588\n",
      "Iteration 333900: Avg Loss =  0.25800\n",
      "Iteration 334000: Avg Loss =  0.23457\n",
      "Iteration 334100: Avg Loss =  0.29959\n",
      "Iteration 334200: Avg Loss =  0.31600\n",
      "Iteration 334300: Avg Loss =  0.27223\n",
      "Iteration 334400: Avg Loss =  0.28056\n",
      "Iteration 334500: Avg Loss =  0.28872\n",
      "Iteration 334600: Avg Loss =  0.28501\n",
      "Iteration 334700: Avg Loss =  0.26002\n",
      "Iteration 334800: Avg Loss =  0.26630\n",
      "Iteration 334900: Avg Loss =  0.25889\n",
      "Iteration 335000: Avg Loss =  0.27631\n",
      "Iteration 335100: Avg Loss =  0.32404\n",
      "Iteration 335200: Avg Loss =  0.27591\n",
      "Iteration 335300: Avg Loss =  0.25757\n",
      "Iteration 335400: Avg Loss =  0.30420\n",
      "Iteration 335500: Avg Loss =  0.26051\n",
      "Iteration 335600: Avg Loss =  0.26862\n",
      "Iteration 335700: Avg Loss =  0.26686\n",
      "Iteration 335800: Avg Loss =  0.24077\n",
      "Iteration 335900: Avg Loss =  0.25289\n",
      "Iteration 336000: Avg Loss =  0.24502\n",
      "Iteration 336100: Avg Loss =  0.23256\n",
      "Iteration 336200: Avg Loss =  0.26608\n",
      "Iteration 336300: Avg Loss =  0.29476\n",
      "Iteration 336400: Avg Loss =  0.28527\n",
      "Iteration 336500: Avg Loss =  0.35404\n",
      "Iteration 336600: Avg Loss =  0.29114\n",
      "Iteration 336700: Avg Loss =  0.24040\n",
      "Iteration 336800: Avg Loss =  0.28336\n",
      "Iteration 336900: Avg Loss =  0.29691\n",
      "Iteration 337000: Avg Loss =  0.28338\n",
      "Iteration 337100: Avg Loss =  0.28225\n",
      "Iteration 337200: Avg Loss =  0.29438\n",
      "Iteration 337300: Avg Loss =  0.26558\n",
      "Iteration 337400: Avg Loss =  0.25172\n",
      "Iteration 337500: Avg Loss =  0.28093\n",
      "Iteration 337600: Avg Loss =  0.23519\n",
      "Iteration 337700: Avg Loss =  0.25700\n",
      "Iteration 337800: Avg Loss =  0.23481\n",
      "Iteration 337900: Avg Loss =  0.31442\n",
      "Iteration 338000: Avg Loss =  0.26377\n",
      "Iteration 338100: Avg Loss =  0.28687\n",
      "Iteration 338200: Avg Loss =  0.26530\n",
      "Iteration 338300: Avg Loss =  0.29387\n",
      "Iteration 338400: Avg Loss =  0.26920\n",
      "Iteration 338500: Avg Loss =  0.30470\n",
      "Iteration 338600: Avg Loss =  0.25400\n",
      "Iteration 338700: Avg Loss =  0.25613\n",
      "Iteration 338800: Avg Loss =  0.28896\n",
      "Iteration 338900: Avg Loss =  0.28556\n",
      "Iteration 339000: Avg Loss =  0.26835\n",
      "Iteration 339100: Avg Loss =  0.27264\n",
      "Iteration 339200: Avg Loss =  0.30836\n",
      "Iteration 339300: Avg Loss =  0.25123\n",
      "Iteration 339400: Avg Loss =  0.29675\n",
      "Iteration 339500: Avg Loss =  0.26447\n",
      "Iteration 339600: Avg Loss =  0.26009\n",
      "Iteration 339700: Avg Loss =  0.31301\n",
      "Iteration 339800: Avg Loss =  0.26208\n",
      "Iteration 339900: Avg Loss =  0.25701\n",
      "Iteration 340000: Avg Loss =  0.30822\n",
      "Iteration 340100: Avg Loss =  0.26219\n",
      "Iteration 340200: Avg Loss =  0.26709\n",
      "Iteration 340300: Avg Loss =  0.26712\n",
      "Iteration 340400: Avg Loss =  0.29384\n",
      "Iteration 340500: Avg Loss =  0.30153\n",
      "Iteration 340600: Avg Loss =  0.29675\n",
      "Iteration 340700: Avg Loss =  0.25364\n",
      "Iteration 340800: Avg Loss =  0.26074\n",
      "Iteration 340900: Avg Loss =  0.28264\n",
      "Iteration 341000: Avg Loss =  0.29145\n",
      "Iteration 341100: Avg Loss =  0.24130\n",
      "Iteration 341200: Avg Loss =  0.28591\n",
      "Iteration 341300: Avg Loss =  0.24908\n",
      "Iteration 341400: Avg Loss =  0.25113\n",
      "Iteration 341500: Avg Loss =  0.30426\n",
      "Iteration 341600: Avg Loss =  0.28299\n",
      "Iteration 341700: Avg Loss =  0.25678\n",
      "Iteration 341800: Avg Loss =  0.27227\n",
      "Iteration 341900: Avg Loss =  0.24759\n",
      "Iteration 342000: Avg Loss =  0.24837\n",
      "Iteration 342100: Avg Loss =  0.22597\n",
      "Iteration 342200: Avg Loss =  0.25106\n",
      "Iteration 342300: Avg Loss =  0.25193\n",
      "Iteration 342400: Avg Loss =  0.26333\n",
      "Iteration 342500: Avg Loss =  0.25526\n",
      "Iteration 342600: Avg Loss =  0.28365\n",
      "Iteration 342700: Avg Loss =  0.28707\n",
      "Iteration 342800: Avg Loss =  0.25189\n",
      "Iteration 342900: Avg Loss =  0.27116\n",
      "Iteration 343000: Avg Loss =  0.29338\n",
      "Iteration 343100: Avg Loss =  0.30660\n",
      "Iteration 343200: Avg Loss =  0.22677\n",
      "Iteration 343300: Avg Loss =  0.28966\n",
      "Iteration 343400: Avg Loss =  0.24157\n",
      "Iteration 343500: Avg Loss =  0.27544\n",
      "Iteration 343600: Avg Loss =  0.26182\n",
      "Iteration 343700: Avg Loss =  0.25135\n",
      "Iteration 343800: Avg Loss =  0.22818\n",
      "Iteration 343900: Avg Loss =  0.27180\n",
      "Iteration 344000: Avg Loss =  0.29097\n",
      "Iteration 344100: Avg Loss =  0.26547\n",
      "Iteration 344200: Avg Loss =  0.28698\n",
      "Iteration 344300: Avg Loss =  0.26254\n",
      "Iteration 344400: Avg Loss =  0.27537\n",
      "Iteration 344500: Avg Loss =  0.25540\n",
      "Iteration 344600: Avg Loss =  0.23991\n",
      "Iteration 344700: Avg Loss =  0.27081\n",
      "Iteration 344800: Avg Loss =  0.30529\n",
      "Iteration 344900: Avg Loss =  0.24473\n",
      "Iteration 345000: Avg Loss =  0.31266\n",
      "Iteration 345100: Avg Loss =  0.26910\n",
      "Iteration 345200: Avg Loss =  0.26592\n",
      "Iteration 345300: Avg Loss =  0.27842\n",
      "Iteration 345400: Avg Loss =  0.30272\n",
      "Iteration 345500: Avg Loss =  0.26678\n",
      "Iteration 345600: Avg Loss =  0.22872\n",
      "Iteration 345700: Avg Loss =  0.25296\n",
      "Iteration 345800: Avg Loss =  0.25179\n",
      "Iteration 345900: Avg Loss =  0.27608\n",
      "Iteration 346000: Avg Loss =  0.24476\n",
      "Iteration 346100: Avg Loss =  0.25777\n",
      "Iteration 346200: Avg Loss =  0.25572\n",
      "Iteration 346300: Avg Loss =  0.30958\n",
      "Iteration 346400: Avg Loss =  0.32099\n",
      "Iteration 346500: Avg Loss =  0.29306\n",
      "Iteration 346600: Avg Loss =  0.27180\n",
      "Iteration 346700: Avg Loss =  0.25744\n",
      "Iteration 346800: Avg Loss =  0.31262\n",
      "Iteration 346900: Avg Loss =  0.29717\n",
      "Iteration 347000: Avg Loss =  0.24456\n",
      "Iteration 347100: Avg Loss =  0.25374\n",
      "Iteration 347200: Avg Loss =  0.27065\n",
      "Iteration 347300: Avg Loss =  0.27481\n",
      "Iteration 347400: Avg Loss =  0.26969\n",
      "Iteration 347500: Avg Loss =  0.29308\n",
      "Iteration 347600: Avg Loss =  0.28635\n",
      "Iteration 347700: Avg Loss =  0.29203\n",
      "Iteration 347800: Avg Loss =  0.24007\n",
      "Iteration 347900: Avg Loss =  0.29985\n",
      "Iteration 348000: Avg Loss =  0.26613\n",
      "Iteration 348100: Avg Loss =  0.29279\n",
      "Iteration 348200: Avg Loss =  0.26881\n",
      "Iteration 348300: Avg Loss =  0.27770\n",
      "Iteration 348400: Avg Loss =  0.28474\n",
      "Iteration 348500: Avg Loss =  0.27368\n",
      "Iteration 348600: Avg Loss =  0.28000\n",
      "Iteration 348700: Avg Loss =  0.26038\n",
      "Iteration 348800: Avg Loss =  0.26734\n",
      "Iteration 348900: Avg Loss =  0.27108\n",
      "Iteration 349000: Avg Loss =  0.25164\n",
      "Iteration 349100: Avg Loss =  0.25856\n",
      "Iteration 349200: Avg Loss =  0.29015\n",
      "Iteration 349300: Avg Loss =  0.27580\n",
      "Iteration 349400: Avg Loss =  0.23518\n",
      "Iteration 349500: Avg Loss =  0.24797\n",
      "Iteration 349600: Avg Loss =  0.25855\n",
      "Iteration 349700: Avg Loss =  0.31450\n",
      "Iteration 349800: Avg Loss =  0.28093\n",
      "Iteration 349900: Avg Loss =  0.25228\n",
      "Iteration 350000: Avg Loss =  0.30154\n",
      "Iteration 350100: Avg Loss =  0.23913\n",
      "Iteration 350200: Avg Loss =  0.25850\n",
      "Iteration 350300: Avg Loss =  0.34645\n",
      "Iteration 350400: Avg Loss =  0.29258\n",
      "Iteration 350500: Avg Loss =  0.25382\n",
      "Iteration 350600: Avg Loss =  0.26159\n",
      "Iteration 350700: Avg Loss =  0.24714\n",
      "Iteration 350800: Avg Loss =  0.27707\n",
      "Iteration 350900: Avg Loss =  0.22960\n",
      "Iteration 351000: Avg Loss =  0.27976\n",
      "Iteration 351100: Avg Loss =  0.25980\n",
      "Iteration 351200: Avg Loss =  0.27098\n",
      "Iteration 351300: Avg Loss =  0.26977\n",
      "Iteration 351400: Avg Loss =  0.28230\n",
      "Iteration 351500: Avg Loss =  0.24094\n",
      "Iteration 351600: Avg Loss =  0.28909\n",
      "Iteration 351700: Avg Loss =  0.24619\n",
      "Iteration 351800: Avg Loss =  0.24374\n",
      "Iteration 351900: Avg Loss =  0.28392\n",
      "Iteration 352000: Avg Loss =  0.28104\n",
      "Iteration 352100: Avg Loss =  0.29798\n",
      "Iteration 352200: Avg Loss =  0.26172\n",
      "Iteration 352300: Avg Loss =  0.27321\n",
      "Iteration 352400: Avg Loss =  0.29016\n",
      "Iteration 352500: Avg Loss =  0.29750\n",
      "Iteration 352600: Avg Loss =  0.27307\n",
      "Iteration 352700: Avg Loss =  0.25706\n",
      "Iteration 352800: Avg Loss =  0.30341\n",
      "Iteration 352900: Avg Loss =  0.25966\n",
      "Iteration 353000: Avg Loss =  0.25919\n",
      "Iteration 353100: Avg Loss =  0.25724\n",
      "Iteration 353200: Avg Loss =  0.24840\n",
      "Iteration 353300: Avg Loss =  0.30974\n",
      "Iteration 353400: Avg Loss =  0.28119\n",
      "Iteration 353500: Avg Loss =  0.24210\n",
      "Iteration 353600: Avg Loss =  0.24454\n",
      "Iteration 353700: Avg Loss =  0.26456\n",
      "Iteration 353800: Avg Loss =  0.22418\n",
      "Iteration 353900: Avg Loss =  0.28802\n",
      "Iteration 354000: Avg Loss =  0.30884\n",
      "Iteration 354100: Avg Loss =  0.24679\n",
      "Iteration 354200: Avg Loss =  0.27382\n",
      "Iteration 354300: Avg Loss =  0.23328\n",
      "Iteration 354400: Avg Loss =  0.22851\n",
      "Iteration 354500: Avg Loss =  0.28460\n",
      "Iteration 354600: Avg Loss =  0.26762\n",
      "Iteration 354700: Avg Loss =  0.27812\n",
      "Iteration 354800: Avg Loss =  0.27529\n",
      "Iteration 354900: Avg Loss =  0.23774\n",
      "Iteration 355000: Avg Loss =  0.24942\n",
      "Iteration 355100: Avg Loss =  0.25724\n",
      "Iteration 355200: Avg Loss =  0.29126\n",
      "Iteration 355300: Avg Loss =  0.27272\n",
      "Iteration 355400: Avg Loss =  0.26880\n",
      "Iteration 355500: Avg Loss =  0.26302\n",
      "Iteration 355600: Avg Loss =  0.24658\n",
      "Iteration 355700: Avg Loss =  0.24533\n",
      "Iteration 355800: Avg Loss =  0.26594\n",
      "Iteration 355900: Avg Loss =  0.25475\n",
      "Iteration 356000: Avg Loss =  0.24292\n",
      "Iteration 356100: Avg Loss =  0.29199\n",
      "Iteration 356200: Avg Loss =  0.26818\n",
      "Iteration 356300: Avg Loss =  0.25832\n",
      "Iteration 356400: Avg Loss =  0.25151\n",
      "Iteration 356500: Avg Loss =  0.27540\n",
      "Iteration 356600: Avg Loss =  0.27613\n",
      "Iteration 356700: Avg Loss =  0.28333\n",
      "Iteration 356800: Avg Loss =  0.29625\n",
      "Iteration 356900: Avg Loss =  0.28429\n",
      "Iteration 357000: Avg Loss =  0.27018\n",
      "Iteration 357100: Avg Loss =  0.23438\n",
      "Iteration 357200: Avg Loss =  0.27084\n",
      "Iteration 357300: Avg Loss =  0.30091\n",
      "Iteration 357400: Avg Loss =  0.25759\n",
      "Iteration 357500: Avg Loss =  0.24087\n",
      "Iteration 357600: Avg Loss =  0.25321\n",
      "Iteration 357700: Avg Loss =  0.28411\n",
      "Iteration 357800: Avg Loss =  0.25198\n",
      "Iteration 357900: Avg Loss =  0.28917\n",
      "Iteration 358000: Avg Loss =  0.26179\n",
      "Iteration 358100: Avg Loss =  0.28028\n",
      "Iteration 358200: Avg Loss =  0.26391\n",
      "Iteration 358300: Avg Loss =  0.28450\n",
      "Iteration 358400: Avg Loss =  0.24316\n",
      "Iteration 358500: Avg Loss =  0.27906\n",
      "Iteration 358600: Avg Loss =  0.25718\n",
      "Iteration 358700: Avg Loss =  0.25133\n",
      "Iteration 358800: Avg Loss =  0.25714\n",
      "Iteration 358900: Avg Loss =  0.23617\n",
      "Iteration 359000: Avg Loss =  0.23852\n",
      "Iteration 359100: Avg Loss =  0.31149\n",
      "Iteration 359200: Avg Loss =  0.27430\n",
      "Iteration 359300: Avg Loss =  0.29750\n",
      "Iteration 359400: Avg Loss =  0.27572\n",
      "Iteration 359500: Avg Loss =  0.26534\n",
      "Iteration 359600: Avg Loss =  0.25760\n",
      "Iteration 359700: Avg Loss =  0.27319\n",
      "Iteration 359800: Avg Loss =  0.29345\n",
      "Iteration 359900: Avg Loss =  0.27899\n",
      "Iteration 360000: Avg Loss =  0.26846\n",
      "Iteration 360100: Avg Loss =  0.33410\n",
      "Iteration 360200: Avg Loss =  0.25921\n",
      "Iteration 360300: Avg Loss =  0.23910\n",
      "Iteration 360400: Avg Loss =  0.28019\n",
      "Iteration 360500: Avg Loss =  0.26876\n",
      "Iteration 360600: Avg Loss =  0.24135\n",
      "Iteration 360700: Avg Loss =  0.29066\n",
      "Iteration 360800: Avg Loss =  0.24568\n",
      "Iteration 360900: Avg Loss =  0.25772\n",
      "Iteration 361000: Avg Loss =  0.27132\n",
      "Iteration 361100: Avg Loss =  0.28367\n",
      "Iteration 361200: Avg Loss =  0.28018\n",
      "Iteration 361300: Avg Loss =  0.25436\n",
      "Iteration 361400: Avg Loss =  0.25688\n",
      "Iteration 361500: Avg Loss =  0.28641\n",
      "Iteration 361600: Avg Loss =  0.29133\n",
      "Iteration 361700: Avg Loss =  0.22015\n",
      "Iteration 361800: Avg Loss =  0.27142\n",
      "Iteration 361900: Avg Loss =  0.31680\n",
      "Iteration 362000: Avg Loss =  0.24539\n",
      "Iteration 362100: Avg Loss =  0.24764\n",
      "Iteration 362200: Avg Loss =  0.31080\n",
      "Iteration 362300: Avg Loss =  0.30233\n",
      "Iteration 362400: Avg Loss =  0.23838\n",
      "Iteration 362500: Avg Loss =  0.26977\n",
      "Iteration 362600: Avg Loss =  0.25025\n",
      "Iteration 362700: Avg Loss =  0.27654\n",
      "Iteration 362800: Avg Loss =  0.27281\n",
      "Iteration 362900: Avg Loss =  0.27253\n",
      "Iteration 363000: Avg Loss =  0.27118\n",
      "Iteration 363100: Avg Loss =  0.26111\n",
      "Iteration 363200: Avg Loss =  0.23697\n",
      "Iteration 363300: Avg Loss =  0.27228\n",
      "Iteration 363400: Avg Loss =  0.29132\n",
      "Iteration 363500: Avg Loss =  0.26912\n",
      "Iteration 363600: Avg Loss =  0.27097\n",
      "Iteration 363700: Avg Loss =  0.24711\n",
      "Iteration 363800: Avg Loss =  0.28674\n",
      "Iteration 363900: Avg Loss =  0.28312\n",
      "Iteration 364000: Avg Loss =  0.23423\n",
      "Iteration 364100: Avg Loss =  0.26736\n",
      "Iteration 364200: Avg Loss =  0.26897\n",
      "Iteration 364300: Avg Loss =  0.27351\n",
      "Iteration 364400: Avg Loss =  0.27375\n",
      "Iteration 364500: Avg Loss =  0.27018\n",
      "Iteration 364600: Avg Loss =  0.28595\n",
      "Iteration 364700: Avg Loss =  0.23743\n",
      "Iteration 364800: Avg Loss =  0.25088\n",
      "Iteration 364900: Avg Loss =  0.23469\n",
      "Iteration 365000: Avg Loss =  0.29016\n",
      "Iteration 365100: Avg Loss =  0.28047\n",
      "Iteration 365200: Avg Loss =  0.25871\n",
      "Iteration 365300: Avg Loss =  0.25726\n",
      "Iteration 365400: Avg Loss =  0.28214\n",
      "Iteration 365500: Avg Loss =  0.26630\n",
      "Iteration 365600: Avg Loss =  0.25538\n",
      "Iteration 365700: Avg Loss =  0.26735\n",
      "Iteration 365800: Avg Loss =  0.28742\n",
      "Iteration 365900: Avg Loss =  0.27054\n",
      "Iteration 366000: Avg Loss =  0.28776\n",
      "Iteration 366100: Avg Loss =  0.21843\n",
      "Iteration 366200: Avg Loss =  0.22963\n",
      "Iteration 366300: Avg Loss =  0.26840\n",
      "Iteration 366400: Avg Loss =  0.29825\n",
      "Iteration 366500: Avg Loss =  0.26385\n",
      "Iteration 366600: Avg Loss =  0.27667\n",
      "Iteration 366700: Avg Loss =  0.23980\n",
      "Iteration 366800: Avg Loss =  0.26470\n",
      "Iteration 366900: Avg Loss =  0.25194\n",
      "Iteration 367000: Avg Loss =  0.25332\n",
      "Iteration 367100: Avg Loss =  0.27036\n",
      "Iteration 367200: Avg Loss =  0.27317\n",
      "Iteration 367300: Avg Loss =  0.25835\n",
      "Iteration 367400: Avg Loss =  0.23030\n",
      "Iteration 367500: Avg Loss =  0.28384\n",
      "Iteration 367600: Avg Loss =  0.28243\n",
      "Iteration 367700: Avg Loss =  0.23767\n",
      "Iteration 367800: Avg Loss =  0.29303\n",
      "Iteration 367900: Avg Loss =  0.26093\n",
      "Iteration 368000: Avg Loss =  0.27535\n",
      "Iteration 368100: Avg Loss =  0.30477\n",
      "Iteration 368200: Avg Loss =  0.23520\n",
      "Iteration 368300: Avg Loss =  0.27739\n",
      "Iteration 368400: Avg Loss =  0.27924\n",
      "Iteration 368500: Avg Loss =  0.22427\n",
      "Iteration 368600: Avg Loss =  0.25667\n",
      "Iteration 368700: Avg Loss =  0.25376\n",
      "Iteration 368800: Avg Loss =  0.25454\n",
      "Iteration 368900: Avg Loss =  0.26205\n",
      "Iteration 369000: Avg Loss =  0.25906\n",
      "Iteration 369100: Avg Loss =  0.25294\n",
      "Iteration 369200: Avg Loss =  0.21891\n",
      "Iteration 369300: Avg Loss =  0.24806\n",
      "Iteration 369400: Avg Loss =  0.21862\n",
      "Iteration 369500: Avg Loss =  0.29137\n",
      "Iteration 369600: Avg Loss =  0.26320\n",
      "Iteration 369700: Avg Loss =  0.23504\n",
      "Iteration 369800: Avg Loss =  0.28831\n",
      "Iteration 369900: Avg Loss =  0.26220\n",
      "Iteration 370000: Avg Loss =  0.27588\n",
      "Iteration 370100: Avg Loss =  0.26859\n",
      "Iteration 370200: Avg Loss =  0.24094\n",
      "Iteration 370300: Avg Loss =  0.29178\n",
      "Iteration 370400: Avg Loss =  0.27851\n",
      "Iteration 370500: Avg Loss =  0.29933\n",
      "Iteration 370600: Avg Loss =  0.26198\n",
      "Iteration 370700: Avg Loss =  0.30508\n",
      "Iteration 370800: Avg Loss =  0.26772\n",
      "Iteration 370900: Avg Loss =  0.27805\n",
      "Iteration 371000: Avg Loss =  0.23850\n",
      "Iteration 371100: Avg Loss =  0.28412\n",
      "Iteration 371200: Avg Loss =  0.26911\n",
      "Iteration 371300: Avg Loss =  0.28813\n",
      "Iteration 371400: Avg Loss =  0.26463\n",
      "Iteration 371500: Avg Loss =  0.25661\n",
      "Iteration 371600: Avg Loss =  0.23860\n",
      "Iteration 371700: Avg Loss =  0.29597\n",
      "Iteration 371800: Avg Loss =  0.29578\n",
      "Iteration 371900: Avg Loss =  0.24361\n",
      "Iteration 372000: Avg Loss =  0.26438\n",
      "Iteration 372100: Avg Loss =  0.25739\n",
      "Iteration 372200: Avg Loss =  0.27566\n",
      "Iteration 372300: Avg Loss =  0.28279\n",
      "Iteration 372400: Avg Loss =  0.25754\n",
      "Iteration 372500: Avg Loss =  0.28729\n",
      "Iteration 372600: Avg Loss =  0.29393\n",
      "Iteration 372700: Avg Loss =  0.21604\n",
      "Iteration 372800: Avg Loss =  0.22846\n",
      "Iteration 372900: Avg Loss =  0.25843\n",
      "Iteration 373000: Avg Loss =  0.26864\n",
      "Iteration 373100: Avg Loss =  0.25882\n",
      "Iteration 373200: Avg Loss =  0.25313\n",
      "Iteration 373300: Avg Loss =  0.25759\n",
      "Iteration 373400: Avg Loss =  0.27302\n",
      "Iteration 373500: Avg Loss =  0.24819\n",
      "Iteration 373600: Avg Loss =  0.26470\n",
      "Iteration 373700: Avg Loss =  0.25253\n",
      "Iteration 373800: Avg Loss =  0.24008\n",
      "Iteration 373900: Avg Loss =  0.22968\n",
      "Iteration 374000: Avg Loss =  0.26605\n",
      "Iteration 374100: Avg Loss =  0.21838\n",
      "Iteration 374200: Avg Loss =  0.25525\n",
      "Iteration 374300: Avg Loss =  0.26446\n",
      "Iteration 374400: Avg Loss =  0.27783\n",
      "Iteration 374500: Avg Loss =  0.30068\n",
      "Iteration 374600: Avg Loss =  0.27000\n",
      "Iteration 374700: Avg Loss =  0.27199\n",
      "Iteration 374800: Avg Loss =  0.23239\n",
      "Iteration 374900: Avg Loss =  0.27732\n",
      "Iteration 375000: Avg Loss =  0.25138\n",
      "Iteration 375100: Avg Loss =  0.24282\n",
      "Iteration 375200: Avg Loss =  0.28641\n",
      "Iteration 375300: Avg Loss =  0.24421\n",
      "Iteration 375400: Avg Loss =  0.24988\n",
      "Iteration 375500: Avg Loss =  0.24842\n",
      "Iteration 375600: Avg Loss =  0.24385\n",
      "Iteration 375700: Avg Loss =  0.29331\n",
      "Iteration 375800: Avg Loss =  0.25658\n",
      "Iteration 375900: Avg Loss =  0.25102\n",
      "Iteration 376000: Avg Loss =  0.30782\n",
      "Iteration 376100: Avg Loss =  0.25360\n",
      "Iteration 376200: Avg Loss =  0.26345\n",
      "Iteration 376300: Avg Loss =  0.29835\n",
      "Iteration 376400: Avg Loss =  0.26176\n",
      "Iteration 376500: Avg Loss =  0.25195\n",
      "Iteration 376600: Avg Loss =  0.23941\n",
      "Iteration 376700: Avg Loss =  0.23921\n",
      "Iteration 376800: Avg Loss =  0.26190\n",
      "Iteration 376900: Avg Loss =  0.24922\n",
      "Iteration 377000: Avg Loss =  0.27014\n",
      "Iteration 377100: Avg Loss =  0.24307\n",
      "Iteration 377200: Avg Loss =  0.27270\n",
      "Iteration 377300: Avg Loss =  0.30245\n",
      "Iteration 377400: Avg Loss =  0.24339\n",
      "Iteration 377500: Avg Loss =  0.25987\n",
      "Iteration 377600: Avg Loss =  0.26036\n",
      "Iteration 377700: Avg Loss =  0.23023\n",
      "Iteration 377800: Avg Loss =  0.24056\n",
      "Iteration 377900: Avg Loss =  0.28181\n",
      "Iteration 378000: Avg Loss =  0.23988\n",
      "Iteration 378100: Avg Loss =  0.25687\n",
      "Iteration 378200: Avg Loss =  0.28910\n",
      "Iteration 378300: Avg Loss =  0.29561\n",
      "Iteration 378400: Avg Loss =  0.27949\n",
      "Iteration 378500: Avg Loss =  0.24757\n",
      "Iteration 378600: Avg Loss =  0.26751\n",
      "Iteration 378700: Avg Loss =  0.25413\n",
      "Iteration 378800: Avg Loss =  0.27693\n",
      "Iteration 378900: Avg Loss =  0.26904\n",
      "Iteration 379000: Avg Loss =  0.30057\n",
      "Iteration 379100: Avg Loss =  0.26615\n",
      "Iteration 379200: Avg Loss =  0.27263\n",
      "Iteration 379300: Avg Loss =  0.28442\n",
      "Iteration 379400: Avg Loss =  0.23311\n",
      "Iteration 379500: Avg Loss =  0.23666\n",
      "Iteration 379600: Avg Loss =  0.26034\n",
      "Iteration 379700: Avg Loss =  0.25894\n",
      "Iteration 379800: Avg Loss =  0.23594\n",
      "Iteration 379900: Avg Loss =  0.26348\n",
      "Iteration 380000: Avg Loss =  0.24778\n",
      "Iteration 380100: Avg Loss =  0.27948\n",
      "Iteration 380200: Avg Loss =  0.25581\n",
      "Iteration 380300: Avg Loss =  0.28353\n",
      "Iteration 380400: Avg Loss =  0.26171\n",
      "Iteration 380500: Avg Loss =  0.24353\n",
      "Iteration 380600: Avg Loss =  0.26359\n",
      "Iteration 380700: Avg Loss =  0.27843\n",
      "Iteration 380800: Avg Loss =  0.22347\n",
      "Iteration 380900: Avg Loss =  0.24055\n",
      "Iteration 381000: Avg Loss =  0.28767\n",
      "Iteration 381100: Avg Loss =  0.24067\n",
      "Iteration 381200: Avg Loss =  0.25520\n",
      "Iteration 381300: Avg Loss =  0.32010\n",
      "Iteration 381400: Avg Loss =  0.29470\n",
      "Iteration 381500: Avg Loss =  0.28787\n",
      "Iteration 381600: Avg Loss =  0.24220\n",
      "Iteration 381700: Avg Loss =  0.23523\n",
      "Iteration 381800: Avg Loss =  0.23162\n",
      "Iteration 381900: Avg Loss =  0.27111\n",
      "Iteration 382000: Avg Loss =  0.24752\n",
      "Iteration 382100: Avg Loss =  0.24447\n",
      "Iteration 382200: Avg Loss =  0.21322\n",
      "Iteration 382300: Avg Loss =  0.29047\n",
      "Iteration 382400: Avg Loss =  0.30185\n",
      "Iteration 382500: Avg Loss =  0.27783\n",
      "Iteration 382600: Avg Loss =  0.28814\n",
      "Iteration 382700: Avg Loss =  0.21937\n",
      "Iteration 382800: Avg Loss =  0.26531\n",
      "Iteration 382900: Avg Loss =  0.26435\n",
      "Iteration 383000: Avg Loss =  0.24490\n",
      "Iteration 383100: Avg Loss =  0.25904\n",
      "Iteration 383200: Avg Loss =  0.27427\n",
      "Iteration 383300: Avg Loss =  0.22470\n",
      "Iteration 383400: Avg Loss =  0.24655\n",
      "Iteration 383500: Avg Loss =  0.24028\n",
      "Iteration 383600: Avg Loss =  0.25811\n",
      "Iteration 383700: Avg Loss =  0.28147\n",
      "Iteration 383800: Avg Loss =  0.23492\n",
      "Iteration 383900: Avg Loss =  0.23656\n",
      "Iteration 384000: Avg Loss =  0.30607\n",
      "Iteration 384100: Avg Loss =  0.27571\n",
      "Iteration 384200: Avg Loss =  0.24900\n",
      "Iteration 384300: Avg Loss =  0.24528\n",
      "Iteration 384400: Avg Loss =  0.23799\n",
      "Iteration 384500: Avg Loss =  0.23912\n",
      "Iteration 384600: Avg Loss =  0.25053\n",
      "Iteration 384700: Avg Loss =  0.28757\n",
      "Iteration 384800: Avg Loss =  0.26552\n",
      "Iteration 384900: Avg Loss =  0.32519\n",
      "Iteration 385000: Avg Loss =  0.24933\n",
      "Iteration 385100: Avg Loss =  0.25886\n",
      "Iteration 385200: Avg Loss =  0.28078\n",
      "Iteration 385300: Avg Loss =  0.28362\n",
      "Iteration 385400: Avg Loss =  0.24783\n",
      "Iteration 385500: Avg Loss =  0.27303\n",
      "Iteration 385600: Avg Loss =  0.25436\n",
      "Iteration 385700: Avg Loss =  0.28545\n",
      "Iteration 385800: Avg Loss =  0.23480\n",
      "Iteration 385900: Avg Loss =  0.28714\n",
      "Iteration 386000: Avg Loss =  0.23514\n",
      "Iteration 386100: Avg Loss =  0.26453\n",
      "Iteration 386200: Avg Loss =  0.25415\n",
      "Iteration 386300: Avg Loss =  0.28305\n",
      "Iteration 386400: Avg Loss =  0.25703\n",
      "Iteration 386500: Avg Loss =  0.26302\n",
      "Iteration 386600: Avg Loss =  0.24352\n",
      "Iteration 386700: Avg Loss =  0.23708\n",
      "Iteration 386800: Avg Loss =  0.24025\n",
      "Iteration 386900: Avg Loss =  0.29101\n",
      "Iteration 387000: Avg Loss =  0.28033\n",
      "Iteration 387100: Avg Loss =  0.23468\n",
      "Iteration 387200: Avg Loss =  0.26349\n",
      "Iteration 387300: Avg Loss =  0.23720\n",
      "Iteration 387400: Avg Loss =  0.22952\n",
      "Iteration 387500: Avg Loss =  0.28424\n",
      "Iteration 387600: Avg Loss =  0.24479\n",
      "Iteration 387700: Avg Loss =  0.24583\n",
      "Iteration 387800: Avg Loss =  0.23153\n",
      "Iteration 387900: Avg Loss =  0.21805\n",
      "Iteration 388000: Avg Loss =  0.26928\n",
      "Iteration 388100: Avg Loss =  0.29711\n",
      "Iteration 388200: Avg Loss =  0.22531\n",
      "Iteration 388300: Avg Loss =  0.23553\n",
      "Iteration 388400: Avg Loss =  0.24106\n",
      "Iteration 388500: Avg Loss =  0.23460\n",
      "Iteration 388600: Avg Loss =  0.28278\n",
      "Iteration 388700: Avg Loss =  0.29674\n",
      "Iteration 388800: Avg Loss =  0.23998\n",
      "Iteration 388900: Avg Loss =  0.28992\n",
      "Iteration 389000: Avg Loss =  0.25115\n",
      "Iteration 389100: Avg Loss =  0.27435\n",
      "Iteration 389200: Avg Loss =  0.21980\n",
      "Iteration 389300: Avg Loss =  0.22347\n",
      "Iteration 389400: Avg Loss =  0.25911\n",
      "Iteration 389500: Avg Loss =  0.25906\n",
      "Iteration 389600: Avg Loss =  0.25714\n",
      "Iteration 389700: Avg Loss =  0.25424\n",
      "Iteration 389800: Avg Loss =  0.24618\n",
      "Iteration 389900: Avg Loss =  0.23710\n",
      "Iteration 390000: Avg Loss =  0.27409\n",
      "Iteration 390100: Avg Loss =  0.30041\n",
      "Iteration 390200: Avg Loss =  0.26990\n",
      "Iteration 390300: Avg Loss =  0.26374\n",
      "Iteration 390400: Avg Loss =  0.29559\n",
      "Iteration 390500: Avg Loss =  0.25293\n",
      "Iteration 390600: Avg Loss =  0.28589\n",
      "Iteration 390700: Avg Loss =  0.25393\n",
      "Iteration 390800: Avg Loss =  0.26165\n",
      "Iteration 390900: Avg Loss =  0.26127\n",
      "Iteration 391000: Avg Loss =  0.27910\n",
      "Iteration 391100: Avg Loss =  0.23814\n",
      "Iteration 391200: Avg Loss =  0.24970\n",
      "Iteration 391300: Avg Loss =  0.25647\n",
      "Iteration 391400: Avg Loss =  0.24894\n",
      "Iteration 391500: Avg Loss =  0.24940\n",
      "Iteration 391600: Avg Loss =  0.25788\n",
      "Iteration 391700: Avg Loss =  0.26579\n",
      "Iteration 391800: Avg Loss =  0.27400\n",
      "Iteration 391900: Avg Loss =  0.28458\n",
      "Iteration 392000: Avg Loss =  0.25753\n",
      "Iteration 392100: Avg Loss =  0.28169\n",
      "Iteration 392200: Avg Loss =  0.25203\n",
      "Iteration 392300: Avg Loss =  0.25602\n",
      "Iteration 392400: Avg Loss =  0.26325\n",
      "Iteration 392500: Avg Loss =  0.28704\n",
      "Iteration 392600: Avg Loss =  0.25716\n",
      "Iteration 392700: Avg Loss =  0.22663\n",
      "Iteration 392800: Avg Loss =  0.29858\n",
      "Iteration 392900: Avg Loss =  0.24425\n",
      "Iteration 393000: Avg Loss =  0.26708\n",
      "Iteration 393100: Avg Loss =  0.25154\n",
      "Iteration 393200: Avg Loss =  0.25413\n",
      "Iteration 393300: Avg Loss =  0.30337\n",
      "Iteration 393400: Avg Loss =  0.24915\n",
      "Iteration 393500: Avg Loss =  0.25335\n",
      "Iteration 393600: Avg Loss =  0.23440\n",
      "Iteration 393700: Avg Loss =  0.25259\n",
      "Iteration 393800: Avg Loss =  0.27672\n",
      "Iteration 393900: Avg Loss =  0.28592\n",
      "Iteration 394000: Avg Loss =  0.25635\n",
      "Iteration 394100: Avg Loss =  0.31054\n",
      "Iteration 394200: Avg Loss =  0.29971\n",
      "Iteration 394300: Avg Loss =  0.25078\n",
      "Iteration 394400: Avg Loss =  0.27204\n",
      "Iteration 394500: Avg Loss =  0.23003\n",
      "Iteration 394600: Avg Loss =  0.25539\n",
      "Iteration 394700: Avg Loss =  0.26946\n",
      "Iteration 394800: Avg Loss =  0.25201\n",
      "Iteration 394900: Avg Loss =  0.27583\n",
      "Iteration 395000: Avg Loss =  0.25381\n",
      "Iteration 395100: Avg Loss =  0.29271\n",
      "Iteration 395200: Avg Loss =  0.26609\n",
      "Iteration 395300: Avg Loss =  0.25334\n",
      "Iteration 395400: Avg Loss =  0.24488\n",
      "Iteration 395500: Avg Loss =  0.27466\n",
      "Iteration 395600: Avg Loss =  0.22079\n",
      "Iteration 395700: Avg Loss =  0.26566\n",
      "Iteration 395800: Avg Loss =  0.24399\n",
      "Iteration 395900: Avg Loss =  0.26197\n",
      "Iteration 396000: Avg Loss =  0.28351\n",
      "Iteration 396100: Avg Loss =  0.31541\n",
      "Iteration 396200: Avg Loss =  0.27033\n",
      "Iteration 396300: Avg Loss =  0.30086\n",
      "Iteration 396400: Avg Loss =  0.22499\n",
      "Iteration 396500: Avg Loss =  0.25139\n",
      "Iteration 396600: Avg Loss =  0.24487\n",
      "Iteration 396700: Avg Loss =  0.28707\n",
      "Iteration 396800: Avg Loss =  0.30977\n",
      "Iteration 396900: Avg Loss =  0.25477\n",
      "Iteration 397000: Avg Loss =  0.28183\n",
      "Iteration 397100: Avg Loss =  0.25788\n",
      "Iteration 397200: Avg Loss =  0.27366\n",
      "Iteration 397300: Avg Loss =  0.24959\n",
      "Iteration 397400: Avg Loss =  0.28013\n",
      "Iteration 397500: Avg Loss =  0.24695\n",
      "Iteration 397600: Avg Loss =  0.23082\n",
      "Iteration 397700: Avg Loss =  0.24832\n",
      "Iteration 397800: Avg Loss =  0.24295\n",
      "Iteration 397900: Avg Loss =  0.22672\n",
      "Iteration 398000: Avg Loss =  0.23456\n",
      "Iteration 398100: Avg Loss =  0.28287\n",
      "Iteration 398200: Avg Loss =  0.21426\n",
      "Iteration 398300: Avg Loss =  0.25104\n",
      "Iteration 398400: Avg Loss =  0.27192\n",
      "Iteration 398500: Avg Loss =  0.27493\n",
      "Iteration 398600: Avg Loss =  0.24775\n",
      "Iteration 398700: Avg Loss =  0.22344\n",
      "Iteration 398800: Avg Loss =  0.25742\n",
      "Iteration 398900: Avg Loss =  0.26847\n",
      "Iteration 399000: Avg Loss =  0.26431\n",
      "Iteration 399100: Avg Loss =  0.24356\n",
      "Iteration 399200: Avg Loss =  0.25699\n",
      "Iteration 399300: Avg Loss =  0.25663\n",
      "Iteration 399400: Avg Loss =  0.25648\n",
      "Iteration 399500: Avg Loss =  0.29595\n",
      "Iteration 399600: Avg Loss =  0.26559\n",
      "Iteration 399700: Avg Loss =  0.26035\n",
      "Iteration 399800: Avg Loss =  0.26375\n",
      "Iteration 399900: Avg Loss =  0.21758\n",
      "Iteration 400000: Avg Loss =  0.29822\n",
      "Iteration 400100: Avg Loss =  0.29774\n",
      "Iteration 400200: Avg Loss =  0.27242\n",
      "Iteration 400300: Avg Loss =  0.23972\n",
      "Iteration 400400: Avg Loss =  0.25142\n",
      "Iteration 400500: Avg Loss =  0.23063\n",
      "Iteration 400600: Avg Loss =  0.25515\n",
      "Iteration 400700: Avg Loss =  0.26856\n",
      "Iteration 400800: Avg Loss =  0.24559\n",
      "Iteration 400900: Avg Loss =  0.25414\n",
      "Iteration 401000: Avg Loss =  0.26073\n",
      "Iteration 401100: Avg Loss =  0.28410\n",
      "Iteration 401200: Avg Loss =  0.23959\n",
      "Iteration 401300: Avg Loss =  0.24698\n",
      "Iteration 401400: Avg Loss =  0.25674\n",
      "Iteration 401500: Avg Loss =  0.22662\n",
      "Iteration 401600: Avg Loss =  0.24406\n",
      "Iteration 401700: Avg Loss =  0.24862\n",
      "Iteration 401800: Avg Loss =  0.28695\n",
      "Iteration 401900: Avg Loss =  0.25279\n",
      "Iteration 402000: Avg Loss =  0.24704\n",
      "Iteration 402100: Avg Loss =  0.28966\n",
      "Iteration 402200: Avg Loss =  0.28598\n",
      "Iteration 402300: Avg Loss =  0.25073\n",
      "Iteration 402400: Avg Loss =  0.26584\n",
      "Iteration 402500: Avg Loss =  0.24189\n",
      "Iteration 402600: Avg Loss =  0.27342\n",
      "Iteration 402700: Avg Loss =  0.24373\n",
      "Iteration 402800: Avg Loss =  0.24399\n",
      "Iteration 402900: Avg Loss =  0.29788\n",
      "Iteration 403000: Avg Loss =  0.24738\n",
      "Iteration 403100: Avg Loss =  0.23364\n",
      "Iteration 403200: Avg Loss =  0.22001\n",
      "Iteration 403300: Avg Loss =  0.25122\n",
      "Iteration 403400: Avg Loss =  0.23641\n",
      "Iteration 403500: Avg Loss =  0.30007\n",
      "Iteration 403600: Avg Loss =  0.23066\n",
      "Iteration 403700: Avg Loss =  0.26775\n",
      "Iteration 403800: Avg Loss =  0.27735\n",
      "Iteration 403900: Avg Loss =  0.26989\n",
      "Iteration 404000: Avg Loss =  0.22878\n",
      "Iteration 404100: Avg Loss =  0.27181\n",
      "Iteration 404200: Avg Loss =  0.25594\n",
      "Iteration 404300: Avg Loss =  0.24452\n",
      "Iteration 404400: Avg Loss =  0.27873\n",
      "Iteration 404500: Avg Loss =  0.28236\n",
      "Iteration 404600: Avg Loss =  0.23179\n",
      "Iteration 404700: Avg Loss =  0.25147\n",
      "Iteration 404800: Avg Loss =  0.24899\n",
      "Iteration 404900: Avg Loss =  0.28451\n",
      "Iteration 405000: Avg Loss =  0.25040\n",
      "Iteration 405100: Avg Loss =  0.24614\n",
      "Iteration 405200: Avg Loss =  0.23531\n",
      "Iteration 405300: Avg Loss =  0.25353\n",
      "Iteration 405400: Avg Loss =  0.28555\n",
      "Iteration 405500: Avg Loss =  0.26822\n",
      "Iteration 405600: Avg Loss =  0.19381\n",
      "Iteration 405700: Avg Loss =  0.27954\n",
      "Iteration 405800: Avg Loss =  0.28340\n",
      "Iteration 405900: Avg Loss =  0.27039\n",
      "Iteration 406000: Avg Loss =  0.27039\n",
      "Iteration 406100: Avg Loss =  0.22792\n",
      "Iteration 406200: Avg Loss =  0.25230\n",
      "Iteration 406300: Avg Loss =  0.25188\n",
      "Iteration 406400: Avg Loss =  0.22873\n",
      "Iteration 406500: Avg Loss =  0.28941\n",
      "Iteration 406600: Avg Loss =  0.24699\n",
      "Iteration 406700: Avg Loss =  0.23282\n",
      "Iteration 406800: Avg Loss =  0.24766\n",
      "Iteration 406900: Avg Loss =  0.24586\n",
      "Iteration 407000: Avg Loss =  0.23748\n",
      "Iteration 407100: Avg Loss =  0.25102\n",
      "Iteration 407200: Avg Loss =  0.30475\n",
      "Iteration 407300: Avg Loss =  0.29280\n",
      "Iteration 407400: Avg Loss =  0.22038\n",
      "Iteration 407500: Avg Loss =  0.24999\n",
      "Iteration 407600: Avg Loss =  0.27458\n",
      "Iteration 407700: Avg Loss =  0.24566\n",
      "Iteration 407800: Avg Loss =  0.25080\n",
      "Iteration 407900: Avg Loss =  0.25443\n",
      "Iteration 408000: Avg Loss =  0.22699\n",
      "Iteration 408100: Avg Loss =  0.29783\n",
      "Iteration 408200: Avg Loss =  0.26011\n",
      "Iteration 408300: Avg Loss =  0.23206\n",
      "Iteration 408400: Avg Loss =  0.23889\n",
      "Iteration 408500: Avg Loss =  0.22627\n",
      "Iteration 408600: Avg Loss =  0.24793\n",
      "Iteration 408700: Avg Loss =  0.25533\n",
      "Iteration 408800: Avg Loss =  0.25316\n",
      "Iteration 408900: Avg Loss =  0.27952\n",
      "Iteration 409000: Avg Loss =  0.26815\n",
      "Iteration 409100: Avg Loss =  0.26886\n",
      "Iteration 409200: Avg Loss =  0.26395\n",
      "Iteration 409300: Avg Loss =  0.26262\n",
      "Iteration 409400: Avg Loss =  0.25719\n",
      "Iteration 409500: Avg Loss =  0.28759\n",
      "Iteration 409600: Avg Loss =  0.26936\n",
      "Iteration 409700: Avg Loss =  0.23691\n",
      "Iteration 409800: Avg Loss =  0.26668\n",
      "Iteration 409900: Avg Loss =  0.23575\n",
      "Iteration 410000: Avg Loss =  0.25475\n",
      "Iteration 410100: Avg Loss =  0.23159\n",
      "Iteration 410200: Avg Loss =  0.28343\n",
      "Iteration 410300: Avg Loss =  0.27452\n",
      "Iteration 410400: Avg Loss =  0.27023\n",
      "Iteration 410500: Avg Loss =  0.22422\n",
      "Iteration 410600: Avg Loss =  0.24933\n",
      "Iteration 410700: Avg Loss =  0.22495\n",
      "Iteration 410800: Avg Loss =  0.24695\n",
      "Iteration 410900: Avg Loss =  0.25615\n",
      "Iteration 411000: Avg Loss =  0.26088\n",
      "Iteration 411100: Avg Loss =  0.29278\n",
      "Iteration 411200: Avg Loss =  0.24033\n",
      "Iteration 411300: Avg Loss =  0.28800\n",
      "Iteration 411400: Avg Loss =  0.23982\n",
      "Iteration 411500: Avg Loss =  0.22003\n",
      "Iteration 411600: Avg Loss =  0.22256\n",
      "Iteration 411700: Avg Loss =  0.24561\n",
      "Iteration 411800: Avg Loss =  0.22306\n",
      "Iteration 411900: Avg Loss =  0.30671\n",
      "Iteration 412000: Avg Loss =  0.26494\n",
      "Iteration 412100: Avg Loss =  0.20059\n",
      "Iteration 412200: Avg Loss =  0.25255\n",
      "Iteration 412300: Avg Loss =  0.29310\n",
      "Iteration 412400: Avg Loss =  0.25622\n",
      "Iteration 412500: Avg Loss =  0.24153\n",
      "Iteration 412600: Avg Loss =  0.23030\n",
      "Iteration 412700: Avg Loss =  0.25208\n",
      "Iteration 412800: Avg Loss =  0.26815\n",
      "Iteration 412900: Avg Loss =  0.26185\n",
      "Iteration 413000: Avg Loss =  0.25395\n",
      "Iteration 413100: Avg Loss =  0.29555\n",
      "Iteration 413200: Avg Loss =  0.27036\n",
      "Iteration 413300: Avg Loss =  0.24447\n",
      "Iteration 413400: Avg Loss =  0.22237\n",
      "Iteration 413500: Avg Loss =  0.21870\n",
      "Iteration 413600: Avg Loss =  0.24875\n",
      "Iteration 413700: Avg Loss =  0.25757\n",
      "Iteration 413800: Avg Loss =  0.26225\n",
      "Iteration 413900: Avg Loss =  0.29530\n",
      "Iteration 414000: Avg Loss =  0.24365\n",
      "Iteration 414100: Avg Loss =  0.25590\n",
      "Iteration 414200: Avg Loss =  0.25542\n",
      "Iteration 414300: Avg Loss =  0.24423\n",
      "Iteration 414400: Avg Loss =  0.24554\n",
      "Iteration 414500: Avg Loss =  0.27164\n",
      "Iteration 414600: Avg Loss =  0.25538\n",
      "Iteration 414700: Avg Loss =  0.29863\n",
      "Iteration 414800: Avg Loss =  0.22223\n",
      "Iteration 414900: Avg Loss =  0.28372\n",
      "Iteration 415000: Avg Loss =  0.22684\n",
      "Iteration 415100: Avg Loss =  0.23330\n",
      "Iteration 415200: Avg Loss =  0.25691\n",
      "Iteration 415300: Avg Loss =  0.23627\n",
      "Iteration 415400: Avg Loss =  0.27665\n",
      "Iteration 415500: Avg Loss =  0.26648\n",
      "Iteration 415600: Avg Loss =  0.24739\n",
      "Iteration 415700: Avg Loss =  0.24641\n",
      "Iteration 415800: Avg Loss =  0.25928\n",
      "Iteration 415900: Avg Loss =  0.22203\n",
      "Iteration 416000: Avg Loss =  0.27012\n",
      "Iteration 416100: Avg Loss =  0.22901\n",
      "Iteration 416200: Avg Loss =  0.24310\n",
      "Iteration 416300: Avg Loss =  0.27018\n",
      "Iteration 416400: Avg Loss =  0.26182\n",
      "Iteration 416500: Avg Loss =  0.25963\n",
      "Iteration 416600: Avg Loss =  0.24013\n",
      "Iteration 416700: Avg Loss =  0.28249\n",
      "Iteration 416800: Avg Loss =  0.23590\n",
      "Iteration 416900: Avg Loss =  0.24221\n",
      "Iteration 417000: Avg Loss =  0.28159\n",
      "Iteration 417100: Avg Loss =  0.21178\n",
      "Iteration 417200: Avg Loss =  0.26179\n",
      "Iteration 417300: Avg Loss =  0.28223\n",
      "Iteration 417400: Avg Loss =  0.25735\n",
      "Iteration 417500: Avg Loss =  0.26039\n",
      "Iteration 417600: Avg Loss =  0.27831\n",
      "Iteration 417700: Avg Loss =  0.23112\n",
      "Iteration 417800: Avg Loss =  0.22513\n",
      "Iteration 417900: Avg Loss =  0.25464\n",
      "Iteration 418000: Avg Loss =  0.26909\n",
      "Iteration 418100: Avg Loss =  0.25335\n",
      "Iteration 418200: Avg Loss =  0.24164\n",
      "Iteration 418300: Avg Loss =  0.22956\n",
      "Iteration 418400: Avg Loss =  0.31679\n",
      "Iteration 418500: Avg Loss =  0.26990\n",
      "Iteration 418600: Avg Loss =  0.24308\n",
      "Iteration 418700: Avg Loss =  0.26108\n",
      "Iteration 418800: Avg Loss =  0.20473\n",
      "Iteration 418900: Avg Loss =  0.21732\n",
      "Iteration 419000: Avg Loss =  0.22209\n",
      "Iteration 419100: Avg Loss =  0.22859\n",
      "Iteration 419200: Avg Loss =  0.25412\n",
      "Iteration 419300: Avg Loss =  0.26980\n",
      "Iteration 419400: Avg Loss =  0.32275\n",
      "Iteration 419500: Avg Loss =  0.29920\n",
      "Iteration 419600: Avg Loss =  0.25516\n",
      "Iteration 419700: Avg Loss =  0.20124\n",
      "Iteration 419800: Avg Loss =  0.26570\n",
      "Iteration 419900: Avg Loss =  0.23899\n",
      "Iteration 420000: Avg Loss =  0.25860\n",
      "Iteration 420100: Avg Loss =  0.24674\n",
      "Iteration 420200: Avg Loss =  0.25367\n",
      "Iteration 420300: Avg Loss =  0.26187\n",
      "Iteration 420400: Avg Loss =  0.23820\n",
      "Iteration 420500: Avg Loss =  0.24828\n",
      "Iteration 420600: Avg Loss =  0.24356\n",
      "Iteration 420700: Avg Loss =  0.23494\n",
      "Iteration 420800: Avg Loss =  0.25508\n",
      "Iteration 420900: Avg Loss =  0.26016\n",
      "Iteration 421000: Avg Loss =  0.27800\n",
      "Iteration 421100: Avg Loss =  0.30084\n",
      "Iteration 421200: Avg Loss =  0.27224\n",
      "Iteration 421300: Avg Loss =  0.25287\n",
      "Iteration 421400: Avg Loss =  0.28719\n",
      "Iteration 421500: Avg Loss =  0.28674\n",
      "Iteration 421600: Avg Loss =  0.24690\n",
      "Iteration 421700: Avg Loss =  0.22480\n",
      "Iteration 421800: Avg Loss =  0.24528\n",
      "Iteration 421900: Avg Loss =  0.28489\n",
      "Iteration 422000: Avg Loss =  0.24610\n",
      "Iteration 422100: Avg Loss =  0.24699\n",
      "Iteration 422200: Avg Loss =  0.23468\n",
      "Iteration 422300: Avg Loss =  0.26382\n",
      "Iteration 422400: Avg Loss =  0.23706\n",
      "Iteration 422500: Avg Loss =  0.23758\n",
      "Iteration 422600: Avg Loss =  0.26537\n",
      "Iteration 422700: Avg Loss =  0.24907\n",
      "Iteration 422800: Avg Loss =  0.22206\n",
      "Iteration 422900: Avg Loss =  0.25325\n",
      "Iteration 423000: Avg Loss =  0.27286\n",
      "Iteration 423100: Avg Loss =  0.23008\n",
      "Iteration 423200: Avg Loss =  0.24766\n",
      "Iteration 423300: Avg Loss =  0.26348\n",
      "Iteration 423400: Avg Loss =  0.25983\n",
      "Iteration 423500: Avg Loss =  0.23628\n",
      "Iteration 423600: Avg Loss =  0.25629\n",
      "Iteration 423700: Avg Loss =  0.25095\n",
      "Iteration 423800: Avg Loss =  0.20436\n",
      "Iteration 423900: Avg Loss =  0.25003\n",
      "Iteration 424000: Avg Loss =  0.22884\n",
      "Iteration 424100: Avg Loss =  0.25135\n",
      "Iteration 424200: Avg Loss =  0.24781\n",
      "Iteration 424300: Avg Loss =  0.31718\n",
      "Iteration 424400: Avg Loss =  0.20873\n",
      "Iteration 424500: Avg Loss =  0.23607\n",
      "Iteration 424600: Avg Loss =  0.26080\n",
      "Iteration 424700: Avg Loss =  0.23068\n",
      "Iteration 424800: Avg Loss =  0.24294\n",
      "Iteration 424900: Avg Loss =  0.29973\n",
      "Iteration 425000: Avg Loss =  0.20557\n",
      "Iteration 425100: Avg Loss =  0.27512\n",
      "Iteration 425200: Avg Loss =  0.25747\n",
      "Iteration 425300: Avg Loss =  0.23937\n",
      "Iteration 425400: Avg Loss =  0.23852\n",
      "Iteration 425500: Avg Loss =  0.23627\n",
      "Iteration 425600: Avg Loss =  0.25430\n",
      "Iteration 425700: Avg Loss =  0.25420\n",
      "Iteration 425800: Avg Loss =  0.26652\n",
      "Iteration 425900: Avg Loss =  0.26354\n",
      "Iteration 426000: Avg Loss =  0.27175\n",
      "Iteration 426100: Avg Loss =  0.26329\n",
      "Iteration 426200: Avg Loss =  0.27554\n",
      "Iteration 426300: Avg Loss =  0.21328\n",
      "Iteration 426400: Avg Loss =  0.22014\n",
      "Iteration 426500: Avg Loss =  0.25202\n",
      "Iteration 426600: Avg Loss =  0.30142\n",
      "Iteration 426700: Avg Loss =  0.29913\n",
      "Iteration 426800: Avg Loss =  0.29562\n",
      "Iteration 426900: Avg Loss =  0.24022\n",
      "Iteration 427000: Avg Loss =  0.28488\n",
      "Iteration 427100: Avg Loss =  0.24938\n",
      "Iteration 427200: Avg Loss =  0.24131\n",
      "Iteration 427300: Avg Loss =  0.23317\n",
      "Iteration 427400: Avg Loss =  0.26725\n",
      "Iteration 427500: Avg Loss =  0.22090\n",
      "Iteration 427600: Avg Loss =  0.22259\n",
      "Iteration 427700: Avg Loss =  0.26609\n",
      "Iteration 427800: Avg Loss =  0.28824\n",
      "Iteration 427900: Avg Loss =  0.22430\n",
      "Iteration 428000: Avg Loss =  0.29810\n",
      "Iteration 428100: Avg Loss =  0.23852\n",
      "Iteration 428200: Avg Loss =  0.26000\n",
      "Iteration 428300: Avg Loss =  0.20472\n",
      "Iteration 428400: Avg Loss =  0.21452\n",
      "Iteration 428500: Avg Loss =  0.25244\n",
      "Iteration 428600: Avg Loss =  0.24200\n",
      "Iteration 428700: Avg Loss =  0.23937\n",
      "Iteration 428800: Avg Loss =  0.23870\n",
      "Iteration 428900: Avg Loss =  0.23510\n",
      "Iteration 429000: Avg Loss =  0.20857\n",
      "Iteration 429100: Avg Loss =  0.19928\n",
      "Iteration 429200: Avg Loss =  0.25325\n",
      "Iteration 429300: Avg Loss =  0.25102\n",
      "Iteration 429400: Avg Loss =  0.22495\n",
      "Iteration 429500: Avg Loss =  0.22337\n",
      "Iteration 429600: Avg Loss =  0.25210\n",
      "Iteration 429700: Avg Loss =  0.20082\n",
      "Iteration 429800: Avg Loss =  0.26919\n",
      "Iteration 429900: Avg Loss =  0.27821\n",
      "Iteration 430000: Avg Loss =  0.25559\n",
      "Iteration 430100: Avg Loss =  0.25676\n",
      "Iteration 430200: Avg Loss =  0.26882\n",
      "Iteration 430300: Avg Loss =  0.25908\n",
      "Iteration 430400: Avg Loss =  0.25018\n",
      "Iteration 430500: Avg Loss =  0.22819\n",
      "Iteration 430600: Avg Loss =  0.26376\n",
      "Iteration 430700: Avg Loss =  0.26600\n",
      "Iteration 430800: Avg Loss =  0.25977\n",
      "Iteration 430900: Avg Loss =  0.24656\n",
      "Iteration 431000: Avg Loss =  0.25943\n",
      "Iteration 431100: Avg Loss =  0.25373\n",
      "Iteration 431200: Avg Loss =  0.21104\n",
      "Iteration 431300: Avg Loss =  0.22716\n",
      "Iteration 431400: Avg Loss =  0.28011\n",
      "Iteration 431500: Avg Loss =  0.26205\n",
      "Iteration 431600: Avg Loss =  0.21332\n",
      "Iteration 431700: Avg Loss =  0.27298\n",
      "Iteration 431800: Avg Loss =  0.23195\n",
      "Iteration 431900: Avg Loss =  0.25382\n",
      "Iteration 432000: Avg Loss =  0.29165\n",
      "Iteration 432100: Avg Loss =  0.23639\n",
      "Iteration 432200: Avg Loss =  0.24723\n",
      "Iteration 432300: Avg Loss =  0.22672\n",
      "Iteration 432400: Avg Loss =  0.24194\n",
      "Iteration 432500: Avg Loss =  0.23569\n",
      "Iteration 432600: Avg Loss =  0.25951\n",
      "Iteration 432700: Avg Loss =  0.23537\n",
      "Iteration 432800: Avg Loss =  0.27520\n",
      "Iteration 432900: Avg Loss =  0.23858\n",
      "Iteration 433000: Avg Loss =  0.25116\n",
      "Iteration 433100: Avg Loss =  0.22012\n",
      "Iteration 433200: Avg Loss =  0.21774\n",
      "Iteration 433300: Avg Loss =  0.25170\n",
      "Iteration 433400: Avg Loss =  0.25683\n",
      "Iteration 433500: Avg Loss =  0.23008\n",
      "Iteration 433600: Avg Loss =  0.25035\n",
      "Iteration 433700: Avg Loss =  0.20814\n",
      "Iteration 433800: Avg Loss =  0.30866\n",
      "Iteration 433900: Avg Loss =  0.25143\n",
      "Iteration 434000: Avg Loss =  0.23124\n",
      "Iteration 434100: Avg Loss =  0.23420\n",
      "Iteration 434200: Avg Loss =  0.25975\n",
      "Iteration 434300: Avg Loss =  0.25545\n",
      "Iteration 434400: Avg Loss =  0.24740\n",
      "Iteration 434500: Avg Loss =  0.23499\n",
      "Iteration 434600: Avg Loss =  0.26056\n",
      "Iteration 434700: Avg Loss =  0.25578\n",
      "Iteration 434800: Avg Loss =  0.24739\n",
      "Iteration 434900: Avg Loss =  0.24963\n",
      "Iteration 435000: Avg Loss =  0.27073\n",
      "Iteration 435100: Avg Loss =  0.20354\n",
      "Iteration 435200: Avg Loss =  0.24426\n",
      "Iteration 435300: Avg Loss =  0.22004\n",
      "Iteration 435400: Avg Loss =  0.23727\n",
      "Iteration 435500: Avg Loss =  0.26987\n",
      "Iteration 435600: Avg Loss =  0.26536\n",
      "Iteration 435700: Avg Loss =  0.23970\n",
      "Iteration 435800: Avg Loss =  0.25064\n",
      "Iteration 435900: Avg Loss =  0.24610\n",
      "Iteration 436000: Avg Loss =  0.22896\n",
      "Iteration 436100: Avg Loss =  0.24658\n",
      "Iteration 436200: Avg Loss =  0.22204\n",
      "Iteration 436300: Avg Loss =  0.22632\n",
      "Iteration 436400: Avg Loss =  0.20612\n",
      "Iteration 436500: Avg Loss =  0.23866\n",
      "Iteration 436600: Avg Loss =  0.24027\n",
      "Iteration 436700: Avg Loss =  0.24420\n",
      "Iteration 436800: Avg Loss =  0.22304\n",
      "Iteration 436900: Avg Loss =  0.25798\n",
      "Iteration 437000: Avg Loss =  0.22929\n",
      "Iteration 437100: Avg Loss =  0.27634\n",
      "Iteration 437200: Avg Loss =  0.28707\n",
      "Iteration 437300: Avg Loss =  0.26242\n",
      "Iteration 437400: Avg Loss =  0.20269\n",
      "Iteration 437500: Avg Loss =  0.24462\n",
      "Iteration 437600: Avg Loss =  0.23378\n",
      "Iteration 437700: Avg Loss =  0.25429\n",
      "Iteration 437800: Avg Loss =  0.24273\n",
      "Iteration 437900: Avg Loss =  0.23382\n",
      "Iteration 438000: Avg Loss =  0.26680\n",
      "Iteration 438100: Avg Loss =  0.25908\n",
      "Iteration 438200: Avg Loss =  0.22985\n",
      "Iteration 438300: Avg Loss =  0.28076\n",
      "Iteration 438400: Avg Loss =  0.20513\n",
      "Iteration 438500: Avg Loss =  0.24484\n",
      "Iteration 438600: Avg Loss =  0.23981\n",
      "Iteration 438700: Avg Loss =  0.24300\n",
      "Iteration 438800: Avg Loss =  0.26984\n",
      "Iteration 438900: Avg Loss =  0.24323\n",
      "Iteration 439000: Avg Loss =  0.28711\n",
      "Iteration 439100: Avg Loss =  0.27019\n",
      "Iteration 439200: Avg Loss =  0.25150\n",
      "Iteration 439300: Avg Loss =  0.22076\n",
      "Iteration 439400: Avg Loss =  0.25247\n",
      "Iteration 439500: Avg Loss =  0.24224\n",
      "Iteration 439600: Avg Loss =  0.25812\n",
      "Iteration 439700: Avg Loss =  0.21124\n",
      "Iteration 439800: Avg Loss =  0.25033\n",
      "Iteration 439900: Avg Loss =  0.26076\n",
      "Iteration 440000: Avg Loss =  0.28687\n",
      "Iteration 440100: Avg Loss =  0.22744\n",
      "Iteration 440200: Avg Loss =  0.24205\n",
      "Iteration 440300: Avg Loss =  0.22135\n",
      "Iteration 440400: Avg Loss =  0.29893\n",
      "Iteration 440500: Avg Loss =  0.28514\n",
      "Iteration 440600: Avg Loss =  0.27867\n",
      "Iteration 440700: Avg Loss =  0.23511\n",
      "Iteration 440800: Avg Loss =  0.23530\n",
      "Iteration 440900: Avg Loss =  0.21477\n",
      "Iteration 441000: Avg Loss =  0.25171\n",
      "Iteration 441100: Avg Loss =  0.23264\n",
      "Iteration 441200: Avg Loss =  0.23217\n",
      "Iteration 441300: Avg Loss =  0.25197\n",
      "Iteration 441400: Avg Loss =  0.24796\n",
      "Iteration 441500: Avg Loss =  0.28416\n",
      "Iteration 441600: Avg Loss =  0.25069\n",
      "Iteration 441700: Avg Loss =  0.25382\n",
      "Iteration 441800: Avg Loss =  0.22698\n",
      "Iteration 441900: Avg Loss =  0.24839\n",
      "Iteration 442000: Avg Loss =  0.22901\n",
      "Iteration 442100: Avg Loss =  0.22984\n",
      "Iteration 442200: Avg Loss =  0.23868\n",
      "Iteration 442300: Avg Loss =  0.26387\n",
      "Iteration 442400: Avg Loss =  0.24863\n",
      "Iteration 442500: Avg Loss =  0.26014\n",
      "Iteration 442600: Avg Loss =  0.23058\n",
      "Iteration 442700: Avg Loss =  0.25246\n",
      "Iteration 442800: Avg Loss =  0.23047\n",
      "Iteration 442900: Avg Loss =  0.21582\n",
      "Iteration 443000: Avg Loss =  0.25368\n",
      "Iteration 443100: Avg Loss =  0.22968\n",
      "Iteration 443200: Avg Loss =  0.22345\n",
      "Iteration 443300: Avg Loss =  0.26768\n",
      "Iteration 443400: Avg Loss =  0.27407\n",
      "Iteration 443500: Avg Loss =  0.27033\n",
      "Iteration 443600: Avg Loss =  0.24189\n",
      "Iteration 443700: Avg Loss =  0.25654\n",
      "Iteration 443800: Avg Loss =  0.23299\n",
      "Iteration 443900: Avg Loss =  0.24587\n",
      "Iteration 444000: Avg Loss =  0.24885\n",
      "Iteration 444100: Avg Loss =  0.27824\n",
      "Iteration 444200: Avg Loss =  0.23094\n",
      "Iteration 444300: Avg Loss =  0.23796\n",
      "Iteration 444400: Avg Loss =  0.22200\n",
      "Iteration 444500: Avg Loss =  0.22859\n",
      "Iteration 444600: Avg Loss =  0.24892\n",
      "Iteration 444700: Avg Loss =  0.23119\n",
      "Iteration 444800: Avg Loss =  0.26156\n",
      "Iteration 444900: Avg Loss =  0.20020\n",
      "Iteration 445000: Avg Loss =  0.28829\n",
      "Iteration 445100: Avg Loss =  0.22755\n",
      "Iteration 445200: Avg Loss =  0.26368\n",
      "Iteration 445300: Avg Loss =  0.27486\n",
      "Iteration 445400: Avg Loss =  0.27979\n",
      "Iteration 445500: Avg Loss =  0.21677\n",
      "Iteration 445600: Avg Loss =  0.23684\n",
      "Iteration 445700: Avg Loss =  0.22479\n",
      "Iteration 445800: Avg Loss =  0.21728\n",
      "Iteration 445900: Avg Loss =  0.24278\n",
      "Iteration 446000: Avg Loss =  0.24556\n",
      "Iteration 446100: Avg Loss =  0.28366\n",
      "Iteration 446200: Avg Loss =  0.24228\n",
      "Iteration 446300: Avg Loss =  0.25701\n",
      "Iteration 446400: Avg Loss =  0.24991\n",
      "Iteration 446500: Avg Loss =  0.23960\n",
      "Iteration 446600: Avg Loss =  0.25140\n",
      "Iteration 446700: Avg Loss =  0.24424\n",
      "Iteration 446800: Avg Loss =  0.25702\n",
      "Iteration 446900: Avg Loss =  0.24940\n",
      "Iteration 447000: Avg Loss =  0.23136\n",
      "Iteration 447100: Avg Loss =  0.24327\n",
      "Iteration 447200: Avg Loss =  0.24102\n",
      "Iteration 447300: Avg Loss =  0.21656\n",
      "Iteration 447400: Avg Loss =  0.25311\n",
      "Iteration 447500: Avg Loss =  0.22653\n",
      "Iteration 447600: Avg Loss =  0.30669\n",
      "Iteration 447700: Avg Loss =  0.22592\n",
      "Iteration 447800: Avg Loss =  0.22314\n",
      "Iteration 447900: Avg Loss =  0.21672\n",
      "Iteration 448000: Avg Loss =  0.24335\n",
      "Iteration 448100: Avg Loss =  0.23360\n",
      "Iteration 448200: Avg Loss =  0.28386\n",
      "Iteration 448300: Avg Loss =  0.22025\n",
      "Iteration 448400: Avg Loss =  0.28723\n",
      "Iteration 448500: Avg Loss =  0.26549\n",
      "Iteration 448600: Avg Loss =  0.21573\n",
      "Iteration 448700: Avg Loss =  0.23276\n",
      "Iteration 448800: Avg Loss =  0.21340\n",
      "Iteration 448900: Avg Loss =  0.27102\n",
      "Iteration 449000: Avg Loss =  0.24252\n",
      "Iteration 449100: Avg Loss =  0.24852\n",
      "Iteration 449200: Avg Loss =  0.20409\n",
      "Iteration 449300: Avg Loss =  0.24442\n",
      "Iteration 449400: Avg Loss =  0.26464\n",
      "Iteration 449500: Avg Loss =  0.22121\n",
      "Iteration 449600: Avg Loss =  0.21503\n",
      "Iteration 449700: Avg Loss =  0.26191\n",
      "Iteration 449800: Avg Loss =  0.23930\n",
      "Iteration 449900: Avg Loss =  0.24893\n",
      "Iteration 450000: Avg Loss =  0.22568\n",
      "Iteration 450100: Avg Loss =  0.25408\n",
      "Iteration 450200: Avg Loss =  0.24399\n",
      "Iteration 450300: Avg Loss =  0.23471\n",
      "Iteration 450400: Avg Loss =  0.27078\n",
      "Iteration 450500: Avg Loss =  0.26393\n",
      "Iteration 450600: Avg Loss =  0.20099\n",
      "Iteration 450700: Avg Loss =  0.24402\n",
      "Iteration 450800: Avg Loss =  0.27121\n",
      "Iteration 450900: Avg Loss =  0.23582\n",
      "Iteration 451000: Avg Loss =  0.22972\n",
      "Iteration 451100: Avg Loss =  0.21531\n",
      "Iteration 451200: Avg Loss =  0.22508\n",
      "Iteration 451300: Avg Loss =  0.28212\n",
      "Iteration 451400: Avg Loss =  0.25789\n",
      "Iteration 451500: Avg Loss =  0.23587\n",
      "Iteration 451600: Avg Loss =  0.22823\n",
      "Iteration 451700: Avg Loss =  0.25629\n",
      "Iteration 451800: Avg Loss =  0.23419\n",
      "Iteration 451900: Avg Loss =  0.21818\n",
      "Iteration 452000: Avg Loss =  0.22751\n",
      "Iteration 452100: Avg Loss =  0.25086\n",
      "Iteration 452200: Avg Loss =  0.25574\n",
      "Iteration 452300: Avg Loss =  0.20400\n",
      "Iteration 452400: Avg Loss =  0.27274\n",
      "Iteration 452500: Avg Loss =  0.23983\n",
      "Iteration 452600: Avg Loss =  0.23293\n",
      "Iteration 452700: Avg Loss =  0.21348\n",
      "Iteration 452800: Avg Loss =  0.20932\n",
      "Iteration 452900: Avg Loss =  0.30729\n",
      "Iteration 453000: Avg Loss =  0.24950\n",
      "Iteration 453100: Avg Loss =  0.22882\n",
      "Iteration 453200: Avg Loss =  0.25816\n",
      "Iteration 453300: Avg Loss =  0.20114\n",
      "Iteration 453400: Avg Loss =  0.22463\n",
      "Iteration 453500: Avg Loss =  0.25640\n",
      "Iteration 453600: Avg Loss =  0.23382\n",
      "Iteration 453700: Avg Loss =  0.20334\n",
      "Iteration 453800: Avg Loss =  0.24617\n",
      "Iteration 453900: Avg Loss =  0.24963\n",
      "Iteration 454000: Avg Loss =  0.26572\n",
      "Iteration 454100: Avg Loss =  0.25557\n",
      "Iteration 454200: Avg Loss =  0.24862\n",
      "Iteration 454300: Avg Loss =  0.29315\n",
      "Iteration 454400: Avg Loss =  0.24780\n",
      "Iteration 454500: Avg Loss =  0.22188\n",
      "Iteration 454600: Avg Loss =  0.25198\n",
      "Iteration 454700: Avg Loss =  0.21821\n",
      "Iteration 454800: Avg Loss =  0.27071\n",
      "Iteration 454900: Avg Loss =  0.22801\n",
      "Iteration 455000: Avg Loss =  0.23414\n",
      "Iteration 455100: Avg Loss =  0.28262\n",
      "Iteration 455200: Avg Loss =  0.21494\n",
      "Iteration 455300: Avg Loss =  0.24533\n",
      "Iteration 455400: Avg Loss =  0.25235\n",
      "Iteration 455500: Avg Loss =  0.23817\n",
      "Iteration 455600: Avg Loss =  0.24624\n",
      "Iteration 455700: Avg Loss =  0.24009\n",
      "Iteration 455800: Avg Loss =  0.24930\n",
      "Iteration 455900: Avg Loss =  0.26898\n",
      "Iteration 456000: Avg Loss =  0.27551\n",
      "Iteration 456100: Avg Loss =  0.23997\n",
      "Iteration 456200: Avg Loss =  0.25660\n",
      "Iteration 456300: Avg Loss =  0.26470\n",
      "Iteration 456400: Avg Loss =  0.24329\n",
      "Iteration 456500: Avg Loss =  0.22355\n",
      "Iteration 456600: Avg Loss =  0.22352\n",
      "Iteration 456700: Avg Loss =  0.23820\n",
      "Iteration 456800: Avg Loss =  0.28814\n",
      "Iteration 456900: Avg Loss =  0.28705\n",
      "Iteration 457000: Avg Loss =  0.23662\n",
      "Iteration 457100: Avg Loss =  0.25366\n",
      "Iteration 457200: Avg Loss =  0.27737\n",
      "Iteration 457300: Avg Loss =  0.28353\n",
      "Iteration 457400: Avg Loss =  0.22873\n",
      "Iteration 457500: Avg Loss =  0.27348\n",
      "Iteration 457600: Avg Loss =  0.25413\n",
      "Iteration 457700: Avg Loss =  0.23032\n",
      "Iteration 457800: Avg Loss =  0.25530\n",
      "Iteration 457900: Avg Loss =  0.27282\n",
      "Iteration 458000: Avg Loss =  0.30475\n",
      "Iteration 458100: Avg Loss =  0.24634\n",
      "Iteration 458200: Avg Loss =  0.21386\n",
      "Iteration 458300: Avg Loss =  0.20997\n",
      "Iteration 458400: Avg Loss =  0.24161\n",
      "Iteration 458500: Avg Loss =  0.23788\n",
      "Iteration 458600: Avg Loss =  0.27396\n",
      "Iteration 458700: Avg Loss =  0.23896\n",
      "Iteration 458800: Avg Loss =  0.23045\n",
      "Iteration 458900: Avg Loss =  0.23436\n",
      "Iteration 459000: Avg Loss =  0.26843\n",
      "Iteration 459100: Avg Loss =  0.26889\n",
      "Iteration 459200: Avg Loss =  0.24830\n",
      "Iteration 459300: Avg Loss =  0.23834\n",
      "Iteration 459400: Avg Loss =  0.25499\n",
      "Iteration 459500: Avg Loss =  0.23211\n",
      "Iteration 459600: Avg Loss =  0.23916\n",
      "Iteration 459700: Avg Loss =  0.24078\n",
      "Iteration 459800: Avg Loss =  0.22433\n",
      "Iteration 459900: Avg Loss =  0.23481\n",
      "Iteration 460000: Avg Loss =  0.21903\n",
      "Iteration 460100: Avg Loss =  0.25158\n",
      "Iteration 460200: Avg Loss =  0.22047\n",
      "Iteration 460300: Avg Loss =  0.26383\n",
      "Iteration 460400: Avg Loss =  0.23106\n",
      "Iteration 460500: Avg Loss =  0.28230\n",
      "Iteration 460600: Avg Loss =  0.20363\n",
      "Iteration 460700: Avg Loss =  0.25557\n",
      "Iteration 460800: Avg Loss =  0.23600\n",
      "Iteration 460900: Avg Loss =  0.23726\n",
      "Iteration 461000: Avg Loss =  0.21340\n",
      "Iteration 461100: Avg Loss =  0.21798\n",
      "Iteration 461200: Avg Loss =  0.22335\n",
      "Iteration 461300: Avg Loss =  0.22878\n",
      "Iteration 461400: Avg Loss =  0.24760\n",
      "Iteration 461500: Avg Loss =  0.23716\n",
      "Iteration 461600: Avg Loss =  0.25567\n",
      "Iteration 461700: Avg Loss =  0.25380\n",
      "Iteration 461800: Avg Loss =  0.29412\n",
      "Iteration 461900: Avg Loss =  0.24870\n",
      "Iteration 462000: Avg Loss =  0.27081\n",
      "Iteration 462100: Avg Loss =  0.22366\n",
      "Iteration 462200: Avg Loss =  0.23638\n",
      "Iteration 462300: Avg Loss =  0.25630\n",
      "Iteration 462400: Avg Loss =  0.26139\n",
      "Iteration 462500: Avg Loss =  0.21709\n",
      "Iteration 462600: Avg Loss =  0.24311\n",
      "Iteration 462700: Avg Loss =  0.25489\n",
      "Iteration 462800: Avg Loss =  0.24840\n",
      "Iteration 462900: Avg Loss =  0.28228\n",
      "Iteration 463000: Avg Loss =  0.24239\n",
      "Iteration 463100: Avg Loss =  0.24823\n",
      "Iteration 463200: Avg Loss =  0.21119\n",
      "Iteration 463300: Avg Loss =  0.18737\n",
      "Iteration 463400: Avg Loss =  0.25212\n",
      "Iteration 463500: Avg Loss =  0.25004\n",
      "Iteration 463600: Avg Loss =  0.23633\n",
      "Iteration 463700: Avg Loss =  0.24205\n",
      "Iteration 463800: Avg Loss =  0.24053\n",
      "Iteration 463900: Avg Loss =  0.26620\n",
      "Iteration 464000: Avg Loss =  0.22869\n",
      "Iteration 464100: Avg Loss =  0.21965\n",
      "Iteration 464200: Avg Loss =  0.25046\n",
      "Iteration 464300: Avg Loss =  0.21057\n",
      "Iteration 464400: Avg Loss =  0.23730\n",
      "Iteration 464500: Avg Loss =  0.27968\n",
      "Iteration 464600: Avg Loss =  0.25215\n",
      "Iteration 464700: Avg Loss =  0.21507\n",
      "Iteration 464800: Avg Loss =  0.23442\n",
      "Iteration 464900: Avg Loss =  0.22517\n",
      "Iteration 465000: Avg Loss =  0.28018\n",
      "Iteration 465100: Avg Loss =  0.27613\n",
      "Iteration 465200: Avg Loss =  0.21971\n",
      "Iteration 465300: Avg Loss =  0.27025\n",
      "Iteration 465400: Avg Loss =  0.24364\n",
      "Iteration 465500: Avg Loss =  0.24867\n",
      "Iteration 465600: Avg Loss =  0.20054\n",
      "Iteration 465700: Avg Loss =  0.25403\n",
      "Iteration 465800: Avg Loss =  0.22132\n",
      "Iteration 465900: Avg Loss =  0.25560\n",
      "Iteration 466000: Avg Loss =  0.26190\n",
      "Iteration 466100: Avg Loss =  0.26432\n",
      "Iteration 466200: Avg Loss =  0.26990\n",
      "Iteration 466300: Avg Loss =  0.25824\n",
      "Iteration 466400: Avg Loss =  0.28132\n",
      "Iteration 466500: Avg Loss =  0.26826\n",
      "Iteration 466600: Avg Loss =  0.25798\n",
      "Iteration 466700: Avg Loss =  0.23318\n",
      "Iteration 466800: Avg Loss =  0.18772\n",
      "Iteration 466900: Avg Loss =  0.22639\n",
      "Iteration 467000: Avg Loss =  0.25668\n",
      "Iteration 467100: Avg Loss =  0.26404\n",
      "Iteration 467200: Avg Loss =  0.25056\n",
      "Iteration 467300: Avg Loss =  0.22896\n",
      "Iteration 467400: Avg Loss =  0.25305\n",
      "Iteration 467500: Avg Loss =  0.24433\n",
      "Iteration 467600: Avg Loss =  0.21816\n",
      "Iteration 467700: Avg Loss =  0.27821\n",
      "Iteration 467800: Avg Loss =  0.23755\n",
      "Iteration 467900: Avg Loss =  0.24747\n",
      "Iteration 468000: Avg Loss =  0.23089\n",
      "Iteration 468100: Avg Loss =  0.25114\n",
      "Iteration 468200: Avg Loss =  0.22800\n",
      "Iteration 468300: Avg Loss =  0.21939\n",
      "Iteration 468400: Avg Loss =  0.20910\n",
      "Iteration 468500: Avg Loss =  0.23805\n",
      "Iteration 468600: Avg Loss =  0.22218\n",
      "Iteration 468700: Avg Loss =  0.19008\n",
      "Iteration 468800: Avg Loss =  0.27321\n",
      "Iteration 468900: Avg Loss =  0.26239\n",
      "Iteration 469000: Avg Loss =  0.23152\n",
      "Iteration 469100: Avg Loss =  0.22709\n",
      "Iteration 469200: Avg Loss =  0.21481\n",
      "Iteration 469300: Avg Loss =  0.22125\n",
      "Iteration 469400: Avg Loss =  0.25072\n",
      "Iteration 469500: Avg Loss =  0.22153\n",
      "Iteration 469600: Avg Loss =  0.27071\n",
      "Iteration 469700: Avg Loss =  0.23348\n",
      "Iteration 469800: Avg Loss =  0.22131\n",
      "Iteration 469900: Avg Loss =  0.25323\n",
      "Iteration 470000: Avg Loss =  0.28673\n",
      "Iteration 470100: Avg Loss =  0.28147\n",
      "Iteration 470200: Avg Loss =  0.25989\n",
      "Iteration 470300: Avg Loss =  0.23488\n",
      "Iteration 470400: Avg Loss =  0.23793\n",
      "Iteration 470500: Avg Loss =  0.26090\n",
      "Iteration 470600: Avg Loss =  0.20432\n",
      "Iteration 470700: Avg Loss =  0.24081\n",
      "Iteration 470800: Avg Loss =  0.20504\n",
      "Iteration 470900: Avg Loss =  0.28133\n",
      "Iteration 471000: Avg Loss =  0.25359\n",
      "Iteration 471100: Avg Loss =  0.28504\n",
      "Iteration 471200: Avg Loss =  0.27194\n",
      "Iteration 471300: Avg Loss =  0.22991\n",
      "Iteration 471400: Avg Loss =  0.23120\n",
      "Iteration 471500: Avg Loss =  0.21617\n",
      "Iteration 471600: Avg Loss =  0.23254\n",
      "Iteration 471700: Avg Loss =  0.23140\n",
      "Iteration 471800: Avg Loss =  0.21289\n",
      "Iteration 471900: Avg Loss =  0.24097\n",
      "Iteration 472000: Avg Loss =  0.21636\n",
      "Iteration 472100: Avg Loss =  0.25377\n",
      "Iteration 472200: Avg Loss =  0.23971\n",
      "Iteration 472300: Avg Loss =  0.24150\n",
      "Iteration 472400: Avg Loss =  0.28303\n",
      "Iteration 472500: Avg Loss =  0.20529\n",
      "Iteration 472600: Avg Loss =  0.22144\n",
      "Iteration 472700: Avg Loss =  0.22205\n",
      "Iteration 472800: Avg Loss =  0.21627\n",
      "Iteration 472900: Avg Loss =  0.19973\n",
      "Iteration 473000: Avg Loss =  0.26321\n",
      "Iteration 473100: Avg Loss =  0.25593\n",
      "Iteration 473200: Avg Loss =  0.24440\n",
      "Iteration 473300: Avg Loss =  0.21177\n",
      "Iteration 473400: Avg Loss =  0.23449\n",
      "Iteration 473500: Avg Loss =  0.22430\n",
      "Iteration 473600: Avg Loss =  0.23371\n",
      "Iteration 473700: Avg Loss =  0.21740\n",
      "Iteration 473800: Avg Loss =  0.28083\n",
      "Iteration 473900: Avg Loss =  0.20603\n",
      "Iteration 474000: Avg Loss =  0.20819\n",
      "Iteration 474100: Avg Loss =  0.20410\n",
      "Iteration 474200: Avg Loss =  0.27207\n",
      "Iteration 474300: Avg Loss =  0.21093\n",
      "Iteration 474400: Avg Loss =  0.20478\n",
      "Iteration 474500: Avg Loss =  0.22408\n",
      "Iteration 474600: Avg Loss =  0.24618\n",
      "Iteration 474700: Avg Loss =  0.21586\n",
      "Iteration 474800: Avg Loss =  0.21666\n",
      "Iteration 474900: Avg Loss =  0.24431\n",
      "Iteration 475000: Avg Loss =  0.22732\n",
      "Iteration 475100: Avg Loss =  0.26564\n",
      "Iteration 475200: Avg Loss =  0.22825\n",
      "Iteration 475300: Avg Loss =  0.22467\n",
      "Iteration 475400: Avg Loss =  0.21599\n",
      "Iteration 475500: Avg Loss =  0.25388\n",
      "Iteration 475600: Avg Loss =  0.22013\n",
      "Iteration 475700: Avg Loss =  0.26759\n",
      "Iteration 475800: Avg Loss =  0.22597\n",
      "Iteration 475900: Avg Loss =  0.25863\n",
      "Iteration 476000: Avg Loss =  0.24304\n",
      "Iteration 476100: Avg Loss =  0.28488\n",
      "Iteration 476200: Avg Loss =  0.23319\n",
      "Iteration 476300: Avg Loss =  0.23822\n",
      "Iteration 476400: Avg Loss =  0.21052\n",
      "Iteration 476500: Avg Loss =  0.24084\n",
      "Iteration 476600: Avg Loss =  0.22655\n",
      "Iteration 476700: Avg Loss =  0.24325\n",
      "Iteration 476800: Avg Loss =  0.24487\n",
      "Iteration 476900: Avg Loss =  0.24702\n",
      "Iteration 477000: Avg Loss =  0.22247\n",
      "Iteration 477100: Avg Loss =  0.24028\n",
      "Iteration 477200: Avg Loss =  0.28436\n",
      "Iteration 477300: Avg Loss =  0.20848\n",
      "Iteration 477400: Avg Loss =  0.24342\n",
      "Iteration 477500: Avg Loss =  0.23577\n",
      "Iteration 477600: Avg Loss =  0.25695\n",
      "Iteration 477700: Avg Loss =  0.26351\n",
      "Iteration 477800: Avg Loss =  0.24904\n",
      "Iteration 477900: Avg Loss =  0.21982\n",
      "Iteration 478000: Avg Loss =  0.24316\n",
      "Iteration 478100: Avg Loss =  0.24655\n",
      "Iteration 478200: Avg Loss =  0.21839\n",
      "Iteration 478300: Avg Loss =  0.19872\n",
      "Iteration 478400: Avg Loss =  0.23378\n",
      "Iteration 478500: Avg Loss =  0.25598\n",
      "Iteration 478600: Avg Loss =  0.19463\n",
      "Iteration 478700: Avg Loss =  0.23834\n",
      "Iteration 478800: Avg Loss =  0.21827\n",
      "Iteration 478900: Avg Loss =  0.23988\n",
      "Iteration 479000: Avg Loss =  0.21984\n",
      "Iteration 479100: Avg Loss =  0.21103\n",
      "Iteration 479200: Avg Loss =  0.25229\n",
      "Iteration 479300: Avg Loss =  0.24791\n",
      "Iteration 479400: Avg Loss =  0.24383\n",
      "Iteration 479500: Avg Loss =  0.23971\n",
      "Iteration 479600: Avg Loss =  0.31117\n",
      "Iteration 479700: Avg Loss =  0.25155\n",
      "Iteration 479800: Avg Loss =  0.24884\n",
      "Iteration 479900: Avg Loss =  0.26514\n",
      "Iteration 480000: Avg Loss =  0.27257\n",
      "Iteration 480100: Avg Loss =  0.19558\n",
      "Iteration 480200: Avg Loss =  0.24435\n",
      "Iteration 480300: Avg Loss =  0.23810\n",
      "Iteration 480400: Avg Loss =  0.26526\n",
      "Iteration 480500: Avg Loss =  0.24072\n",
      "Iteration 480600: Avg Loss =  0.25068\n",
      "Iteration 480700: Avg Loss =  0.20190\n",
      "Iteration 480800: Avg Loss =  0.28625\n",
      "Iteration 480900: Avg Loss =  0.27089\n",
      "Iteration 481000: Avg Loss =  0.27998\n",
      "Iteration 481100: Avg Loss =  0.21199\n",
      "Iteration 481200: Avg Loss =  0.22464\n",
      "Iteration 481300: Avg Loss =  0.22285\n",
      "Iteration 481400: Avg Loss =  0.27120\n",
      "Iteration 481500: Avg Loss =  0.21473\n",
      "Iteration 481600: Avg Loss =  0.20947\n",
      "Iteration 481700: Avg Loss =  0.24187\n",
      "Iteration 481800: Avg Loss =  0.22947\n",
      "Iteration 481900: Avg Loss =  0.22832\n",
      "Iteration 482000: Avg Loss =  0.28093\n",
      "Iteration 482100: Avg Loss =  0.21747\n",
      "Iteration 482200: Avg Loss =  0.25489\n",
      "Iteration 482300: Avg Loss =  0.24005\n",
      "Iteration 482400: Avg Loss =  0.24547\n",
      "Iteration 482500: Avg Loss =  0.22584\n",
      "Iteration 482600: Avg Loss =  0.20232\n",
      "Iteration 482700: Avg Loss =  0.25422\n",
      "Iteration 482800: Avg Loss =  0.19454\n",
      "Iteration 482900: Avg Loss =  0.27042\n",
      "Iteration 483000: Avg Loss =  0.21441\n",
      "Iteration 483100: Avg Loss =  0.19316\n",
      "Iteration 483200: Avg Loss =  0.23258\n",
      "Iteration 483300: Avg Loss =  0.20633\n",
      "Iteration 483400: Avg Loss =  0.22195\n",
      "Iteration 483500: Avg Loss =  0.22698\n",
      "Iteration 483600: Avg Loss =  0.28173\n",
      "Iteration 483700: Avg Loss =  0.23757\n",
      "Iteration 483800: Avg Loss =  0.22725\n",
      "Iteration 483900: Avg Loss =  0.23125\n",
      "Iteration 484000: Avg Loss =  0.28028\n",
      "Iteration 484100: Avg Loss =  0.23167\n",
      "Iteration 484200: Avg Loss =  0.20338\n",
      "Iteration 484300: Avg Loss =  0.20291\n",
      "Iteration 484400: Avg Loss =  0.23100\n",
      "Iteration 484500: Avg Loss =  0.22638\n",
      "Iteration 484600: Avg Loss =  0.25303\n",
      "Iteration 484700: Avg Loss =  0.24314\n",
      "Iteration 484800: Avg Loss =  0.25036\n",
      "Iteration 484900: Avg Loss =  0.27174\n",
      "Iteration 485000: Avg Loss =  0.24322\n",
      "Iteration 485100: Avg Loss =  0.26116\n",
      "Iteration 485200: Avg Loss =  0.23108\n",
      "Iteration 485300: Avg Loss =  0.24424\n",
      "Iteration 485400: Avg Loss =  0.23870\n",
      "Iteration 485500: Avg Loss =  0.30519\n",
      "Iteration 485600: Avg Loss =  0.26563\n",
      "Iteration 485700: Avg Loss =  0.24853\n",
      "Iteration 485800: Avg Loss =  0.26880\n",
      "Iteration 485900: Avg Loss =  0.21531\n",
      "Iteration 486000: Avg Loss =  0.22515\n",
      "Iteration 486100: Avg Loss =  0.21509\n",
      "Iteration 486200: Avg Loss =  0.27988\n",
      "Iteration 486300: Avg Loss =  0.20583\n",
      "Iteration 486400: Avg Loss =  0.24284\n",
      "Iteration 486500: Avg Loss =  0.19698\n",
      "Iteration 486600: Avg Loss =  0.25027\n",
      "Iteration 486700: Avg Loss =  0.26297\n",
      "Iteration 486800: Avg Loss =  0.25434\n",
      "Iteration 486900: Avg Loss =  0.21946\n",
      "Iteration 487000: Avg Loss =  0.22708\n",
      "Iteration 487100: Avg Loss =  0.23965\n",
      "Iteration 487200: Avg Loss =  0.24219\n",
      "Iteration 487300: Avg Loss =  0.22907\n",
      "Iteration 487400: Avg Loss =  0.24573\n",
      "Iteration 487500: Avg Loss =  0.29125\n",
      "Iteration 487600: Avg Loss =  0.24381\n",
      "Iteration 487700: Avg Loss =  0.22666\n",
      "Iteration 487800: Avg Loss =  0.27183\n",
      "Iteration 487900: Avg Loss =  0.21898\n",
      "Iteration 488000: Avg Loss =  0.22932\n",
      "Iteration 488100: Avg Loss =  0.23014\n",
      "Iteration 488200: Avg Loss =  0.24777\n",
      "Iteration 488300: Avg Loss =  0.24803\n",
      "Iteration 488400: Avg Loss =  0.23197\n",
      "Iteration 488500: Avg Loss =  0.23889\n",
      "Iteration 488600: Avg Loss =  0.21374\n",
      "Iteration 488700: Avg Loss =  0.26359\n",
      "Iteration 488800: Avg Loss =  0.22122\n",
      "Iteration 488900: Avg Loss =  0.18355\n",
      "Iteration 489000: Avg Loss =  0.21458\n",
      "Iteration 489100: Avg Loss =  0.21911\n",
      "Iteration 489200: Avg Loss =  0.25239\n",
      "Iteration 489300: Avg Loss =  0.23115\n",
      "Iteration 489400: Avg Loss =  0.24716\n",
      "Iteration 489500: Avg Loss =  0.19664\n",
      "Iteration 489600: Avg Loss =  0.22746\n",
      "Iteration 489700: Avg Loss =  0.25022\n",
      "Iteration 489800: Avg Loss =  0.23254\n",
      "Iteration 489900: Avg Loss =  0.24946\n",
      "Iteration 490000: Avg Loss =  0.21071\n",
      "Iteration 490100: Avg Loss =  0.24531\n",
      "Iteration 490200: Avg Loss =  0.21693\n",
      "Iteration 490300: Avg Loss =  0.22598\n",
      "Iteration 490400: Avg Loss =  0.25387\n",
      "Iteration 490500: Avg Loss =  0.24550\n",
      "Iteration 490600: Avg Loss =  0.24888\n",
      "Iteration 490700: Avg Loss =  0.25055\n",
      "Iteration 490800: Avg Loss =  0.22630\n",
      "Iteration 490900: Avg Loss =  0.22073\n",
      "Iteration 491000: Avg Loss =  0.24165\n",
      "Iteration 491100: Avg Loss =  0.22707\n",
      "Iteration 491200: Avg Loss =  0.26235\n",
      "Iteration 491300: Avg Loss =  0.29819\n",
      "Iteration 491400: Avg Loss =  0.25105\n",
      "Iteration 491500: Avg Loss =  0.21259\n",
      "Iteration 491600: Avg Loss =  0.24050\n",
      "Iteration 491700: Avg Loss =  0.26501\n",
      "Iteration 491800: Avg Loss =  0.23634\n",
      "Iteration 491900: Avg Loss =  0.24805\n",
      "Iteration 492000: Avg Loss =  0.23793\n",
      "Iteration 492100: Avg Loss =  0.22165\n",
      "Iteration 492200: Avg Loss =  0.22563\n",
      "Iteration 492300: Avg Loss =  0.22216\n",
      "Iteration 492400: Avg Loss =  0.23339\n",
      "Iteration 492500: Avg Loss =  0.23963\n",
      "Iteration 492600: Avg Loss =  0.19330\n",
      "Iteration 492700: Avg Loss =  0.29880\n",
      "Iteration 492800: Avg Loss =  0.24875\n",
      "Iteration 492900: Avg Loss =  0.23576\n",
      "Iteration 493000: Avg Loss =  0.26594\n",
      "Iteration 493100: Avg Loss =  0.19927\n",
      "Iteration 493200: Avg Loss =  0.22748\n",
      "Iteration 493300: Avg Loss =  0.24280\n",
      "Iteration 493400: Avg Loss =  0.23875\n",
      "Iteration 493500: Avg Loss =  0.27655\n",
      "Iteration 493600: Avg Loss =  0.24202\n",
      "Iteration 493700: Avg Loss =  0.24474\n",
      "Iteration 493800: Avg Loss =  0.21704\n",
      "Iteration 493900: Avg Loss =  0.19701\n",
      "Iteration 494000: Avg Loss =  0.20952\n",
      "Iteration 494100: Avg Loss =  0.19085\n",
      "Iteration 494200: Avg Loss =  0.26125\n",
      "Iteration 494300: Avg Loss =  0.24542\n",
      "Iteration 494400: Avg Loss =  0.26415\n",
      "Iteration 494500: Avg Loss =  0.26139\n",
      "Iteration 494600: Avg Loss =  0.25805\n",
      "Iteration 494700: Avg Loss =  0.22539\n",
      "Iteration 494800: Avg Loss =  0.21207\n",
      "Iteration 494900: Avg Loss =  0.25664\n",
      "Iteration 495000: Avg Loss =  0.22158\n",
      "Iteration 495100: Avg Loss =  0.23229\n",
      "Iteration 495200: Avg Loss =  0.21338\n",
      "Iteration 495300: Avg Loss =  0.23461\n",
      "Iteration 495400: Avg Loss =  0.24235\n",
      "Iteration 495500: Avg Loss =  0.21088\n",
      "Iteration 495600: Avg Loss =  0.24975\n",
      "Iteration 495700: Avg Loss =  0.23060\n",
      "Iteration 495800: Avg Loss =  0.26593\n",
      "Iteration 495900: Avg Loss =  0.26486\n",
      "Iteration 496000: Avg Loss =  0.21975\n",
      "Iteration 496100: Avg Loss =  0.22531\n",
      "Iteration 496200: Avg Loss =  0.24958\n",
      "Iteration 496300: Avg Loss =  0.24915\n",
      "Iteration 496400: Avg Loss =  0.23190\n",
      "Iteration 496500: Avg Loss =  0.27030\n",
      "Iteration 496600: Avg Loss =  0.24838\n",
      "Iteration 496700: Avg Loss =  0.21307\n",
      "Iteration 496800: Avg Loss =  0.25577\n",
      "Iteration 496900: Avg Loss =  0.24039\n",
      "Iteration 497000: Avg Loss =  0.25385\n",
      "Iteration 497100: Avg Loss =  0.21584\n",
      "Iteration 497200: Avg Loss =  0.22783\n",
      "Iteration 497300: Avg Loss =  0.22452\n",
      "Iteration 497400: Avg Loss =  0.19795\n",
      "Iteration 497500: Avg Loss =  0.26298\n",
      "Iteration 497600: Avg Loss =  0.26505\n",
      "Iteration 497700: Avg Loss =  0.22001\n",
      "Iteration 497800: Avg Loss =  0.25271\n",
      "Iteration 497900: Avg Loss =  0.22611\n",
      "Iteration 498000: Avg Loss =  0.22006\n",
      "Iteration 498100: Avg Loss =  0.20427\n",
      "Iteration 498200: Avg Loss =  0.24166\n",
      "Iteration 498300: Avg Loss =  0.22855\n",
      "Iteration 498400: Avg Loss =  0.20977\n",
      "Iteration 498500: Avg Loss =  0.20327\n",
      "Iteration 498600: Avg Loss =  0.22477\n",
      "Iteration 498700: Avg Loss =  0.25947\n",
      "Iteration 498800: Avg Loss =  0.22755\n",
      "Iteration 498900: Avg Loss =  0.23986\n",
      "Iteration 499000: Avg Loss =  0.20761\n",
      "Iteration 499100: Avg Loss =  0.22094\n",
      "Iteration 499200: Avg Loss =  0.21844\n",
      "Iteration 499300: Avg Loss =  0.23579\n",
      "Iteration 499400: Avg Loss =  0.21344\n",
      "Iteration 499500: Avg Loss =  0.22201\n",
      "Iteration 499600: Avg Loss =  0.23134\n",
      "Iteration 499700: Avg Loss =  0.22417\n",
      "Iteration 499800: Avg Loss =  0.21796\n",
      "Iteration 499900: Avg Loss =  0.27064\n",
      "Iteration 500000: Avg Loss =  0.22650\n",
      "Iteration 500100: Avg Loss =  0.22137\n",
      "Iteration 500200: Avg Loss =  0.23864\n",
      "Iteration 500300: Avg Loss =  0.26863\n",
      "Iteration 500400: Avg Loss =  0.24785\n",
      "Iteration 500500: Avg Loss =  0.19618\n",
      "Iteration 500600: Avg Loss =  0.23375\n",
      "Iteration 500700: Avg Loss =  0.19909\n",
      "Iteration 500800: Avg Loss =  0.20727\n",
      "Iteration 500900: Avg Loss =  0.25037\n",
      "Iteration 501000: Avg Loss =  0.21660\n",
      "Iteration 501100: Avg Loss =  0.24353\n",
      "Iteration 501200: Avg Loss =  0.23964\n",
      "Iteration 501300: Avg Loss =  0.23451\n",
      "Iteration 501400: Avg Loss =  0.30335\n",
      "Iteration 501500: Avg Loss =  0.22870\n",
      "Iteration 501600: Avg Loss =  0.22491\n",
      "Iteration 501700: Avg Loss =  0.21221\n",
      "Iteration 501800: Avg Loss =  0.23157\n",
      "Iteration 501900: Avg Loss =  0.29206\n",
      "Iteration 502000: Avg Loss =  0.30743\n",
      "Iteration 502100: Avg Loss =  0.22441\n",
      "Iteration 502200: Avg Loss =  0.21669\n",
      "Iteration 502300: Avg Loss =  0.26514\n",
      "Iteration 502400: Avg Loss =  0.22689\n",
      "Iteration 502500: Avg Loss =  0.25013\n",
      "Iteration 502600: Avg Loss =  0.25621\n",
      "Iteration 502700: Avg Loss =  0.23813\n",
      "Iteration 502800: Avg Loss =  0.22328\n",
      "Iteration 502900: Avg Loss =  0.24169\n",
      "Iteration 503000: Avg Loss =  0.23692\n",
      "Iteration 503100: Avg Loss =  0.23455\n",
      "Iteration 503200: Avg Loss =  0.26346\n",
      "Iteration 503300: Avg Loss =  0.23125\n",
      "Iteration 503400: Avg Loss =  0.22769\n",
      "Iteration 503500: Avg Loss =  0.22116\n",
      "Iteration 503600: Avg Loss =  0.22640\n",
      "Iteration 503700: Avg Loss =  0.21675\n",
      "Iteration 503800: Avg Loss =  0.18786\n",
      "Iteration 503900: Avg Loss =  0.28275\n",
      "Iteration 504000: Avg Loss =  0.25781\n",
      "Iteration 504100: Avg Loss =  0.27744\n",
      "Iteration 504200: Avg Loss =  0.24782\n",
      "Iteration 504300: Avg Loss =  0.20866\n",
      "Iteration 504400: Avg Loss =  0.22672\n",
      "Iteration 504500: Avg Loss =  0.23890\n",
      "Iteration 504600: Avg Loss =  0.21913\n",
      "Iteration 504700: Avg Loss =  0.21666\n",
      "Iteration 504800: Avg Loss =  0.22491\n",
      "Iteration 504900: Avg Loss =  0.21698\n",
      "Iteration 505000: Avg Loss =  0.26231\n",
      "Iteration 505100: Avg Loss =  0.21687\n",
      "Iteration 505200: Avg Loss =  0.23215\n",
      "Iteration 505300: Avg Loss =  0.19838\n",
      "Iteration 505400: Avg Loss =  0.22045\n",
      "Iteration 505500: Avg Loss =  0.21282\n",
      "Iteration 505600: Avg Loss =  0.22181\n",
      "Iteration 505700: Avg Loss =  0.25894\n",
      "Iteration 505800: Avg Loss =  0.20719\n",
      "Iteration 505900: Avg Loss =  0.25954\n",
      "Iteration 506000: Avg Loss =  0.22055\n",
      "Iteration 506100: Avg Loss =  0.23173\n",
      "Iteration 506200: Avg Loss =  0.21662\n",
      "Iteration 506300: Avg Loss =  0.23418\n",
      "Iteration 506400: Avg Loss =  0.26812\n",
      "Iteration 506500: Avg Loss =  0.21835\n",
      "Iteration 506600: Avg Loss =  0.24643\n",
      "Iteration 506700: Avg Loss =  0.28765\n",
      "Iteration 506800: Avg Loss =  0.26812\n",
      "Iteration 506900: Avg Loss =  0.22281\n",
      "Iteration 507000: Avg Loss =  0.22875\n",
      "Iteration 507100: Avg Loss =  0.19721\n",
      "Iteration 507200: Avg Loss =  0.25014\n",
      "Iteration 507300: Avg Loss =  0.24247\n",
      "Iteration 507400: Avg Loss =  0.23529\n",
      "Iteration 507500: Avg Loss =  0.24671\n",
      "Iteration 507600: Avg Loss =  0.22587\n",
      "Iteration 507700: Avg Loss =  0.23872\n",
      "Iteration 507800: Avg Loss =  0.24902\n",
      "Iteration 507900: Avg Loss =  0.20878\n",
      "Iteration 508000: Avg Loss =  0.23560\n",
      "Iteration 508100: Avg Loss =  0.21484\n",
      "Iteration 508200: Avg Loss =  0.25500\n",
      "Iteration 508300: Avg Loss =  0.21409\n",
      "Iteration 508400: Avg Loss =  0.23706\n",
      "Iteration 508500: Avg Loss =  0.26746\n",
      "Iteration 508600: Avg Loss =  0.29568\n",
      "Iteration 508700: Avg Loss =  0.23110\n",
      "Iteration 508800: Avg Loss =  0.25343\n",
      "Iteration 508900: Avg Loss =  0.24962\n",
      "Iteration 509000: Avg Loss =  0.23850\n",
      "Iteration 509100: Avg Loss =  0.23630\n",
      "Iteration 509200: Avg Loss =  0.21303\n",
      "Iteration 509300: Avg Loss =  0.24283\n",
      "Iteration 509400: Avg Loss =  0.19492\n",
      "Iteration 509500: Avg Loss =  0.20490\n",
      "Iteration 509600: Avg Loss =  0.26866\n",
      "Iteration 509700: Avg Loss =  0.25626\n",
      "Iteration 509800: Avg Loss =  0.20205\n",
      "Iteration 509900: Avg Loss =  0.21259\n",
      "Iteration 510000: Avg Loss =  0.20953\n",
      "Iteration 510100: Avg Loss =  0.22218\n",
      "Iteration 510200: Avg Loss =  0.21154\n",
      "Iteration 510300: Avg Loss =  0.25225\n",
      "Iteration 510400: Avg Loss =  0.21426\n",
      "Iteration 510500: Avg Loss =  0.21119\n",
      "Iteration 510600: Avg Loss =  0.25226\n",
      "Iteration 510700: Avg Loss =  0.23939\n",
      "Iteration 510800: Avg Loss =  0.20910\n",
      "Iteration 510900: Avg Loss =  0.23667\n",
      "Iteration 511000: Avg Loss =  0.20381\n",
      "Iteration 511100: Avg Loss =  0.23997\n",
      "Iteration 511200: Avg Loss =  0.21824\n",
      "Iteration 511300: Avg Loss =  0.19826\n",
      "Iteration 511400: Avg Loss =  0.20172\n",
      "Iteration 511500: Avg Loss =  0.23754\n",
      "Iteration 511600: Avg Loss =  0.25105\n",
      "Iteration 511700: Avg Loss =  0.22818\n",
      "Iteration 511800: Avg Loss =  0.24649\n",
      "Iteration 511900: Avg Loss =  0.26540\n",
      "Iteration 512000: Avg Loss =  0.22630\n",
      "Iteration 512100: Avg Loss =  0.19930\n",
      "Iteration 512200: Avg Loss =  0.26089\n",
      "Iteration 512300: Avg Loss =  0.23215\n",
      "Iteration 512400: Avg Loss =  0.23111\n",
      "Iteration 512500: Avg Loss =  0.22558\n",
      "Iteration 512600: Avg Loss =  0.21896\n",
      "Iteration 512700: Avg Loss =  0.21484\n",
      "Iteration 512800: Avg Loss =  0.22432\n",
      "Iteration 512900: Avg Loss =  0.24668\n",
      "Iteration 513000: Avg Loss =  0.22752\n",
      "Iteration 513100: Avg Loss =  0.22821\n",
      "Iteration 513200: Avg Loss =  0.21825\n",
      "Iteration 513300: Avg Loss =  0.24115\n",
      "Iteration 513400: Avg Loss =  0.20777\n",
      "Iteration 513500: Avg Loss =  0.29396\n",
      "Iteration 513600: Avg Loss =  0.21941\n",
      "Iteration 513700: Avg Loss =  0.23953\n",
      "Iteration 513800: Avg Loss =  0.21776\n",
      "Iteration 513900: Avg Loss =  0.26327\n",
      "Iteration 514000: Avg Loss =  0.24047\n",
      "Iteration 514100: Avg Loss =  0.21176\n",
      "Iteration 514200: Avg Loss =  0.24813\n",
      "Iteration 514300: Avg Loss =  0.24257\n",
      "Iteration 514400: Avg Loss =  0.21502\n",
      "Iteration 514500: Avg Loss =  0.24393\n",
      "Iteration 514600: Avg Loss =  0.22106\n",
      "Iteration 514700: Avg Loss =  0.22197\n",
      "Iteration 514800: Avg Loss =  0.26690\n",
      "Iteration 514900: Avg Loss =  0.27802\n",
      "Iteration 515000: Avg Loss =  0.22444\n",
      "Iteration 515100: Avg Loss =  0.21550\n",
      "Iteration 515200: Avg Loss =  0.23077\n",
      "Iteration 515300: Avg Loss =  0.22520\n",
      "Iteration 515400: Avg Loss =  0.24770\n",
      "Iteration 515500: Avg Loss =  0.23256\n",
      "Iteration 515600: Avg Loss =  0.20963\n",
      "Iteration 515700: Avg Loss =  0.23363\n",
      "Iteration 515800: Avg Loss =  0.23969\n",
      "Iteration 515900: Avg Loss =  0.25824\n",
      "Iteration 516000: Avg Loss =  0.22069\n",
      "Iteration 516100: Avg Loss =  0.22025\n",
      "Iteration 516200: Avg Loss =  0.26825\n",
      "Iteration 516300: Avg Loss =  0.22155\n",
      "Iteration 516400: Avg Loss =  0.19829\n",
      "Iteration 516500: Avg Loss =  0.27825\n",
      "Iteration 516600: Avg Loss =  0.26083\n",
      "Iteration 516700: Avg Loss =  0.21735\n",
      "Iteration 516800: Avg Loss =  0.22713\n",
      "Iteration 516900: Avg Loss =  0.21562\n",
      "Iteration 517000: Avg Loss =  0.21357\n",
      "Iteration 517100: Avg Loss =  0.27112\n",
      "Iteration 517200: Avg Loss =  0.22134\n",
      "Iteration 517300: Avg Loss =  0.23471\n",
      "Iteration 517400: Avg Loss =  0.22055\n",
      "Iteration 517500: Avg Loss =  0.23257\n",
      "Iteration 517600: Avg Loss =  0.20179\n",
      "Iteration 517700: Avg Loss =  0.25453\n",
      "Iteration 517800: Avg Loss =  0.22361\n",
      "Iteration 517900: Avg Loss =  0.18177\n",
      "Iteration 518000: Avg Loss =  0.28538\n",
      "Iteration 518100: Avg Loss =  0.22034\n",
      "Iteration 518200: Avg Loss =  0.22764\n",
      "Iteration 518300: Avg Loss =  0.23355\n",
      "Iteration 518400: Avg Loss =  0.22332\n",
      "Iteration 518500: Avg Loss =  0.23288\n",
      "Iteration 518600: Avg Loss =  0.24635\n",
      "Iteration 518700: Avg Loss =  0.21792\n",
      "Iteration 518800: Avg Loss =  0.24965\n",
      "Iteration 518900: Avg Loss =  0.22016\n",
      "Iteration 519000: Avg Loss =  0.24080\n",
      "Iteration 519100: Avg Loss =  0.21030\n",
      "Iteration 519200: Avg Loss =  0.24102\n",
      "Iteration 519300: Avg Loss =  0.18725\n",
      "Iteration 519400: Avg Loss =  0.18795\n",
      "Iteration 519500: Avg Loss =  0.22458\n",
      "Iteration 519600: Avg Loss =  0.21488\n",
      "Iteration 519700: Avg Loss =  0.24882\n",
      "Iteration 519800: Avg Loss =  0.23569\n",
      "Iteration 519900: Avg Loss =  0.28231\n",
      "Iteration 520000: Avg Loss =  0.19674\n",
      "Iteration 520100: Avg Loss =  0.20057\n",
      "Iteration 520200: Avg Loss =  0.21891\n",
      "Iteration 520300: Avg Loss =  0.23760\n",
      "Iteration 520400: Avg Loss =  0.25035\n",
      "Iteration 520500: Avg Loss =  0.21141\n",
      "Iteration 520600: Avg Loss =  0.22807\n",
      "Iteration 520700: Avg Loss =  0.22729\n",
      "Iteration 520800: Avg Loss =  0.26098\n",
      "Iteration 520900: Avg Loss =  0.24158\n",
      "Iteration 521000: Avg Loss =  0.25251\n",
      "Iteration 521100: Avg Loss =  0.22231\n",
      "Iteration 521200: Avg Loss =  0.24369\n",
      "Iteration 521300: Avg Loss =  0.22740\n",
      "Iteration 521400: Avg Loss =  0.21402\n",
      "Iteration 521500: Avg Loss =  0.28417\n",
      "Iteration 521600: Avg Loss =  0.19674\n",
      "Iteration 521700: Avg Loss =  0.17549\n",
      "Iteration 521800: Avg Loss =  0.25598\n",
      "Iteration 521900: Avg Loss =  0.22040\n",
      "Iteration 522000: Avg Loss =  0.23006\n",
      "Iteration 522100: Avg Loss =  0.27008\n",
      "Iteration 522200: Avg Loss =  0.22094\n",
      "Iteration 522300: Avg Loss =  0.23823\n",
      "Iteration 522400: Avg Loss =  0.20740\n",
      "Iteration 522500: Avg Loss =  0.21952\n",
      "Iteration 522600: Avg Loss =  0.27136\n",
      "Iteration 522700: Avg Loss =  0.25477\n",
      "Iteration 522800: Avg Loss =  0.23818\n",
      "Iteration 522900: Avg Loss =  0.22569\n",
      "Iteration 523000: Avg Loss =  0.24037\n",
      "Iteration 523100: Avg Loss =  0.23237\n",
      "Iteration 523200: Avg Loss =  0.23975\n",
      "Iteration 523300: Avg Loss =  0.19059\n",
      "Iteration 523400: Avg Loss =  0.28273\n",
      "Iteration 523500: Avg Loss =  0.21305\n",
      "Iteration 523600: Avg Loss =  0.20873\n",
      "Iteration 523700: Avg Loss =  0.22609\n",
      "Iteration 523800: Avg Loss =  0.21959\n",
      "Iteration 523900: Avg Loss =  0.24364\n",
      "Iteration 524000: Avg Loss =  0.20907\n",
      "Iteration 524100: Avg Loss =  0.22704\n",
      "Iteration 524200: Avg Loss =  0.22630\n",
      "Iteration 524300: Avg Loss =  0.23551\n",
      "Iteration 524400: Avg Loss =  0.19426\n",
      "Iteration 524500: Avg Loss =  0.21708\n",
      "Iteration 524600: Avg Loss =  0.21606\n",
      "Iteration 524700: Avg Loss =  0.22698\n",
      "Iteration 524800: Avg Loss =  0.23240\n",
      "Iteration 524900: Avg Loss =  0.27113\n",
      "Iteration 525000: Avg Loss =  0.22023\n",
      "Iteration 525100: Avg Loss =  0.22525\n",
      "Iteration 525200: Avg Loss =  0.23184\n",
      "Iteration 525300: Avg Loss =  0.21735\n",
      "Iteration 525400: Avg Loss =  0.21400\n",
      "Iteration 525500: Avg Loss =  0.23444\n",
      "Iteration 525600: Avg Loss =  0.22523\n",
      "Iteration 525700: Avg Loss =  0.24422\n",
      "Iteration 525800: Avg Loss =  0.24560\n",
      "Iteration 525900: Avg Loss =  0.22098\n",
      "Iteration 526000: Avg Loss =  0.23130\n",
      "Iteration 526100: Avg Loss =  0.19769\n",
      "Iteration 526200: Avg Loss =  0.24008\n",
      "Iteration 526300: Avg Loss =  0.27003\n",
      "Iteration 526400: Avg Loss =  0.23136\n",
      "Iteration 526500: Avg Loss =  0.23396\n",
      "Iteration 526600: Avg Loss =  0.24770\n",
      "Iteration 526700: Avg Loss =  0.20366\n",
      "Iteration 526800: Avg Loss =  0.22437\n",
      "Iteration 526900: Avg Loss =  0.21607\n",
      "Iteration 527000: Avg Loss =  0.23442\n",
      "Iteration 527100: Avg Loss =  0.22103\n",
      "Iteration 527200: Avg Loss =  0.23833\n",
      "Iteration 527300: Avg Loss =  0.21684\n",
      "Iteration 527400: Avg Loss =  0.24769\n",
      "Iteration 527500: Avg Loss =  0.20855\n",
      "Iteration 527600: Avg Loss =  0.25108\n",
      "Iteration 527700: Avg Loss =  0.21451\n",
      "Iteration 527800: Avg Loss =  0.24362\n",
      "Iteration 527900: Avg Loss =  0.26936\n",
      "Iteration 528000: Avg Loss =  0.20347\n",
      "Iteration 528100: Avg Loss =  0.24990\n",
      "Iteration 528200: Avg Loss =  0.23145\n",
      "Iteration 528300: Avg Loss =  0.25352\n",
      "Iteration 528400: Avg Loss =  0.23165\n",
      "Iteration 528500: Avg Loss =  0.20445\n",
      "Iteration 528600: Avg Loss =  0.25303\n",
      "Iteration 528700: Avg Loss =  0.20655\n",
      "Iteration 528800: Avg Loss =  0.22581\n",
      "Iteration 528900: Avg Loss =  0.22834\n",
      "Iteration 529000: Avg Loss =  0.24651\n",
      "Iteration 529100: Avg Loss =  0.20496\n",
      "Iteration 529200: Avg Loss =  0.19758\n",
      "Iteration 529300: Avg Loss =  0.17588\n",
      "Iteration 529400: Avg Loss =  0.23229\n",
      "Iteration 529500: Avg Loss =  0.20812\n",
      "Iteration 529600: Avg Loss =  0.27947\n",
      "Iteration 529700: Avg Loss =  0.24031\n",
      "Iteration 529800: Avg Loss =  0.25550\n",
      "Iteration 529900: Avg Loss =  0.20397\n",
      "Iteration 530000: Avg Loss =  0.22576\n",
      "Iteration 530100: Avg Loss =  0.29168\n",
      "Iteration 530200: Avg Loss =  0.26402\n",
      "Iteration 530300: Avg Loss =  0.22232\n",
      "Iteration 530400: Avg Loss =  0.26148\n",
      "Iteration 530500: Avg Loss =  0.27032\n",
      "Iteration 530600: Avg Loss =  0.26981\n",
      "Iteration 530700: Avg Loss =  0.24535\n",
      "Iteration 530800: Avg Loss =  0.19429\n",
      "Iteration 530900: Avg Loss =  0.22891\n",
      "Iteration 531000: Avg Loss =  0.21584\n",
      "Iteration 531100: Avg Loss =  0.20837\n",
      "Iteration 531200: Avg Loss =  0.29378\n",
      "Iteration 531300: Avg Loss =  0.20693\n",
      "Iteration 531400: Avg Loss =  0.21976\n",
      "Iteration 531500: Avg Loss =  0.20570\n",
      "Iteration 531600: Avg Loss =  0.20504\n",
      "Iteration 531700: Avg Loss =  0.20895\n",
      "Iteration 531800: Avg Loss =  0.24802\n",
      "Iteration 531900: Avg Loss =  0.21134\n",
      "Iteration 532000: Avg Loss =  0.21190\n",
      "Iteration 532100: Avg Loss =  0.23811\n",
      "Iteration 532200: Avg Loss =  0.28881\n",
      "Iteration 532300: Avg Loss =  0.24418\n",
      "Iteration 532400: Avg Loss =  0.26889\n",
      "Iteration 532500: Avg Loss =  0.26061\n",
      "Iteration 532600: Avg Loss =  0.21356\n",
      "Iteration 532700: Avg Loss =  0.21579\n",
      "Iteration 532800: Avg Loss =  0.24612\n",
      "Iteration 532900: Avg Loss =  0.20029\n",
      "Iteration 533000: Avg Loss =  0.20594\n",
      "Iteration 533100: Avg Loss =  0.21935\n",
      "Iteration 533200: Avg Loss =  0.24410\n",
      "Iteration 533300: Avg Loss =  0.22211\n",
      "Iteration 533400: Avg Loss =  0.21575\n",
      "Iteration 533500: Avg Loss =  0.26323\n",
      "Iteration 533600: Avg Loss =  0.24382\n",
      "Iteration 533700: Avg Loss =  0.25357\n",
      "Iteration 533800: Avg Loss =  0.20879\n",
      "Iteration 533900: Avg Loss =  0.25629\n",
      "Iteration 534000: Avg Loss =  0.21752\n",
      "Iteration 534100: Avg Loss =  0.22360\n",
      "Iteration 534200: Avg Loss =  0.24794\n",
      "Iteration 534300: Avg Loss =  0.21973\n",
      "Iteration 534400: Avg Loss =  0.23604\n",
      "Iteration 534500: Avg Loss =  0.22869\n",
      "Iteration 534600: Avg Loss =  0.25398\n",
      "Iteration 534700: Avg Loss =  0.24361\n",
      "Iteration 534800: Avg Loss =  0.22749\n",
      "Iteration 534900: Avg Loss =  0.26198\n",
      "Iteration 535000: Avg Loss =  0.22782\n",
      "Iteration 535100: Avg Loss =  0.18747\n",
      "Iteration 535200: Avg Loss =  0.23222\n",
      "Iteration 535300: Avg Loss =  0.23914\n",
      "Iteration 535400: Avg Loss =  0.26200\n",
      "Iteration 535500: Avg Loss =  0.22060\n",
      "Iteration 535600: Avg Loss =  0.28944\n",
      "Iteration 535700: Avg Loss =  0.20919\n",
      "Iteration 535800: Avg Loss =  0.24482\n",
      "Iteration 535900: Avg Loss =  0.18866\n",
      "Iteration 536000: Avg Loss =  0.20023\n",
      "Iteration 536100: Avg Loss =  0.20295\n",
      "Iteration 536200: Avg Loss =  0.22724\n",
      "Iteration 536300: Avg Loss =  0.24204\n",
      "Iteration 536400: Avg Loss =  0.22528\n",
      "Iteration 536500: Avg Loss =  0.20286\n",
      "Iteration 536600: Avg Loss =  0.18013\n",
      "Iteration 536700: Avg Loss =  0.23846\n",
      "Iteration 536800: Avg Loss =  0.20386\n",
      "Iteration 536900: Avg Loss =  0.22750\n",
      "Iteration 537000: Avg Loss =  0.22612\n",
      "Iteration 537100: Avg Loss =  0.22301\n",
      "Iteration 537200: Avg Loss =  0.23807\n",
      "Iteration 537300: Avg Loss =  0.18630\n",
      "Iteration 537400: Avg Loss =  0.25100\n",
      "Iteration 537500: Avg Loss =  0.20562\n",
      "Iteration 537600: Avg Loss =  0.21561\n",
      "Iteration 537700: Avg Loss =  0.21683\n",
      "Iteration 537800: Avg Loss =  0.25981\n",
      "Iteration 537900: Avg Loss =  0.21533\n",
      "Iteration 538000: Avg Loss =  0.24067\n",
      "Iteration 538100: Avg Loss =  0.31055\n",
      "Iteration 538200: Avg Loss =  0.20999\n",
      "Iteration 538300: Avg Loss =  0.20351\n",
      "Iteration 538400: Avg Loss =  0.21664\n",
      "Iteration 538500: Avg Loss =  0.19684\n",
      "Iteration 538600: Avg Loss =  0.23210\n",
      "Iteration 538700: Avg Loss =  0.19759\n",
      "Iteration 538800: Avg Loss =  0.23274\n",
      "Iteration 538900: Avg Loss =  0.22693\n",
      "Iteration 539000: Avg Loss =  0.26802\n",
      "Iteration 539100: Avg Loss =  0.21663\n",
      "Iteration 539200: Avg Loss =  0.21214\n",
      "Iteration 539300: Avg Loss =  0.23272\n",
      "Iteration 539400: Avg Loss =  0.22716\n",
      "Iteration 539500: Avg Loss =  0.25037\n",
      "Iteration 539600: Avg Loss =  0.24937\n",
      "Iteration 539700: Avg Loss =  0.21070\n",
      "Iteration 539800: Avg Loss =  0.22543\n",
      "Iteration 539900: Avg Loss =  0.23126\n",
      "Iteration 540000: Avg Loss =  0.24269\n",
      "Iteration 540100: Avg Loss =  0.21910\n",
      "Iteration 540200: Avg Loss =  0.20657\n",
      "Iteration 540300: Avg Loss =  0.22110\n",
      "Iteration 540400: Avg Loss =  0.24853\n",
      "Iteration 540500: Avg Loss =  0.23763\n",
      "Iteration 540600: Avg Loss =  0.19855\n",
      "Iteration 540700: Avg Loss =  0.20617\n",
      "Iteration 540800: Avg Loss =  0.22573\n",
      "Iteration 540900: Avg Loss =  0.22974\n",
      "Iteration 541000: Avg Loss =  0.20945\n",
      "Iteration 541100: Avg Loss =  0.21759\n",
      "Iteration 541200: Avg Loss =  0.28195\n",
      "Iteration 541300: Avg Loss =  0.19859\n",
      "Iteration 541400: Avg Loss =  0.22919\n",
      "Iteration 541500: Avg Loss =  0.24305\n",
      "Iteration 541600: Avg Loss =  0.22097\n",
      "Iteration 541700: Avg Loss =  0.20373\n",
      "Iteration 541800: Avg Loss =  0.22147\n",
      "Iteration 541900: Avg Loss =  0.22468\n",
      "Iteration 542000: Avg Loss =  0.24416\n",
      "Iteration 542100: Avg Loss =  0.20283\n",
      "Iteration 542200: Avg Loss =  0.23702\n",
      "Iteration 542300: Avg Loss =  0.20496\n",
      "Iteration 542400: Avg Loss =  0.26075\n",
      "Iteration 542500: Avg Loss =  0.22653\n",
      "Iteration 542600: Avg Loss =  0.22128\n",
      "Iteration 542700: Avg Loss =  0.21472\n",
      "Iteration 542800: Avg Loss =  0.23876\n",
      "Iteration 542900: Avg Loss =  0.22958\n",
      "Iteration 543000: Avg Loss =  0.24900\n",
      "Iteration 543100: Avg Loss =  0.23253\n",
      "Iteration 543200: Avg Loss =  0.27040\n",
      "Iteration 543300: Avg Loss =  0.20098\n",
      "Iteration 543400: Avg Loss =  0.20027\n",
      "Iteration 543500: Avg Loss =  0.20969\n",
      "Iteration 543600: Avg Loss =  0.24810\n",
      "Iteration 543700: Avg Loss =  0.23883\n",
      "Iteration 543800: Avg Loss =  0.23548\n",
      "Iteration 543900: Avg Loss =  0.23027\n",
      "Iteration 544000: Avg Loss =  0.25067\n",
      "Iteration 544100: Avg Loss =  0.26829\n",
      "Iteration 544200: Avg Loss =  0.22343\n",
      "Iteration 544300: Avg Loss =  0.23796\n",
      "Iteration 544400: Avg Loss =  0.24490\n",
      "Iteration 544500: Avg Loss =  0.28149\n",
      "Iteration 544600: Avg Loss =  0.22279\n",
      "Iteration 544700: Avg Loss =  0.24098\n",
      "Iteration 544800: Avg Loss =  0.25529\n",
      "Iteration 544900: Avg Loss =  0.24956\n",
      "Iteration 545000: Avg Loss =  0.20465\n",
      "Iteration 545100: Avg Loss =  0.22827\n",
      "Iteration 545200: Avg Loss =  0.21749\n",
      "Iteration 545300: Avg Loss =  0.22152\n",
      "Iteration 545400: Avg Loss =  0.24628\n",
      "Iteration 545500: Avg Loss =  0.20831\n",
      "Iteration 545600: Avg Loss =  0.22269\n",
      "Iteration 545700: Avg Loss =  0.19103\n",
      "Iteration 545800: Avg Loss =  0.29326\n",
      "Iteration 545900: Avg Loss =  0.24584\n",
      "Iteration 546000: Avg Loss =  0.24681\n",
      "Iteration 546100: Avg Loss =  0.24120\n",
      "Iteration 546200: Avg Loss =  0.20948\n",
      "Iteration 546300: Avg Loss =  0.22831\n",
      "Iteration 546400: Avg Loss =  0.21094\n",
      "Iteration 546500: Avg Loss =  0.21824\n",
      "Iteration 546600: Avg Loss =  0.22844\n",
      "Iteration 546700: Avg Loss =  0.25246\n",
      "Iteration 546800: Avg Loss =  0.21175\n",
      "Iteration 546900: Avg Loss =  0.22431\n",
      "Iteration 547000: Avg Loss =  0.25885\n",
      "Iteration 547100: Avg Loss =  0.20707\n",
      "Iteration 547200: Avg Loss =  0.20505\n",
      "Iteration 547300: Avg Loss =  0.21499\n",
      "Iteration 547400: Avg Loss =  0.21872\n",
      "Iteration 547500: Avg Loss =  0.20751\n",
      "Iteration 547600: Avg Loss =  0.21301\n",
      "Iteration 547700: Avg Loss =  0.27798\n",
      "Iteration 547800: Avg Loss =  0.25069\n",
      "Iteration 547900: Avg Loss =  0.22784\n",
      "Iteration 548000: Avg Loss =  0.24006\n",
      "Iteration 548100: Avg Loss =  0.22544\n",
      "Iteration 548200: Avg Loss =  0.21294\n",
      "Iteration 548300: Avg Loss =  0.26126\n",
      "Iteration 548400: Avg Loss =  0.23300\n",
      "Iteration 548500: Avg Loss =  0.21048\n",
      "Iteration 548600: Avg Loss =  0.20565\n",
      "Iteration 548700: Avg Loss =  0.25187\n",
      "Iteration 548800: Avg Loss =  0.26872\n",
      "Iteration 548900: Avg Loss =  0.23118\n",
      "Iteration 549000: Avg Loss =  0.21364\n",
      "Iteration 549100: Avg Loss =  0.23461\n",
      "Iteration 549200: Avg Loss =  0.23380\n",
      "Iteration 549300: Avg Loss =  0.21237\n",
      "Iteration 549400: Avg Loss =  0.23072\n",
      "Iteration 549500: Avg Loss =  0.23241\n",
      "Iteration 549600: Avg Loss =  0.22547\n",
      "Iteration 549700: Avg Loss =  0.20913\n",
      "Iteration 549800: Avg Loss =  0.26412\n",
      "Iteration 549900: Avg Loss =  0.23562\n",
      "Iteration 550000: Avg Loss =  0.23708\n",
      "Iteration 550100: Avg Loss =  0.24954\n",
      "Iteration 550200: Avg Loss =  0.27157\n",
      "Iteration 550300: Avg Loss =  0.22074\n",
      "Iteration 550400: Avg Loss =  0.23011\n",
      "Iteration 550500: Avg Loss =  0.25356\n",
      "Iteration 550600: Avg Loss =  0.23987\n",
      "Iteration 550700: Avg Loss =  0.24150\n",
      "Iteration 550800: Avg Loss =  0.26183\n",
      "Iteration 550900: Avg Loss =  0.22524\n",
      "Iteration 551000: Avg Loss =  0.26573\n",
      "Iteration 551100: Avg Loss =  0.26772\n",
      "Iteration 551200: Avg Loss =  0.22932\n",
      "Iteration 551300: Avg Loss =  0.21096\n",
      "Iteration 551400: Avg Loss =  0.25732\n",
      "Iteration 551500: Avg Loss =  0.23672\n",
      "Iteration 551600: Avg Loss =  0.22622\n",
      "Iteration 551700: Avg Loss =  0.23874\n",
      "Iteration 551800: Avg Loss =  0.19732\n",
      "Iteration 551900: Avg Loss =  0.19218\n",
      "Iteration 552000: Avg Loss =  0.23185\n",
      "Iteration 552100: Avg Loss =  0.22278\n",
      "Iteration 552200: Avg Loss =  0.23684\n",
      "Iteration 552300: Avg Loss =  0.22883\n",
      "Iteration 552400: Avg Loss =  0.25130\n",
      "Iteration 552500: Avg Loss =  0.27423\n",
      "Iteration 552600: Avg Loss =  0.29984\n",
      "Iteration 552700: Avg Loss =  0.21398\n",
      "Iteration 552800: Avg Loss =  0.21633\n",
      "Iteration 552900: Avg Loss =  0.22350\n",
      "Iteration 553000: Avg Loss =  0.23696\n",
      "Iteration 553100: Avg Loss =  0.20877\n",
      "Iteration 553200: Avg Loss =  0.23250\n",
      "Iteration 553300: Avg Loss =  0.23162\n",
      "Iteration 553400: Avg Loss =  0.21284\n",
      "Iteration 553500: Avg Loss =  0.23043\n",
      "Iteration 553600: Avg Loss =  0.19787\n",
      "Iteration 553700: Avg Loss =  0.22214\n",
      "Iteration 553800: Avg Loss =  0.28403\n",
      "Iteration 553900: Avg Loss =  0.20209\n",
      "Iteration 554000: Avg Loss =  0.24212\n",
      "Iteration 554100: Avg Loss =  0.21564\n",
      "Iteration 554200: Avg Loss =  0.19703\n",
      "Iteration 554300: Avg Loss =  0.21614\n",
      "Iteration 554400: Avg Loss =  0.23046\n",
      "Iteration 554500: Avg Loss =  0.22141\n",
      "Iteration 554600: Avg Loss =  0.28414\n",
      "Iteration 554700: Avg Loss =  0.21501\n",
      "Iteration 554800: Avg Loss =  0.19725\n",
      "Iteration 554900: Avg Loss =  0.20307\n",
      "Iteration 555000: Avg Loss =  0.22824\n",
      "Iteration 555100: Avg Loss =  0.25909\n",
      "Iteration 555200: Avg Loss =  0.20941\n",
      "Iteration 555300: Avg Loss =  0.24375\n",
      "Iteration 555400: Avg Loss =  0.22019\n",
      "Iteration 555500: Avg Loss =  0.21635\n",
      "Iteration 555600: Avg Loss =  0.20111\n",
      "Iteration 555700: Avg Loss =  0.23100\n",
      "Iteration 555800: Avg Loss =  0.20375\n",
      "Iteration 555900: Avg Loss =  0.18526\n",
      "Iteration 556000: Avg Loss =  0.20097\n",
      "Iteration 556100: Avg Loss =  0.22023\n",
      "Iteration 556200: Avg Loss =  0.23534\n",
      "Iteration 556300: Avg Loss =  0.22165\n",
      "Iteration 556400: Avg Loss =  0.25277\n",
      "Iteration 556500: Avg Loss =  0.21116\n",
      "Iteration 556600: Avg Loss =  0.25614\n",
      "Iteration 556700: Avg Loss =  0.18220\n",
      "Iteration 556800: Avg Loss =  0.17904\n",
      "Iteration 556900: Avg Loss =  0.19629\n",
      "Iteration 557000: Avg Loss =  0.25227\n",
      "Iteration 557100: Avg Loss =  0.27467\n",
      "Iteration 557200: Avg Loss =  0.21029\n",
      "Iteration 557300: Avg Loss =  0.26323\n",
      "Iteration 557400: Avg Loss =  0.21585\n",
      "Iteration 557500: Avg Loss =  0.19434\n",
      "Iteration 557600: Avg Loss =  0.23339\n",
      "Iteration 557700: Avg Loss =  0.23749\n",
      "Iteration 557800: Avg Loss =  0.21717\n",
      "Iteration 557900: Avg Loss =  0.21669\n",
      "Iteration 558000: Avg Loss =  0.19847\n",
      "Iteration 558100: Avg Loss =  0.18342\n",
      "Iteration 558200: Avg Loss =  0.24740\n",
      "Iteration 558300: Avg Loss =  0.18734\n",
      "Iteration 558400: Avg Loss =  0.18407\n",
      "Iteration 558500: Avg Loss =  0.18361\n",
      "Iteration 558600: Avg Loss =  0.20614\n",
      "Iteration 558700: Avg Loss =  0.19336\n",
      "Iteration 558800: Avg Loss =  0.24483\n",
      "Iteration 558900: Avg Loss =  0.22212\n",
      "Iteration 559000: Avg Loss =  0.21753\n",
      "Iteration 559100: Avg Loss =  0.28634\n",
      "Iteration 559200: Avg Loss =  0.22287\n",
      "Iteration 559300: Avg Loss =  0.24686\n",
      "Iteration 559400: Avg Loss =  0.21567\n",
      "Iteration 559500: Avg Loss =  0.24222\n",
      "Iteration 559600: Avg Loss =  0.21183\n",
      "Iteration 559700: Avg Loss =  0.24449\n",
      "Iteration 559800: Avg Loss =  0.23419\n",
      "Iteration 559900: Avg Loss =  0.22269\n",
      "Iteration 560000: Avg Loss =  0.24772\n",
      "Iteration 560100: Avg Loss =  0.20743\n",
      "Iteration 560200: Avg Loss =  0.22444\n",
      "Iteration 560300: Avg Loss =  0.23715\n",
      "Iteration 560400: Avg Loss =  0.24016\n",
      "Iteration 560500: Avg Loss =  0.24911\n",
      "Iteration 560600: Avg Loss =  0.21376\n",
      "Iteration 560700: Avg Loss =  0.21081\n",
      "Iteration 560800: Avg Loss =  0.23557\n",
      "Iteration 560900: Avg Loss =  0.25000\n",
      "Iteration 561000: Avg Loss =  0.24296\n",
      "Iteration 561100: Avg Loss =  0.22664\n",
      "Iteration 561200: Avg Loss =  0.23090\n",
      "Iteration 561300: Avg Loss =  0.19387\n",
      "Iteration 561400: Avg Loss =  0.24291\n",
      "Iteration 561500: Avg Loss =  0.26925\n",
      "Iteration 561600: Avg Loss =  0.23952\n",
      "Iteration 561700: Avg Loss =  0.18645\n",
      "Iteration 561800: Avg Loss =  0.21623\n",
      "Iteration 561900: Avg Loss =  0.19847\n",
      "Iteration 562000: Avg Loss =  0.22718\n",
      "Iteration 562100: Avg Loss =  0.19440\n",
      "Iteration 562200: Avg Loss =  0.18644\n",
      "Iteration 562300: Avg Loss =  0.21568\n",
      "Iteration 562400: Avg Loss =  0.21897\n",
      "Iteration 562500: Avg Loss =  0.24594\n",
      "Iteration 562600: Avg Loss =  0.23433\n",
      "Iteration 562700: Avg Loss =  0.24404\n",
      "Iteration 562800: Avg Loss =  0.20452\n",
      "Iteration 562900: Avg Loss =  0.22949\n",
      "Iteration 563000: Avg Loss =  0.24500\n",
      "Iteration 563100: Avg Loss =  0.20920\n",
      "Iteration 563200: Avg Loss =  0.20900\n",
      "Iteration 563300: Avg Loss =  0.27149\n",
      "Iteration 563400: Avg Loss =  0.22833\n",
      "Iteration 563500: Avg Loss =  0.19623\n",
      "Iteration 563600: Avg Loss =  0.19730\n",
      "Iteration 563700: Avg Loss =  0.24569\n",
      "Iteration 563800: Avg Loss =  0.21679\n",
      "Iteration 563900: Avg Loss =  0.21530\n",
      "Iteration 564000: Avg Loss =  0.20902\n",
      "Iteration 564100: Avg Loss =  0.21501\n",
      "Iteration 564200: Avg Loss =  0.21584\n",
      "Iteration 564300: Avg Loss =  0.26631\n",
      "Iteration 564400: Avg Loss =  0.24404\n",
      "Iteration 564500: Avg Loss =  0.18187\n",
      "Iteration 564600: Avg Loss =  0.21220\n",
      "Iteration 564700: Avg Loss =  0.27036\n",
      "Iteration 564800: Avg Loss =  0.19320\n",
      "Iteration 564900: Avg Loss =  0.19917\n",
      "Iteration 565000: Avg Loss =  0.22510\n",
      "Iteration 565100: Avg Loss =  0.21798\n",
      "Iteration 565200: Avg Loss =  0.19976\n",
      "Iteration 565300: Avg Loss =  0.24744\n",
      "Iteration 565400: Avg Loss =  0.24812\n",
      "Iteration 565500: Avg Loss =  0.19966\n",
      "Iteration 565600: Avg Loss =  0.22679\n",
      "Iteration 565700: Avg Loss =  0.24969\n",
      "Iteration 565800: Avg Loss =  0.25532\n",
      "Iteration 565900: Avg Loss =  0.23946\n",
      "Iteration 566000: Avg Loss =  0.23905\n",
      "Iteration 566100: Avg Loss =  0.26754\n",
      "Iteration 566200: Avg Loss =  0.24565\n",
      "Iteration 566300: Avg Loss =  0.18527\n",
      "Iteration 566400: Avg Loss =  0.24721\n",
      "Iteration 566500: Avg Loss =  0.24767\n",
      "Iteration 566600: Avg Loss =  0.17653\n",
      "Iteration 566700: Avg Loss =  0.20758\n",
      "Iteration 566800: Avg Loss =  0.22685\n",
      "Iteration 566900: Avg Loss =  0.21445\n",
      "Iteration 567000: Avg Loss =  0.25709\n",
      "Iteration 567100: Avg Loss =  0.21191\n",
      "Iteration 567200: Avg Loss =  0.23242\n",
      "Iteration 567300: Avg Loss =  0.25967\n",
      "Iteration 567400: Avg Loss =  0.24857\n",
      "Iteration 567500: Avg Loss =  0.24145\n",
      "Iteration 567600: Avg Loss =  0.21473\n",
      "Iteration 567700: Avg Loss =  0.24248\n",
      "Iteration 567800: Avg Loss =  0.20258\n",
      "Iteration 567900: Avg Loss =  0.19723\n",
      "Iteration 568000: Avg Loss =  0.25224\n",
      "Iteration 568100: Avg Loss =  0.23985\n",
      "Iteration 568200: Avg Loss =  0.24095\n",
      "Iteration 568300: Avg Loss =  0.21716\n",
      "Iteration 568400: Avg Loss =  0.21989\n",
      "Iteration 568500: Avg Loss =  0.19656\n",
      "Iteration 568600: Avg Loss =  0.22644\n",
      "Iteration 568700: Avg Loss =  0.16741\n",
      "Iteration 568800: Avg Loss =  0.23674\n",
      "Iteration 568900: Avg Loss =  0.20607\n",
      "Iteration 569000: Avg Loss =  0.24876\n",
      "Iteration 569100: Avg Loss =  0.25482\n",
      "Iteration 569200: Avg Loss =  0.25195\n",
      "Iteration 569300: Avg Loss =  0.20576\n",
      "Iteration 569400: Avg Loss =  0.21734\n",
      "Iteration 569500: Avg Loss =  0.26547\n",
      "Iteration 569600: Avg Loss =  0.21851\n",
      "Iteration 569700: Avg Loss =  0.23738\n",
      "Iteration 569800: Avg Loss =  0.19928\n",
      "Iteration 569900: Avg Loss =  0.23985\n",
      "Iteration 570000: Avg Loss =  0.21261\n",
      "Iteration 570100: Avg Loss =  0.20563\n",
      "Iteration 570200: Avg Loss =  0.21911\n",
      "Iteration 570300: Avg Loss =  0.20660\n",
      "Iteration 570400: Avg Loss =  0.21450\n",
      "Iteration 570500: Avg Loss =  0.23533\n",
      "Iteration 570600: Avg Loss =  0.20803\n",
      "Iteration 570700: Avg Loss =  0.22447\n",
      "Iteration 570800: Avg Loss =  0.23525\n",
      "Iteration 570900: Avg Loss =  0.20631\n",
      "Iteration 571000: Avg Loss =  0.19622\n",
      "Iteration 571100: Avg Loss =  0.22263\n",
      "Iteration 571200: Avg Loss =  0.21830\n",
      "Iteration 571300: Avg Loss =  0.20322\n",
      "Iteration 571400: Avg Loss =  0.20710\n",
      "Iteration 571500: Avg Loss =  0.20238\n",
      "Iteration 571600: Avg Loss =  0.20859\n",
      "Iteration 571700: Avg Loss =  0.24043\n",
      "Iteration 571800: Avg Loss =  0.26396\n",
      "Iteration 571900: Avg Loss =  0.20885\n",
      "Iteration 572000: Avg Loss =  0.21721\n",
      "Iteration 572100: Avg Loss =  0.21789\n",
      "Iteration 572200: Avg Loss =  0.19368\n",
      "Iteration 572300: Avg Loss =  0.23748\n",
      "Iteration 572400: Avg Loss =  0.21675\n",
      "Iteration 572500: Avg Loss =  0.20790\n",
      "Iteration 572600: Avg Loss =  0.23681\n",
      "Iteration 572700: Avg Loss =  0.21084\n",
      "Iteration 572800: Avg Loss =  0.22354\n",
      "Iteration 572900: Avg Loss =  0.22344\n",
      "Iteration 573000: Avg Loss =  0.20751\n",
      "Iteration 573100: Avg Loss =  0.21246\n",
      "Iteration 573200: Avg Loss =  0.21707\n",
      "Iteration 573300: Avg Loss =  0.23553\n",
      "Iteration 573400: Avg Loss =  0.25071\n",
      "Iteration 573500: Avg Loss =  0.21596\n",
      "Iteration 573600: Avg Loss =  0.21635\n",
      "Iteration 573700: Avg Loss =  0.22761\n",
      "Iteration 573800: Avg Loss =  0.22981\n",
      "Iteration 573900: Avg Loss =  0.22730\n",
      "Iteration 574000: Avg Loss =  0.22176\n",
      "Iteration 574100: Avg Loss =  0.22372\n",
      "Iteration 574200: Avg Loss =  0.21230\n",
      "Iteration 574300: Avg Loss =  0.27331\n",
      "Iteration 574400: Avg Loss =  0.20922\n",
      "Iteration 574500: Avg Loss =  0.22731\n",
      "Iteration 574600: Avg Loss =  0.23424\n",
      "Iteration 574700: Avg Loss =  0.26746\n",
      "Iteration 574800: Avg Loss =  0.20585\n",
      "Iteration 574900: Avg Loss =  0.21533\n",
      "Iteration 575000: Avg Loss =  0.22260\n",
      "Iteration 575100: Avg Loss =  0.28849\n",
      "Iteration 575200: Avg Loss =  0.20123\n",
      "Iteration 575300: Avg Loss =  0.24824\n",
      "Iteration 575400: Avg Loss =  0.20338\n",
      "Iteration 575500: Avg Loss =  0.25316\n",
      "Iteration 575600: Avg Loss =  0.20652\n",
      "Iteration 575700: Avg Loss =  0.25574\n",
      "Iteration 575800: Avg Loss =  0.21677\n",
      "Iteration 575900: Avg Loss =  0.22905\n",
      "Iteration 576000: Avg Loss =  0.19096\n",
      "Iteration 576100: Avg Loss =  0.20543\n",
      "Iteration 576200: Avg Loss =  0.23621\n",
      "Iteration 576300: Avg Loss =  0.20385\n",
      "Iteration 576400: Avg Loss =  0.23171\n",
      "Iteration 576500: Avg Loss =  0.22129\n",
      "Iteration 576600: Avg Loss =  0.20362\n",
      "Iteration 576700: Avg Loss =  0.21813\n",
      "Iteration 576800: Avg Loss =  0.22861\n",
      "Iteration 576900: Avg Loss =  0.26049\n",
      "Iteration 577000: Avg Loss =  0.21774\n",
      "Iteration 577100: Avg Loss =  0.20342\n",
      "Iteration 577200: Avg Loss =  0.25951\n",
      "Iteration 577300: Avg Loss =  0.26272\n",
      "Iteration 577400: Avg Loss =  0.23011\n",
      "Iteration 577500: Avg Loss =  0.22944\n",
      "Iteration 577600: Avg Loss =  0.20686\n",
      "Iteration 577700: Avg Loss =  0.24912\n",
      "Iteration 577800: Avg Loss =  0.19023\n",
      "Iteration 577900: Avg Loss =  0.21571\n",
      "Iteration 578000: Avg Loss =  0.26713\n",
      "Iteration 578100: Avg Loss =  0.24559\n",
      "Iteration 578200: Avg Loss =  0.20623\n",
      "Iteration 578300: Avg Loss =  0.22302\n",
      "Iteration 578400: Avg Loss =  0.26380\n",
      "Iteration 578500: Avg Loss =  0.21351\n",
      "Iteration 578600: Avg Loss =  0.19923\n",
      "Iteration 578700: Avg Loss =  0.16888\n",
      "Iteration 578800: Avg Loss =  0.21229\n",
      "Iteration 578900: Avg Loss =  0.23563\n",
      "Iteration 579000: Avg Loss =  0.22430\n",
      "Iteration 579100: Avg Loss =  0.21623\n",
      "Iteration 579200: Avg Loss =  0.25470\n",
      "Iteration 579300: Avg Loss =  0.21602\n",
      "Iteration 579400: Avg Loss =  0.21400\n",
      "Iteration 579500: Avg Loss =  0.23000\n",
      "Iteration 579600: Avg Loss =  0.22479\n",
      "Iteration 579700: Avg Loss =  0.19853\n",
      "Iteration 579800: Avg Loss =  0.22186\n",
      "Iteration 579900: Avg Loss =  0.28236\n",
      "Iteration 580000: Avg Loss =  0.24078\n",
      "Iteration 580100: Avg Loss =  0.20693\n",
      "Iteration 580200: Avg Loss =  0.27595\n",
      "Iteration 580300: Avg Loss =  0.23478\n",
      "Iteration 580400: Avg Loss =  0.24634\n",
      "Iteration 580500: Avg Loss =  0.18122\n",
      "Iteration 580600: Avg Loss =  0.23284\n",
      "Iteration 580700: Avg Loss =  0.23689\n",
      "Iteration 580800: Avg Loss =  0.24978\n",
      "Iteration 580900: Avg Loss =  0.26033\n",
      "Iteration 581000: Avg Loss =  0.22452\n",
      "Iteration 581100: Avg Loss =  0.19214\n",
      "Iteration 581200: Avg Loss =  0.20809\n",
      "Iteration 581300: Avg Loss =  0.27468\n",
      "Iteration 581400: Avg Loss =  0.22248\n",
      "Iteration 581500: Avg Loss =  0.22036\n",
      "Iteration 581600: Avg Loss =  0.23379\n",
      "Iteration 581700: Avg Loss =  0.19582\n",
      "Iteration 581800: Avg Loss =  0.22100\n",
      "Iteration 581900: Avg Loss =  0.22008\n",
      "Iteration 582000: Avg Loss =  0.20623\n",
      "Iteration 582100: Avg Loss =  0.22299\n",
      "Iteration 582200: Avg Loss =  0.19069\n",
      "Iteration 582300: Avg Loss =  0.24174\n",
      "Iteration 582400: Avg Loss =  0.21883\n",
      "Iteration 582500: Avg Loss =  0.24038\n",
      "Iteration 582600: Avg Loss =  0.20338\n",
      "Iteration 582700: Avg Loss =  0.24512\n",
      "Iteration 582800: Avg Loss =  0.19958\n",
      "Iteration 582900: Avg Loss =  0.19802\n",
      "Iteration 583000: Avg Loss =  0.23211\n",
      "Iteration 583100: Avg Loss =  0.24640\n",
      "Iteration 583200: Avg Loss =  0.27376\n",
      "Iteration 583300: Avg Loss =  0.26279\n",
      "Iteration 583400: Avg Loss =  0.19805\n",
      "Iteration 583500: Avg Loss =  0.28248\n",
      "Iteration 583600: Avg Loss =  0.23698\n",
      "Iteration 583700: Avg Loss =  0.21273\n",
      "Iteration 583800: Avg Loss =  0.23019\n",
      "Iteration 583900: Avg Loss =  0.22815\n",
      "Iteration 584000: Avg Loss =  0.19897\n",
      "Iteration 584100: Avg Loss =  0.18714\n",
      "Iteration 584200: Avg Loss =  0.20478\n",
      "Iteration 584300: Avg Loss =  0.25707\n",
      "Iteration 584400: Avg Loss =  0.20541\n",
      "Iteration 584500: Avg Loss =  0.21495\n",
      "Iteration 584600: Avg Loss =  0.25357\n",
      "Iteration 584700: Avg Loss =  0.24806\n",
      "Iteration 584800: Avg Loss =  0.19925\n",
      "Iteration 584900: Avg Loss =  0.22676\n",
      "Iteration 585000: Avg Loss =  0.22788\n",
      "Iteration 585100: Avg Loss =  0.26614\n",
      "Iteration 585200: Avg Loss =  0.19384\n",
      "Iteration 585300: Avg Loss =  0.24202\n",
      "Iteration 585400: Avg Loss =  0.26446\n",
      "Iteration 585500: Avg Loss =  0.22620\n",
      "Iteration 585600: Avg Loss =  0.23980\n",
      "Iteration 585700: Avg Loss =  0.24037\n",
      "Iteration 585800: Avg Loss =  0.18658\n",
      "Iteration 585900: Avg Loss =  0.23187\n",
      "Iteration 586000: Avg Loss =  0.21884\n",
      "Iteration 586100: Avg Loss =  0.22329\n",
      "Iteration 586200: Avg Loss =  0.22767\n",
      "Iteration 586300: Avg Loss =  0.20950\n",
      "Iteration 586400: Avg Loss =  0.24163\n",
      "Iteration 586500: Avg Loss =  0.22906\n",
      "Iteration 586600: Avg Loss =  0.21371\n",
      "Iteration 586700: Avg Loss =  0.23065\n",
      "Iteration 586800: Avg Loss =  0.20696\n",
      "Iteration 586900: Avg Loss =  0.25488\n",
      "Iteration 587000: Avg Loss =  0.23349\n",
      "Iteration 587100: Avg Loss =  0.19738\n",
      "Iteration 587200: Avg Loss =  0.23602\n",
      "Iteration 587300: Avg Loss =  0.20681\n",
      "Iteration 587400: Avg Loss =  0.19710\n",
      "Iteration 587500: Avg Loss =  0.21181\n",
      "Iteration 587600: Avg Loss =  0.23772\n",
      "Iteration 587700: Avg Loss =  0.21972\n",
      "Iteration 587800: Avg Loss =  0.26251\n",
      "Iteration 587900: Avg Loss =  0.21754\n",
      "Iteration 588000: Avg Loss =  0.20532\n",
      "Iteration 588100: Avg Loss =  0.20411\n",
      "Iteration 588200: Avg Loss =  0.20005\n",
      "Iteration 588300: Avg Loss =  0.17911\n",
      "Iteration 588400: Avg Loss =  0.20179\n",
      "Iteration 588500: Avg Loss =  0.27861\n",
      "Iteration 588600: Avg Loss =  0.23550\n",
      "Iteration 588700: Avg Loss =  0.20870\n",
      "Iteration 588800: Avg Loss =  0.24145\n",
      "Iteration 588900: Avg Loss =  0.23283\n",
      "Iteration 589000: Avg Loss =  0.24285\n",
      "Iteration 589100: Avg Loss =  0.19838\n",
      "Iteration 589200: Avg Loss =  0.24137\n",
      "Iteration 589300: Avg Loss =  0.25200\n",
      "Iteration 589400: Avg Loss =  0.22321\n",
      "Iteration 589500: Avg Loss =  0.21344\n",
      "Iteration 589600: Avg Loss =  0.18427\n",
      "Iteration 589700: Avg Loss =  0.22213\n",
      "Iteration 589800: Avg Loss =  0.25584\n",
      "Iteration 589900: Avg Loss =  0.24251\n",
      "Iteration 590000: Avg Loss =  0.24507\n",
      "Iteration 590100: Avg Loss =  0.23694\n",
      "Iteration 590200: Avg Loss =  0.23985\n",
      "Iteration 590300: Avg Loss =  0.20537\n",
      "Iteration 590400: Avg Loss =  0.19967\n",
      "Iteration 590500: Avg Loss =  0.21370\n",
      "Iteration 590600: Avg Loss =  0.21795\n",
      "Iteration 590700: Avg Loss =  0.19963\n",
      "Iteration 590800: Avg Loss =  0.18036\n",
      "Iteration 590900: Avg Loss =  0.18919\n",
      "Iteration 591000: Avg Loss =  0.24321\n",
      "Iteration 591100: Avg Loss =  0.19433\n",
      "Iteration 591200: Avg Loss =  0.19340\n",
      "Iteration 591300: Avg Loss =  0.25126\n",
      "Iteration 591400: Avg Loss =  0.23906\n",
      "Iteration 591500: Avg Loss =  0.25578\n",
      "Iteration 591600: Avg Loss =  0.22907\n",
      "Iteration 591700: Avg Loss =  0.23807\n",
      "Iteration 591800: Avg Loss =  0.21064\n",
      "Iteration 591900: Avg Loss =  0.25775\n",
      "Iteration 592000: Avg Loss =  0.20411\n",
      "Iteration 592100: Avg Loss =  0.25988\n",
      "Iteration 592200: Avg Loss =  0.26209\n",
      "Iteration 592300: Avg Loss =  0.26172\n",
      "Iteration 592400: Avg Loss =  0.19591\n",
      "Iteration 592500: Avg Loss =  0.20807\n",
      "Iteration 592600: Avg Loss =  0.19602\n",
      "Iteration 592700: Avg Loss =  0.23511\n",
      "Iteration 592800: Avg Loss =  0.20030\n",
      "Iteration 592900: Avg Loss =  0.20035\n",
      "Iteration 593000: Avg Loss =  0.20655\n",
      "Iteration 593100: Avg Loss =  0.20890\n",
      "Iteration 593200: Avg Loss =  0.22819\n",
      "Iteration 593300: Avg Loss =  0.24452\n",
      "Iteration 593400: Avg Loss =  0.23862\n",
      "Iteration 593500: Avg Loss =  0.25868\n",
      "Iteration 593600: Avg Loss =  0.21413\n",
      "Iteration 593700: Avg Loss =  0.22111\n",
      "Iteration 593800: Avg Loss =  0.26216\n",
      "Iteration 593900: Avg Loss =  0.25989\n",
      "Iteration 594000: Avg Loss =  0.20872\n",
      "Iteration 594100: Avg Loss =  0.20692\n",
      "Iteration 594200: Avg Loss =  0.19253\n",
      "Iteration 594300: Avg Loss =  0.24860\n",
      "Iteration 594400: Avg Loss =  0.21671\n",
      "Iteration 594500: Avg Loss =  0.21839\n",
      "Iteration 594600: Avg Loss =  0.23179\n",
      "Iteration 594700: Avg Loss =  0.22342\n",
      "Iteration 594800: Avg Loss =  0.22359\n",
      "Iteration 594900: Avg Loss =  0.25316\n",
      "Iteration 595000: Avg Loss =  0.25215\n",
      "Iteration 595100: Avg Loss =  0.21695\n",
      "Iteration 595200: Avg Loss =  0.25703\n",
      "Iteration 595300: Avg Loss =  0.23045\n",
      "Iteration 595400: Avg Loss =  0.24637\n",
      "Iteration 595500: Avg Loss =  0.19377\n",
      "Iteration 595600: Avg Loss =  0.19835\n",
      "Iteration 595700: Avg Loss =  0.24730\n",
      "Iteration 595800: Avg Loss =  0.21726\n",
      "Iteration 595900: Avg Loss =  0.20574\n",
      "Iteration 596000: Avg Loss =  0.25752\n",
      "Iteration 596100: Avg Loss =  0.20674\n",
      "Iteration 596200: Avg Loss =  0.22521\n",
      "Iteration 596300: Avg Loss =  0.18901\n",
      "Iteration 596400: Avg Loss =  0.25124\n",
      "Iteration 596500: Avg Loss =  0.20957\n",
      "Iteration 596600: Avg Loss =  0.24826\n",
      "Iteration 596700: Avg Loss =  0.22166\n",
      "Iteration 596800: Avg Loss =  0.19332\n",
      "Iteration 596900: Avg Loss =  0.20823\n",
      "Iteration 597000: Avg Loss =  0.21946\n",
      "Iteration 597100: Avg Loss =  0.21320\n",
      "Iteration 597200: Avg Loss =  0.19264\n",
      "Iteration 597300: Avg Loss =  0.24271\n",
      "Iteration 597400: Avg Loss =  0.24659\n",
      "Iteration 597500: Avg Loss =  0.22853\n",
      "Iteration 597600: Avg Loss =  0.22031\n",
      "Iteration 597700: Avg Loss =  0.27042\n",
      "Iteration 597800: Avg Loss =  0.23116\n",
      "Iteration 597900: Avg Loss =  0.23923\n",
      "Iteration 598000: Avg Loss =  0.20015\n",
      "Iteration 598100: Avg Loss =  0.17291\n",
      "Iteration 598200: Avg Loss =  0.18607\n",
      "Iteration 598300: Avg Loss =  0.24880\n",
      "Iteration 598400: Avg Loss =  0.24509\n",
      "Iteration 598500: Avg Loss =  0.21467\n",
      "Iteration 598600: Avg Loss =  0.23361\n",
      "Iteration 598700: Avg Loss =  0.22209\n",
      "Iteration 598800: Avg Loss =  0.23007\n",
      "Iteration 598900: Avg Loss =  0.21533\n",
      "Iteration 599000: Avg Loss =  0.25954\n",
      "Iteration 599100: Avg Loss =  0.22886\n",
      "Iteration 599200: Avg Loss =  0.21102\n",
      "Iteration 599300: Avg Loss =  0.18868\n",
      "Iteration 599400: Avg Loss =  0.22407\n",
      "Iteration 599500: Avg Loss =  0.20889\n",
      "Iteration 599600: Avg Loss =  0.22413\n",
      "Iteration 599700: Avg Loss =  0.17913\n",
      "Iteration 599800: Avg Loss =  0.21426\n",
      "Iteration 599900: Avg Loss =  0.20538\n",
      "Iteration 600000: Avg Loss =  0.21785\n",
      "Iteration 600100: Avg Loss =  0.22390\n",
      "Iteration 600200: Avg Loss =  0.26531\n",
      "Iteration 600300: Avg Loss =  0.24898\n",
      "Iteration 600400: Avg Loss =  0.25563\n",
      "Iteration 600500: Avg Loss =  0.21766\n",
      "Iteration 600600: Avg Loss =  0.25289\n",
      "Iteration 600700: Avg Loss =  0.24978\n",
      "Iteration 600800: Avg Loss =  0.21404\n",
      "Iteration 600900: Avg Loss =  0.21514\n",
      "Iteration 601000: Avg Loss =  0.26414\n",
      "Iteration 601100: Avg Loss =  0.27052\n",
      "Iteration 601200: Avg Loss =  0.26178\n",
      "Iteration 601300: Avg Loss =  0.24127\n",
      "Iteration 601400: Avg Loss =  0.21494\n",
      "Iteration 601500: Avg Loss =  0.23106\n",
      "Iteration 601600: Avg Loss =  0.22572\n",
      "Iteration 601700: Avg Loss =  0.20521\n",
      "Iteration 601800: Avg Loss =  0.18910\n",
      "Iteration 601900: Avg Loss =  0.22696\n",
      "Iteration 602000: Avg Loss =  0.25054\n",
      "Iteration 602100: Avg Loss =  0.22462\n",
      "Iteration 602200: Avg Loss =  0.23995\n",
      "Iteration 602300: Avg Loss =  0.24476\n",
      "Iteration 602400: Avg Loss =  0.22625\n",
      "Iteration 602500: Avg Loss =  0.20052\n",
      "Iteration 602600: Avg Loss =  0.20957\n",
      "Iteration 602700: Avg Loss =  0.27709\n",
      "Iteration 602800: Avg Loss =  0.25109\n",
      "Iteration 602900: Avg Loss =  0.22845\n",
      "Iteration 603000: Avg Loss =  0.22058\n",
      "Iteration 603100: Avg Loss =  0.19889\n",
      "Iteration 603200: Avg Loss =  0.22800\n",
      "Iteration 603300: Avg Loss =  0.20997\n",
      "Iteration 603400: Avg Loss =  0.20341\n",
      "Iteration 603500: Avg Loss =  0.19605\n",
      "Iteration 603600: Avg Loss =  0.21974\n",
      "Iteration 603700: Avg Loss =  0.17251\n",
      "Iteration 603800: Avg Loss =  0.19586\n",
      "Iteration 603900: Avg Loss =  0.26107\n",
      "Iteration 604000: Avg Loss =  0.25012\n",
      "Iteration 604100: Avg Loss =  0.22700\n",
      "Iteration 604200: Avg Loss =  0.24440\n",
      "Iteration 604300: Avg Loss =  0.22104\n",
      "Iteration 604400: Avg Loss =  0.24757\n",
      "Iteration 604500: Avg Loss =  0.25174\n",
      "Iteration 604600: Avg Loss =  0.20707\n",
      "Iteration 604700: Avg Loss =  0.25493\n",
      "Iteration 604800: Avg Loss =  0.21270\n",
      "Iteration 604900: Avg Loss =  0.23698\n",
      "Iteration 605000: Avg Loss =  0.19732\n",
      "Iteration 605100: Avg Loss =  0.21059\n",
      "Iteration 605200: Avg Loss =  0.21320\n",
      "Iteration 605300: Avg Loss =  0.23816\n",
      "Iteration 605400: Avg Loss =  0.23130\n",
      "Iteration 605500: Avg Loss =  0.25939\n",
      "Iteration 605600: Avg Loss =  0.20957\n",
      "Iteration 605700: Avg Loss =  0.23315\n",
      "Iteration 605800: Avg Loss =  0.25302\n",
      "Iteration 605900: Avg Loss =  0.23313\n",
      "Iteration 606000: Avg Loss =  0.21245\n",
      "Iteration 606100: Avg Loss =  0.21849\n",
      "Iteration 606200: Avg Loss =  0.23798\n",
      "Iteration 606300: Avg Loss =  0.22150\n",
      "Iteration 606400: Avg Loss =  0.21587\n",
      "Iteration 606500: Avg Loss =  0.28751\n",
      "Iteration 606600: Avg Loss =  0.25004\n",
      "Iteration 606700: Avg Loss =  0.20639\n",
      "Iteration 606800: Avg Loss =  0.21179\n",
      "Iteration 606900: Avg Loss =  0.22609\n",
      "Iteration 607000: Avg Loss =  0.20308\n",
      "Iteration 607100: Avg Loss =  0.22969\n",
      "Iteration 607200: Avg Loss =  0.22112\n",
      "Iteration 607300: Avg Loss =  0.21098\n",
      "Iteration 607400: Avg Loss =  0.24632\n",
      "Iteration 607500: Avg Loss =  0.20318\n",
      "Iteration 607600: Avg Loss =  0.23586\n",
      "Iteration 607700: Avg Loss =  0.19455\n",
      "Iteration 607800: Avg Loss =  0.20963\n",
      "Iteration 607900: Avg Loss =  0.20273\n",
      "Iteration 608000: Avg Loss =  0.23190\n",
      "Iteration 608100: Avg Loss =  0.20673\n",
      "Iteration 608200: Avg Loss =  0.20576\n",
      "Iteration 608300: Avg Loss =  0.21246\n",
      "Iteration 608400: Avg Loss =  0.21076\n",
      "Iteration 608500: Avg Loss =  0.20082\n",
      "Iteration 608600: Avg Loss =  0.23826\n",
      "Iteration 608700: Avg Loss =  0.20676\n",
      "Iteration 608800: Avg Loss =  0.23094\n",
      "Iteration 608900: Avg Loss =  0.21467\n",
      "Iteration 609000: Avg Loss =  0.22976\n",
      "Iteration 609100: Avg Loss =  0.19588\n",
      "Iteration 609200: Avg Loss =  0.19285\n",
      "Iteration 609300: Avg Loss =  0.22073\n",
      "Iteration 609400: Avg Loss =  0.24246\n",
      "Iteration 609500: Avg Loss =  0.19572\n",
      "Iteration 609600: Avg Loss =  0.24173\n",
      "Iteration 609700: Avg Loss =  0.26598\n",
      "Iteration 609800: Avg Loss =  0.26338\n",
      "Iteration 609900: Avg Loss =  0.24292\n",
      "Iteration 610000: Avg Loss =  0.24730\n",
      "Iteration 610100: Avg Loss =  0.19865\n",
      "Iteration 610200: Avg Loss =  0.23353\n",
      "Iteration 610300: Avg Loss =  0.23330\n",
      "Iteration 610400: Avg Loss =  0.23656\n",
      "Iteration 610500: Avg Loss =  0.23141\n",
      "Iteration 610600: Avg Loss =  0.24147\n",
      "Iteration 610700: Avg Loss =  0.19938\n",
      "Iteration 610800: Avg Loss =  0.24435\n",
      "Iteration 610900: Avg Loss =  0.17655\n",
      "Iteration 611000: Avg Loss =  0.23670\n",
      "Iteration 611100: Avg Loss =  0.20149\n",
      "Iteration 611200: Avg Loss =  0.30109\n",
      "Iteration 611300: Avg Loss =  0.23019\n",
      "Iteration 611400: Avg Loss =  0.22612\n",
      "Iteration 611500: Avg Loss =  0.22136\n",
      "Iteration 611600: Avg Loss =  0.19472\n",
      "Iteration 611700: Avg Loss =  0.20129\n",
      "Iteration 611800: Avg Loss =  0.24833\n",
      "Iteration 611900: Avg Loss =  0.20182\n",
      "Iteration 612000: Avg Loss =  0.22988\n",
      "Iteration 612100: Avg Loss =  0.22103\n",
      "Iteration 612200: Avg Loss =  0.23663\n",
      "Iteration 612300: Avg Loss =  0.20181\n",
      "Iteration 612400: Avg Loss =  0.21263\n",
      "Iteration 612500: Avg Loss =  0.22611\n",
      "Iteration 612600: Avg Loss =  0.26342\n",
      "Iteration 612700: Avg Loss =  0.17814\n",
      "Iteration 612800: Avg Loss =  0.20996\n",
      "Iteration 612900: Avg Loss =  0.23485\n",
      "Iteration 613000: Avg Loss =  0.22676\n",
      "Iteration 613100: Avg Loss =  0.24425\n",
      "Iteration 613200: Avg Loss =  0.22842\n",
      "Iteration 613300: Avg Loss =  0.22345\n",
      "Iteration 613400: Avg Loss =  0.26651\n",
      "Iteration 613500: Avg Loss =  0.19110\n",
      "Iteration 613600: Avg Loss =  0.16698\n",
      "Iteration 613700: Avg Loss =  0.20607\n",
      "Iteration 613800: Avg Loss =  0.20512\n",
      "Iteration 613900: Avg Loss =  0.20099\n",
      "Iteration 614000: Avg Loss =  0.21993\n",
      "Iteration 614100: Avg Loss =  0.21456\n",
      "Iteration 614200: Avg Loss =  0.20347\n",
      "Iteration 614300: Avg Loss =  0.19337\n",
      "Iteration 614400: Avg Loss =  0.26835\n",
      "Iteration 614500: Avg Loss =  0.25122\n",
      "Iteration 614600: Avg Loss =  0.24326\n",
      "Iteration 614700: Avg Loss =  0.20077\n",
      "Iteration 614800: Avg Loss =  0.19326\n",
      "Iteration 614900: Avg Loss =  0.24084\n",
      "Iteration 615000: Avg Loss =  0.18633\n",
      "Iteration 615100: Avg Loss =  0.24065\n",
      "Iteration 615200: Avg Loss =  0.21627\n",
      "Iteration 615300: Avg Loss =  0.22233\n",
      "Iteration 615400: Avg Loss =  0.21282\n",
      "Iteration 615500: Avg Loss =  0.21839\n",
      "Iteration 615600: Avg Loss =  0.23590\n",
      "Iteration 615700: Avg Loss =  0.26106\n",
      "Iteration 615800: Avg Loss =  0.21862\n",
      "Iteration 615900: Avg Loss =  0.18692\n",
      "Iteration 616000: Avg Loss =  0.21388\n",
      "Iteration 616100: Avg Loss =  0.21700\n",
      "Iteration 616200: Avg Loss =  0.20868\n",
      "Iteration 616300: Avg Loss =  0.23531\n",
      "Iteration 616400: Avg Loss =  0.22988\n",
      "Iteration 616500: Avg Loss =  0.24384\n",
      "Iteration 616600: Avg Loss =  0.19852\n",
      "Iteration 616700: Avg Loss =  0.21393\n",
      "Iteration 616800: Avg Loss =  0.24033\n",
      "Iteration 616900: Avg Loss =  0.24989\n",
      "Iteration 617000: Avg Loss =  0.24867\n",
      "Iteration 617100: Avg Loss =  0.21101\n",
      "Iteration 617200: Avg Loss =  0.21472\n",
      "Iteration 617300: Avg Loss =  0.22586\n",
      "Iteration 617400: Avg Loss =  0.22852\n",
      "Iteration 617500: Avg Loss =  0.24459\n",
      "Iteration 617600: Avg Loss =  0.21668\n",
      "Iteration 617700: Avg Loss =  0.24486\n",
      "Iteration 617800: Avg Loss =  0.27438\n",
      "Iteration 617900: Avg Loss =  0.22540\n",
      "Iteration 618000: Avg Loss =  0.20583\n",
      "Iteration 618100: Avg Loss =  0.22637\n",
      "Iteration 618200: Avg Loss =  0.20233\n",
      "Iteration 618300: Avg Loss =  0.24394\n",
      "Iteration 618400: Avg Loss =  0.21878\n",
      "Iteration 618500: Avg Loss =  0.21237\n",
      "Iteration 618600: Avg Loss =  0.26741\n",
      "Iteration 618700: Avg Loss =  0.21311\n",
      "Iteration 618800: Avg Loss =  0.24297\n",
      "Iteration 618900: Avg Loss =  0.25501\n",
      "Iteration 619000: Avg Loss =  0.24873\n",
      "Iteration 619100: Avg Loss =  0.26990\n",
      "Iteration 619200: Avg Loss =  0.24081\n",
      "Iteration 619300: Avg Loss =  0.26123\n",
      "Iteration 619400: Avg Loss =  0.20079\n",
      "Iteration 619500: Avg Loss =  0.20526\n",
      "Iteration 619600: Avg Loss =  0.21620\n",
      "Iteration 619700: Avg Loss =  0.21396\n",
      "Iteration 619800: Avg Loss =  0.21029\n",
      "Iteration 619900: Avg Loss =  0.20422\n",
      "Iteration 620000: Avg Loss =  0.22567\n",
      "Iteration 620100: Avg Loss =  0.24609\n",
      "Iteration 620200: Avg Loss =  0.19257\n",
      "Iteration 620300: Avg Loss =  0.19567\n",
      "Iteration 620400: Avg Loss =  0.27242\n",
      "Iteration 620500: Avg Loss =  0.20967\n",
      "Iteration 620600: Avg Loss =  0.24004\n",
      "Iteration 620700: Avg Loss =  0.23463\n",
      "Iteration 620800: Avg Loss =  0.24535\n",
      "Iteration 620900: Avg Loss =  0.20441\n",
      "Iteration 621000: Avg Loss =  0.22435\n",
      "Iteration 621100: Avg Loss =  0.20837\n",
      "Iteration 621200: Avg Loss =  0.17694\n",
      "Iteration 621300: Avg Loss =  0.24118\n",
      "Iteration 621400: Avg Loss =  0.22545\n",
      "Iteration 621500: Avg Loss =  0.24733\n",
      "Iteration 621600: Avg Loss =  0.22749\n",
      "Iteration 621700: Avg Loss =  0.19752\n",
      "Iteration 621800: Avg Loss =  0.20756\n",
      "Iteration 621900: Avg Loss =  0.26082\n",
      "Iteration 622000: Avg Loss =  0.21800\n",
      "Iteration 622100: Avg Loss =  0.24475\n",
      "Iteration 622200: Avg Loss =  0.24526\n",
      "Iteration 622300: Avg Loss =  0.26809\n",
      "Iteration 622400: Avg Loss =  0.20742\n",
      "Iteration 622500: Avg Loss =  0.22738\n",
      "Iteration 622600: Avg Loss =  0.23103\n",
      "Iteration 622700: Avg Loss =  0.20578\n",
      "Iteration 622800: Avg Loss =  0.24888\n",
      "Iteration 622900: Avg Loss =  0.25133\n",
      "Iteration 623000: Avg Loss =  0.22356\n",
      "Iteration 623100: Avg Loss =  0.21593\n",
      "Iteration 623200: Avg Loss =  0.20614\n",
      "Iteration 623300: Avg Loss =  0.22212\n",
      "Iteration 623400: Avg Loss =  0.19802\n",
      "Iteration 623500: Avg Loss =  0.22006\n",
      "Iteration 623600: Avg Loss =  0.25230\n",
      "Iteration 623700: Avg Loss =  0.24342\n",
      "Iteration 623800: Avg Loss =  0.23443\n",
      "Iteration 623900: Avg Loss =  0.18428\n",
      "Iteration 624000: Avg Loss =  0.22243\n",
      "Iteration 624100: Avg Loss =  0.23452\n",
      "Iteration 624200: Avg Loss =  0.24235\n",
      "Iteration 624300: Avg Loss =  0.20981\n",
      "Iteration 624400: Avg Loss =  0.23966\n",
      "Iteration 624500: Avg Loss =  0.23645\n",
      "Iteration 624600: Avg Loss =  0.23304\n",
      "Iteration 624700: Avg Loss =  0.24602\n",
      "Iteration 624800: Avg Loss =  0.19824\n",
      "Iteration 624900: Avg Loss =  0.21919\n",
      "Iteration 625000: Avg Loss =  0.21620\n",
      "Iteration 625100: Avg Loss =  0.22570\n",
      "Iteration 625200: Avg Loss =  0.23474\n",
      "Iteration 625300: Avg Loss =  0.24652\n",
      "Iteration 625400: Avg Loss =  0.24078\n",
      "Iteration 625500: Avg Loss =  0.20064\n",
      "Iteration 625600: Avg Loss =  0.21559\n",
      "Iteration 625700: Avg Loss =  0.23630\n",
      "Iteration 625800: Avg Loss =  0.21857\n",
      "Iteration 625900: Avg Loss =  0.19379\n",
      "Iteration 626000: Avg Loss =  0.20909\n",
      "Iteration 626100: Avg Loss =  0.21781\n",
      "Iteration 626200: Avg Loss =  0.26938\n",
      "Iteration 626300: Avg Loss =  0.26856\n",
      "Iteration 626400: Avg Loss =  0.17350\n",
      "Iteration 626500: Avg Loss =  0.22598\n",
      "Iteration 626600: Avg Loss =  0.21115\n",
      "Iteration 626700: Avg Loss =  0.21583\n",
      "Iteration 626800: Avg Loss =  0.23805\n",
      "Iteration 626900: Avg Loss =  0.24095\n",
      "Iteration 627000: Avg Loss =  0.26139\n",
      "Iteration 627100: Avg Loss =  0.22562\n",
      "Iteration 627200: Avg Loss =  0.21245\n",
      "Iteration 627300: Avg Loss =  0.21715\n",
      "Iteration 627400: Avg Loss =  0.23193\n",
      "Iteration 627500: Avg Loss =  0.28289\n",
      "Iteration 627600: Avg Loss =  0.23685\n",
      "Iteration 627700: Avg Loss =  0.26375\n",
      "Iteration 627800: Avg Loss =  0.21210\n",
      "Iteration 627900: Avg Loss =  0.21576\n",
      "Iteration 628000: Avg Loss =  0.24253\n",
      "Iteration 628100: Avg Loss =  0.27698\n",
      "Iteration 628200: Avg Loss =  0.16336\n",
      "Iteration 628300: Avg Loss =  0.22426\n",
      "Iteration 628400: Avg Loss =  0.21279\n",
      "Iteration 628500: Avg Loss =  0.21889\n",
      "Iteration 628600: Avg Loss =  0.18075\n",
      "Iteration 628700: Avg Loss =  0.28455\n",
      "Iteration 628800: Avg Loss =  0.22471\n",
      "Iteration 628900: Avg Loss =  0.24648\n",
      "Iteration 629000: Avg Loss =  0.23502\n",
      "Iteration 629100: Avg Loss =  0.23487\n",
      "Iteration 629200: Avg Loss =  0.26530\n",
      "Iteration 629300: Avg Loss =  0.25722\n",
      "Iteration 629400: Avg Loss =  0.21054\n",
      "Iteration 629500: Avg Loss =  0.18398\n",
      "Iteration 629600: Avg Loss =  0.19517\n",
      "Iteration 629700: Avg Loss =  0.24159\n",
      "Iteration 629800: Avg Loss =  0.20357\n",
      "Iteration 629900: Avg Loss =  0.21308\n",
      "Iteration 630000: Avg Loss =  0.22245\n",
      "Iteration 630100: Avg Loss =  0.22230\n",
      "Iteration 630200: Avg Loss =  0.19322\n",
      "Iteration 630300: Avg Loss =  0.18828\n",
      "Iteration 630400: Avg Loss =  0.21748\n",
      "Iteration 630500: Avg Loss =  0.23898\n",
      "Iteration 630600: Avg Loss =  0.18662\n",
      "Iteration 630700: Avg Loss =  0.26087\n",
      "Iteration 630800: Avg Loss =  0.20430\n",
      "Iteration 630900: Avg Loss =  0.25195\n",
      "Iteration 631000: Avg Loss =  0.26115\n",
      "Iteration 631100: Avg Loss =  0.19236\n",
      "Iteration 631200: Avg Loss =  0.21177\n",
      "Iteration 631300: Avg Loss =  0.18736\n",
      "Iteration 631400: Avg Loss =  0.20487\n",
      "Iteration 631500: Avg Loss =  0.19189\n",
      "Iteration 631600: Avg Loss =  0.25629\n",
      "Iteration 631700: Avg Loss =  0.24855\n",
      "Iteration 631800: Avg Loss =  0.24266\n",
      "Iteration 631900: Avg Loss =  0.19929\n",
      "Iteration 632000: Avg Loss =  0.23782\n",
      "Iteration 632100: Avg Loss =  0.20582\n",
      "Iteration 632200: Avg Loss =  0.19906\n",
      "Iteration 632300: Avg Loss =  0.22606\n",
      "Iteration 632400: Avg Loss =  0.18802\n",
      "Iteration 632500: Avg Loss =  0.22549\n",
      "Iteration 632600: Avg Loss =  0.21432\n",
      "Iteration 632700: Avg Loss =  0.21169\n",
      "Iteration 632800: Avg Loss =  0.23160\n",
      "Iteration 632900: Avg Loss =  0.21233\n",
      "Iteration 633000: Avg Loss =  0.22039\n",
      "Iteration 633100: Avg Loss =  0.25531\n",
      "Iteration 633200: Avg Loss =  0.22288\n",
      "Iteration 633300: Avg Loss =  0.22115\n",
      "Iteration 633400: Avg Loss =  0.22086\n",
      "Iteration 633500: Avg Loss =  0.21771\n",
      "Iteration 633600: Avg Loss =  0.20000\n",
      "Iteration 633700: Avg Loss =  0.22105\n",
      "Iteration 633800: Avg Loss =  0.18082\n",
      "Iteration 633900: Avg Loss =  0.26405\n",
      "Iteration 634000: Avg Loss =  0.19951\n",
      "Iteration 634100: Avg Loss =  0.21258\n",
      "Iteration 634200: Avg Loss =  0.20750\n",
      "Iteration 634300: Avg Loss =  0.20371\n",
      "Iteration 634400: Avg Loss =  0.20985\n",
      "Iteration 634500: Avg Loss =  0.20382\n",
      "Iteration 634600: Avg Loss =  0.19923\n",
      "Iteration 634700: Avg Loss =  0.21640\n",
      "Iteration 634800: Avg Loss =  0.22562\n",
      "Iteration 634900: Avg Loss =  0.18713\n",
      "Iteration 635000: Avg Loss =  0.18057\n",
      "Iteration 635100: Avg Loss =  0.22107\n",
      "Iteration 635200: Avg Loss =  0.24953\n",
      "Iteration 635300: Avg Loss =  0.25386\n",
      "Iteration 635400: Avg Loss =  0.18086\n",
      "Iteration 635500: Avg Loss =  0.20074\n",
      "Iteration 635600: Avg Loss =  0.22967\n",
      "Iteration 635700: Avg Loss =  0.19627\n",
      "Iteration 635800: Avg Loss =  0.23237\n",
      "Iteration 635900: Avg Loss =  0.20493\n",
      "Iteration 636000: Avg Loss =  0.23391\n",
      "Iteration 636100: Avg Loss =  0.20392\n",
      "Iteration 636200: Avg Loss =  0.21804\n",
      "Iteration 636300: Avg Loss =  0.20948\n",
      "Iteration 636400: Avg Loss =  0.26875\n",
      "Iteration 636500: Avg Loss =  0.20303\n",
      "Iteration 636600: Avg Loss =  0.20667\n",
      "Iteration 636700: Avg Loss =  0.23684\n",
      "Iteration 636800: Avg Loss =  0.20137\n",
      "Iteration 636900: Avg Loss =  0.21776\n",
      "Iteration 637000: Avg Loss =  0.23350\n",
      "Iteration 637100: Avg Loss =  0.24643\n",
      "Iteration 637200: Avg Loss =  0.21296\n",
      "Iteration 637300: Avg Loss =  0.20276\n",
      "Iteration 637400: Avg Loss =  0.28988\n",
      "Iteration 637500: Avg Loss =  0.21918\n",
      "Iteration 637600: Avg Loss =  0.22133\n",
      "Iteration 637700: Avg Loss =  0.21076\n",
      "Iteration 637800: Avg Loss =  0.24451\n",
      "Iteration 637900: Avg Loss =  0.25352\n",
      "Iteration 638000: Avg Loss =  0.22782\n",
      "Iteration 638100: Avg Loss =  0.25030\n",
      "Iteration 638200: Avg Loss =  0.20865\n",
      "Iteration 638300: Avg Loss =  0.19530\n",
      "Iteration 638400: Avg Loss =  0.17655\n",
      "Iteration 638500: Avg Loss =  0.22314\n",
      "Iteration 638600: Avg Loss =  0.18172\n",
      "Iteration 638700: Avg Loss =  0.21151\n",
      "Iteration 638800: Avg Loss =  0.23285\n",
      "Iteration 638900: Avg Loss =  0.23927\n",
      "Iteration 639000: Avg Loss =  0.18341\n",
      "Iteration 639100: Avg Loss =  0.26968\n",
      "Iteration 639200: Avg Loss =  0.20345\n",
      "Iteration 639300: Avg Loss =  0.20047\n",
      "Iteration 639400: Avg Loss =  0.24451\n",
      "Iteration 639500: Avg Loss =  0.21905\n",
      "Iteration 639600: Avg Loss =  0.23677\n",
      "Iteration 639700: Avg Loss =  0.20974\n",
      "Iteration 639800: Avg Loss =  0.20007\n",
      "Iteration 639900: Avg Loss =  0.18813\n",
      "Iteration 640000: Avg Loss =  0.20348\n",
      "Iteration 640100: Avg Loss =  0.21889\n",
      "Iteration 640200: Avg Loss =  0.18823\n",
      "Iteration 640300: Avg Loss =  0.21087\n",
      "Iteration 640400: Avg Loss =  0.24839\n",
      "Iteration 640500: Avg Loss =  0.23789\n",
      "Iteration 640600: Avg Loss =  0.22305\n",
      "Iteration 640700: Avg Loss =  0.21607\n",
      "Iteration 640800: Avg Loss =  0.24466\n",
      "Iteration 640900: Avg Loss =  0.19682\n",
      "Iteration 641000: Avg Loss =  0.18869\n",
      "Iteration 641100: Avg Loss =  0.18595\n",
      "Iteration 641200: Avg Loss =  0.21484\n",
      "Iteration 641300: Avg Loss =  0.24239\n",
      "Iteration 641400: Avg Loss =  0.24440\n",
      "Iteration 641500: Avg Loss =  0.21289\n",
      "Iteration 641600: Avg Loss =  0.21143\n",
      "Iteration 641700: Avg Loss =  0.18245\n",
      "Iteration 641800: Avg Loss =  0.21046\n",
      "Iteration 641900: Avg Loss =  0.20109\n",
      "Iteration 642000: Avg Loss =  0.22636\n",
      "Iteration 642100: Avg Loss =  0.21542\n",
      "Iteration 642200: Avg Loss =  0.22212\n",
      "Iteration 642300: Avg Loss =  0.21712\n",
      "Iteration 642400: Avg Loss =  0.18485\n",
      "Iteration 642500: Avg Loss =  0.19614\n",
      "Iteration 642600: Avg Loss =  0.25035\n",
      "Iteration 642700: Avg Loss =  0.28505\n",
      "Iteration 642800: Avg Loss =  0.22153\n",
      "Iteration 642900: Avg Loss =  0.23698\n",
      "Iteration 643000: Avg Loss =  0.20544\n",
      "Iteration 643100: Avg Loss =  0.22766\n",
      "Iteration 643200: Avg Loss =  0.20683\n",
      "Iteration 643300: Avg Loss =  0.20772\n",
      "Iteration 643400: Avg Loss =  0.20670\n",
      "Iteration 643500: Avg Loss =  0.25401\n",
      "Iteration 643600: Avg Loss =  0.24540\n",
      "Iteration 643700: Avg Loss =  0.23660\n",
      "Iteration 643800: Avg Loss =  0.21851\n",
      "Iteration 643900: Avg Loss =  0.18716\n",
      "Iteration 644000: Avg Loss =  0.20697\n",
      "Iteration 644100: Avg Loss =  0.22088\n",
      "Iteration 644200: Avg Loss =  0.21843\n",
      "Iteration 644300: Avg Loss =  0.20508\n",
      "Iteration 644400: Avg Loss =  0.21676\n",
      "Iteration 644500: Avg Loss =  0.22132\n",
      "Iteration 644600: Avg Loss =  0.20284\n",
      "Iteration 644700: Avg Loss =  0.26565\n",
      "Iteration 644800: Avg Loss =  0.25136\n",
      "Iteration 644900: Avg Loss =  0.21652\n",
      "Iteration 645000: Avg Loss =  0.17966\n",
      "Iteration 645100: Avg Loss =  0.22078\n",
      "Iteration 645200: Avg Loss =  0.20708\n",
      "Iteration 645300: Avg Loss =  0.22563\n",
      "Iteration 645400: Avg Loss =  0.23967\n",
      "Iteration 645500: Avg Loss =  0.25700\n",
      "Iteration 645600: Avg Loss =  0.23052\n",
      "Iteration 645700: Avg Loss =  0.20419\n",
      "Iteration 645800: Avg Loss =  0.21447\n",
      "Iteration 645900: Avg Loss =  0.16693\n",
      "Iteration 646000: Avg Loss =  0.21871\n",
      "Iteration 646100: Avg Loss =  0.23699\n",
      "Iteration 646200: Avg Loss =  0.26846\n",
      "Iteration 646300: Avg Loss =  0.19165\n",
      "Iteration 646400: Avg Loss =  0.29217\n",
      "Iteration 646500: Avg Loss =  0.20644\n",
      "Iteration 646600: Avg Loss =  0.20143\n",
      "Iteration 646700: Avg Loss =  0.22625\n",
      "Iteration 646800: Avg Loss =  0.20644\n",
      "Iteration 646900: Avg Loss =  0.19648\n",
      "Iteration 647000: Avg Loss =  0.20229\n",
      "Iteration 647100: Avg Loss =  0.23926\n",
      "Iteration 647200: Avg Loss =  0.18976\n",
      "Iteration 647300: Avg Loss =  0.20073\n",
      "Iteration 647400: Avg Loss =  0.20075\n",
      "Iteration 647500: Avg Loss =  0.20586\n",
      "Iteration 647600: Avg Loss =  0.24074\n",
      "Iteration 647700: Avg Loss =  0.23577\n",
      "Iteration 647800: Avg Loss =  0.21406\n",
      "Iteration 647900: Avg Loss =  0.19604\n",
      "Iteration 648000: Avg Loss =  0.21860\n",
      "Iteration 648100: Avg Loss =  0.23014\n",
      "Iteration 648200: Avg Loss =  0.21460\n",
      "Iteration 648300: Avg Loss =  0.24093\n",
      "Iteration 648400: Avg Loss =  0.24840\n",
      "Iteration 648500: Avg Loss =  0.21558\n",
      "Iteration 648600: Avg Loss =  0.21851\n",
      "Iteration 648700: Avg Loss =  0.23914\n",
      "Iteration 648800: Avg Loss =  0.20154\n",
      "Iteration 648900: Avg Loss =  0.23314\n",
      "Iteration 649000: Avg Loss =  0.24813\n",
      "Iteration 649100: Avg Loss =  0.19445\n",
      "Iteration 649200: Avg Loss =  0.16968\n",
      "Iteration 649300: Avg Loss =  0.23233\n",
      "Iteration 649400: Avg Loss =  0.19994\n",
      "Iteration 649500: Avg Loss =  0.21970\n",
      "Iteration 649600: Avg Loss =  0.21316\n",
      "Iteration 649700: Avg Loss =  0.21802\n",
      "Iteration 649800: Avg Loss =  0.19301\n",
      "Iteration 649900: Avg Loss =  0.22628\n",
      "Iteration 650000: Avg Loss =  0.26232\n",
      "Iteration 650100: Avg Loss =  0.20051\n",
      "Iteration 650200: Avg Loss =  0.26506\n",
      "Iteration 650300: Avg Loss =  0.20361\n",
      "Iteration 650400: Avg Loss =  0.22421\n",
      "Iteration 650500: Avg Loss =  0.27675\n",
      "Iteration 650600: Avg Loss =  0.25458\n",
      "Iteration 650700: Avg Loss =  0.24004\n",
      "Iteration 650800: Avg Loss =  0.26451\n",
      "Iteration 650900: Avg Loss =  0.17631\n",
      "Iteration 651000: Avg Loss =  0.18192\n",
      "Iteration 651100: Avg Loss =  0.22732\n",
      "Iteration 651200: Avg Loss =  0.20889\n",
      "Iteration 651300: Avg Loss =  0.19303\n",
      "Iteration 651400: Avg Loss =  0.26938\n",
      "Iteration 651500: Avg Loss =  0.20713\n",
      "Iteration 651600: Avg Loss =  0.20623\n",
      "Iteration 651700: Avg Loss =  0.19974\n",
      "Iteration 651800: Avg Loss =  0.20242\n",
      "Iteration 651900: Avg Loss =  0.21482\n",
      "Iteration 652000: Avg Loss =  0.19322\n",
      "Iteration 652100: Avg Loss =  0.24740\n",
      "Iteration 652200: Avg Loss =  0.25532\n",
      "Iteration 652300: Avg Loss =  0.25408\n",
      "Iteration 652400: Avg Loss =  0.23887\n",
      "Iteration 652500: Avg Loss =  0.22919\n",
      "Iteration 652600: Avg Loss =  0.23949\n",
      "Iteration 652700: Avg Loss =  0.18616\n",
      "Iteration 652800: Avg Loss =  0.21369\n",
      "Iteration 652900: Avg Loss =  0.16723\n",
      "Iteration 653000: Avg Loss =  0.21852\n",
      "Iteration 653100: Avg Loss =  0.23039\n",
      "Iteration 653200: Avg Loss =  0.25394\n",
      "Iteration 653300: Avg Loss =  0.20059\n",
      "Iteration 653400: Avg Loss =  0.24863\n",
      "Iteration 653500: Avg Loss =  0.24396\n",
      "Iteration 653600: Avg Loss =  0.27741\n",
      "Iteration 653700: Avg Loss =  0.21562\n",
      "Iteration 653800: Avg Loss =  0.19253\n",
      "Iteration 653900: Avg Loss =  0.22963\n",
      "Iteration 654000: Avg Loss =  0.21778\n",
      "Iteration 654100: Avg Loss =  0.28042\n",
      "Iteration 654200: Avg Loss =  0.22331\n",
      "Iteration 654300: Avg Loss =  0.21551\n",
      "Iteration 654400: Avg Loss =  0.27227\n",
      "Iteration 654500: Avg Loss =  0.20783\n",
      "Iteration 654600: Avg Loss =  0.19635\n",
      "Iteration 654700: Avg Loss =  0.23812\n",
      "Iteration 654800: Avg Loss =  0.22131\n",
      "Iteration 654900: Avg Loss =  0.22403\n",
      "Iteration 655000: Avg Loss =  0.22558\n",
      "Iteration 655100: Avg Loss =  0.24178\n",
      "Iteration 655200: Avg Loss =  0.18879\n",
      "Iteration 655300: Avg Loss =  0.22432\n",
      "Iteration 655400: Avg Loss =  0.23124\n",
      "Iteration 655500: Avg Loss =  0.22688\n",
      "Iteration 655600: Avg Loss =  0.22619\n",
      "Iteration 655700: Avg Loss =  0.21319\n",
      "Iteration 655800: Avg Loss =  0.20821\n",
      "Iteration 655900: Avg Loss =  0.28375\n",
      "Iteration 656000: Avg Loss =  0.27753\n",
      "Iteration 656100: Avg Loss =  0.18423\n",
      "Iteration 656200: Avg Loss =  0.21867\n",
      "Iteration 656300: Avg Loss =  0.22470\n",
      "Iteration 656400: Avg Loss =  0.24875\n",
      "Iteration 656500: Avg Loss =  0.26451\n",
      "Iteration 656600: Avg Loss =  0.22537\n",
      "Iteration 656700: Avg Loss =  0.19596\n",
      "Iteration 656800: Avg Loss =  0.21125\n",
      "Iteration 656900: Avg Loss =  0.20315\n",
      "Iteration 657000: Avg Loss =  0.20686\n",
      "Iteration 657100: Avg Loss =  0.21276\n",
      "Iteration 657200: Avg Loss =  0.21534\n",
      "Iteration 657300: Avg Loss =  0.21749\n",
      "Iteration 657400: Avg Loss =  0.22114\n",
      "Iteration 657500: Avg Loss =  0.20863\n",
      "Iteration 657600: Avg Loss =  0.21795\n",
      "Iteration 657700: Avg Loss =  0.20863\n",
      "Iteration 657800: Avg Loss =  0.21503\n",
      "Iteration 657900: Avg Loss =  0.23525\n",
      "Iteration 658000: Avg Loss =  0.24863\n",
      "Iteration 658100: Avg Loss =  0.20977\n",
      "Iteration 658200: Avg Loss =  0.16268\n",
      "Iteration 658300: Avg Loss =  0.26343\n",
      "Iteration 658400: Avg Loss =  0.22409\n",
      "Iteration 658500: Avg Loss =  0.21579\n",
      "Iteration 658600: Avg Loss =  0.23471\n",
      "Iteration 658700: Avg Loss =  0.21386\n",
      "Iteration 658800: Avg Loss =  0.23403\n",
      "Iteration 658900: Avg Loss =  0.22545\n",
      "Iteration 659000: Avg Loss =  0.20011\n",
      "Iteration 659100: Avg Loss =  0.23241\n",
      "Iteration 659200: Avg Loss =  0.18873\n",
      "Iteration 659300: Avg Loss =  0.23268\n",
      "Iteration 659400: Avg Loss =  0.20622\n",
      "Iteration 659500: Avg Loss =  0.19976\n",
      "Iteration 659600: Avg Loss =  0.23629\n",
      "Iteration 659700: Avg Loss =  0.24599\n",
      "Iteration 659800: Avg Loss =  0.18469\n",
      "Iteration 659900: Avg Loss =  0.20675\n",
      "Iteration 660000: Avg Loss =  0.25286\n",
      "Iteration 660100: Avg Loss =  0.20603\n",
      "Iteration 660200: Avg Loss =  0.20384\n",
      "Iteration 660300: Avg Loss =  0.23723\n",
      "Iteration 660400: Avg Loss =  0.21577\n",
      "Iteration 660500: Avg Loss =  0.21363\n",
      "Iteration 660600: Avg Loss =  0.22883\n",
      "Iteration 660700: Avg Loss =  0.21127\n",
      "Iteration 660800: Avg Loss =  0.18420\n",
      "Iteration 660900: Avg Loss =  0.19881\n",
      "Iteration 661000: Avg Loss =  0.22205\n",
      "Iteration 661100: Avg Loss =  0.23048\n",
      "Iteration 661200: Avg Loss =  0.25313\n",
      "Iteration 661300: Avg Loss =  0.21565\n",
      "Iteration 661400: Avg Loss =  0.22174\n",
      "Iteration 661500: Avg Loss =  0.21000\n",
      "Iteration 661600: Avg Loss =  0.21831\n",
      "Iteration 661700: Avg Loss =  0.23149\n",
      "Iteration 661800: Avg Loss =  0.21147\n",
      "Iteration 661900: Avg Loss =  0.22465\n",
      "Iteration 662000: Avg Loss =  0.21150\n",
      "Iteration 662100: Avg Loss =  0.16749\n",
      "Iteration 662200: Avg Loss =  0.19887\n",
      "Iteration 662300: Avg Loss =  0.25514\n",
      "Iteration 662400: Avg Loss =  0.24527\n",
      "Iteration 662500: Avg Loss =  0.20884\n",
      "Iteration 662600: Avg Loss =  0.27236\n",
      "Iteration 662700: Avg Loss =  0.22210\n",
      "Iteration 662800: Avg Loss =  0.21574\n",
      "Iteration 662900: Avg Loss =  0.22832\n",
      "Iteration 663000: Avg Loss =  0.25079\n",
      "Iteration 663100: Avg Loss =  0.21548\n",
      "Iteration 663200: Avg Loss =  0.20466\n",
      "Iteration 663300: Avg Loss =  0.24031\n",
      "Iteration 663400: Avg Loss =  0.22260\n",
      "Iteration 663500: Avg Loss =  0.20176\n",
      "Iteration 663600: Avg Loss =  0.19585\n",
      "Iteration 663700: Avg Loss =  0.22508\n",
      "Iteration 663800: Avg Loss =  0.19019\n",
      "Iteration 663900: Avg Loss =  0.23917\n",
      "Iteration 664000: Avg Loss =  0.21960\n",
      "Iteration 664100: Avg Loss =  0.23201\n",
      "Iteration 664200: Avg Loss =  0.22962\n",
      "Iteration 664300: Avg Loss =  0.21040\n",
      "Iteration 664400: Avg Loss =  0.24747\n",
      "Iteration 664500: Avg Loss =  0.20971\n",
      "Iteration 664600: Avg Loss =  0.17802\n",
      "Iteration 664700: Avg Loss =  0.19334\n",
      "Iteration 664800: Avg Loss =  0.20694\n",
      "Iteration 664900: Avg Loss =  0.20139\n",
      "Iteration 665000: Avg Loss =  0.21211\n",
      "Iteration 665100: Avg Loss =  0.22574\n",
      "Iteration 665200: Avg Loss =  0.22483\n",
      "Iteration 665300: Avg Loss =  0.22916\n",
      "Iteration 665400: Avg Loss =  0.21776\n",
      "Iteration 665500: Avg Loss =  0.22780\n",
      "Iteration 665600: Avg Loss =  0.20727\n",
      "Iteration 665700: Avg Loss =  0.23312\n",
      "Iteration 665800: Avg Loss =  0.21524\n",
      "Iteration 665900: Avg Loss =  0.23101\n",
      "Iteration 666000: Avg Loss =  0.21018\n",
      "Iteration 666100: Avg Loss =  0.24881\n",
      "Iteration 666200: Avg Loss =  0.22331\n",
      "Iteration 666300: Avg Loss =  0.22360\n",
      "Iteration 666400: Avg Loss =  0.23884\n",
      "Iteration 666500: Avg Loss =  0.24093\n",
      "Iteration 666600: Avg Loss =  0.24324\n",
      "Iteration 666700: Avg Loss =  0.21424\n",
      "Iteration 666800: Avg Loss =  0.18403\n",
      "Iteration 666900: Avg Loss =  0.20987\n",
      "Iteration 667000: Avg Loss =  0.26411\n",
      "Iteration 667100: Avg Loss =  0.21830\n",
      "Iteration 667200: Avg Loss =  0.19402\n",
      "Iteration 667300: Avg Loss =  0.20639\n",
      "Iteration 667400: Avg Loss =  0.25929\n",
      "Iteration 667500: Avg Loss =  0.20668\n",
      "Iteration 667600: Avg Loss =  0.24265\n",
      "Iteration 667700: Avg Loss =  0.21272\n",
      "Iteration 667800: Avg Loss =  0.19223\n",
      "Iteration 667900: Avg Loss =  0.19202\n",
      "Iteration 668000: Avg Loss =  0.20663\n",
      "Iteration 668100: Avg Loss =  0.19321\n",
      "Iteration 668200: Avg Loss =  0.22777\n",
      "Iteration 668300: Avg Loss =  0.20549\n",
      "Iteration 668400: Avg Loss =  0.19898\n",
      "Iteration 668500: Avg Loss =  0.24387\n",
      "Iteration 668600: Avg Loss =  0.27724\n",
      "Iteration 668700: Avg Loss =  0.29419\n",
      "Iteration 668800: Avg Loss =  0.25917\n",
      "Iteration 668900: Avg Loss =  0.22480\n",
      "Iteration 669000: Avg Loss =  0.23750\n",
      "Iteration 669100: Avg Loss =  0.21138\n",
      "Iteration 669200: Avg Loss =  0.21160\n",
      "Iteration 669300: Avg Loss =  0.17409\n",
      "Iteration 669400: Avg Loss =  0.20991\n",
      "Iteration 669500: Avg Loss =  0.21208\n",
      "Iteration 669600: Avg Loss =  0.19600\n",
      "Iteration 669700: Avg Loss =  0.20840\n",
      "Iteration 669800: Avg Loss =  0.25029\n",
      "Iteration 669900: Avg Loss =  0.20028\n",
      "Iteration 670000: Avg Loss =  0.17183\n",
      "Iteration 670100: Avg Loss =  0.24947\n",
      "Iteration 670200: Avg Loss =  0.29460\n",
      "Iteration 670300: Avg Loss =  0.18401\n",
      "Iteration 670400: Avg Loss =  0.26527\n",
      "Iteration 670500: Avg Loss =  0.18333\n",
      "Iteration 670600: Avg Loss =  0.20149\n",
      "Iteration 670700: Avg Loss =  0.20050\n",
      "Iteration 670800: Avg Loss =  0.21544\n",
      "Iteration 670900: Avg Loss =  0.23384\n",
      "Iteration 671000: Avg Loss =  0.18743\n",
      "Iteration 671100: Avg Loss =  0.21563\n",
      "Iteration 671200: Avg Loss =  0.21449\n",
      "Iteration 671300: Avg Loss =  0.22006\n",
      "Iteration 671400: Avg Loss =  0.22492\n",
      "Iteration 671500: Avg Loss =  0.19606\n",
      "Iteration 671600: Avg Loss =  0.21071\n",
      "Iteration 671700: Avg Loss =  0.21941\n",
      "Iteration 671800: Avg Loss =  0.21443\n",
      "Iteration 671900: Avg Loss =  0.22791\n",
      "Iteration 672000: Avg Loss =  0.20409\n",
      "Iteration 672100: Avg Loss =  0.22667\n",
      "Iteration 672200: Avg Loss =  0.21128\n",
      "Iteration 672300: Avg Loss =  0.23092\n",
      "Iteration 672400: Avg Loss =  0.26279\n",
      "Iteration 672500: Avg Loss =  0.19266\n",
      "Iteration 672600: Avg Loss =  0.22875\n",
      "Iteration 672700: Avg Loss =  0.19739\n",
      "Iteration 672800: Avg Loss =  0.22826\n",
      "Iteration 672900: Avg Loss =  0.19878\n",
      "Iteration 673000: Avg Loss =  0.20530\n",
      "Iteration 673100: Avg Loss =  0.18277\n",
      "Iteration 673200: Avg Loss =  0.19735\n",
      "Iteration 673300: Avg Loss =  0.22068\n",
      "Iteration 673400: Avg Loss =  0.28672\n",
      "Iteration 673500: Avg Loss =  0.19050\n",
      "Iteration 673600: Avg Loss =  0.19150\n",
      "Iteration 673700: Avg Loss =  0.22165\n",
      "Iteration 673800: Avg Loss =  0.18829\n",
      "Iteration 673900: Avg Loss =  0.23018\n",
      "Iteration 674000: Avg Loss =  0.24160\n",
      "Iteration 674100: Avg Loss =  0.22447\n",
      "Iteration 674200: Avg Loss =  0.20875\n",
      "Iteration 674300: Avg Loss =  0.22432\n",
      "Iteration 674400: Avg Loss =  0.22387\n",
      "Iteration 674500: Avg Loss =  0.18547\n",
      "Iteration 674600: Avg Loss =  0.21899\n",
      "Iteration 674700: Avg Loss =  0.18735\n",
      "Iteration 674800: Avg Loss =  0.24031\n",
      "Iteration 674900: Avg Loss =  0.23064\n",
      "Iteration 675000: Avg Loss =  0.26124\n",
      "Iteration 675100: Avg Loss =  0.22976\n",
      "Iteration 675200: Avg Loss =  0.17470\n",
      "Iteration 675300: Avg Loss =  0.20129\n",
      "Iteration 675400: Avg Loss =  0.21275\n",
      "Iteration 675500: Avg Loss =  0.21265\n",
      "Iteration 675600: Avg Loss =  0.24542\n",
      "Iteration 675700: Avg Loss =  0.23112\n",
      "Iteration 675800: Avg Loss =  0.20735\n",
      "Iteration 675900: Avg Loss =  0.24800\n",
      "Iteration 676000: Avg Loss =  0.19335\n",
      "Iteration 676100: Avg Loss =  0.22970\n",
      "Iteration 676200: Avg Loss =  0.21399\n",
      "Iteration 676300: Avg Loss =  0.22480\n",
      "Iteration 676400: Avg Loss =  0.17628\n",
      "Iteration 676500: Avg Loss =  0.19623\n",
      "Iteration 676600: Avg Loss =  0.18955\n",
      "Iteration 676700: Avg Loss =  0.19358\n",
      "Iteration 676800: Avg Loss =  0.22358\n",
      "Iteration 676900: Avg Loss =  0.22576\n",
      "Iteration 677000: Avg Loss =  0.20624\n",
      "Iteration 677100: Avg Loss =  0.20826\n",
      "Iteration 677200: Avg Loss =  0.25815\n",
      "Iteration 677300: Avg Loss =  0.25793\n",
      "Iteration 677400: Avg Loss =  0.23563\n",
      "Iteration 677500: Avg Loss =  0.22627\n",
      "Iteration 677600: Avg Loss =  0.24899\n",
      "Iteration 677700: Avg Loss =  0.20499\n",
      "Iteration 677800: Avg Loss =  0.20839\n",
      "Iteration 677900: Avg Loss =  0.19194\n",
      "Iteration 678000: Avg Loss =  0.21189\n",
      "Iteration 678100: Avg Loss =  0.22144\n",
      "Iteration 678200: Avg Loss =  0.21099\n",
      "Iteration 678300: Avg Loss =  0.21725\n",
      "Iteration 678400: Avg Loss =  0.21262\n",
      "Iteration 678500: Avg Loss =  0.26060\n",
      "Iteration 678600: Avg Loss =  0.23625\n",
      "Iteration 678700: Avg Loss =  0.22610\n",
      "Iteration 678800: Avg Loss =  0.18374\n",
      "Iteration 678900: Avg Loss =  0.19236\n",
      "Iteration 679000: Avg Loss =  0.22938\n",
      "Iteration 679100: Avg Loss =  0.22497\n",
      "Iteration 679200: Avg Loss =  0.22951\n",
      "Iteration 679300: Avg Loss =  0.22821\n",
      "Iteration 679400: Avg Loss =  0.22776\n",
      "Iteration 679500: Avg Loss =  0.19430\n",
      "Iteration 679600: Avg Loss =  0.21610\n",
      "Iteration 679700: Avg Loss =  0.23661\n",
      "Iteration 679800: Avg Loss =  0.22015\n",
      "Iteration 679900: Avg Loss =  0.19937\n",
      "Iteration 680000: Avg Loss =  0.23039\n",
      "Iteration 680100: Avg Loss =  0.23796\n",
      "Iteration 680200: Avg Loss =  0.25022\n",
      "Iteration 680300: Avg Loss =  0.19961\n",
      "Iteration 680400: Avg Loss =  0.20500\n",
      "Iteration 680500: Avg Loss =  0.25794\n",
      "Iteration 680600: Avg Loss =  0.22851\n",
      "Iteration 680700: Avg Loss =  0.19446\n",
      "Iteration 680800: Avg Loss =  0.23347\n",
      "Iteration 680900: Avg Loss =  0.20417\n",
      "Iteration 681000: Avg Loss =  0.19855\n",
      "Iteration 681100: Avg Loss =  0.21591\n",
      "Iteration 681200: Avg Loss =  0.23909\n",
      "Iteration 681300: Avg Loss =  0.25726\n",
      "Iteration 681400: Avg Loss =  0.19738\n",
      "Iteration 681500: Avg Loss =  0.22274\n",
      "Iteration 681600: Avg Loss =  0.20581\n",
      "Iteration 681700: Avg Loss =  0.23032\n",
      "Iteration 681800: Avg Loss =  0.21815\n",
      "Iteration 681900: Avg Loss =  0.19614\n",
      "Iteration 682000: Avg Loss =  0.26023\n",
      "Iteration 682100: Avg Loss =  0.20233\n",
      "Iteration 682200: Avg Loss =  0.21898\n",
      "Iteration 682300: Avg Loss =  0.17411\n",
      "Iteration 682400: Avg Loss =  0.18213\n",
      "Iteration 682500: Avg Loss =  0.24614\n",
      "Iteration 682600: Avg Loss =  0.19642\n",
      "Iteration 682700: Avg Loss =  0.23023\n",
      "Iteration 682800: Avg Loss =  0.19725\n",
      "Iteration 682900: Avg Loss =  0.23569\n",
      "Iteration 683000: Avg Loss =  0.20229\n",
      "Iteration 683100: Avg Loss =  0.22399\n",
      "Iteration 683200: Avg Loss =  0.25182\n",
      "Iteration 683300: Avg Loss =  0.20377\n",
      "Iteration 683400: Avg Loss =  0.25516\n",
      "Iteration 683500: Avg Loss =  0.21065\n",
      "Iteration 683600: Avg Loss =  0.23119\n",
      "Iteration 683700: Avg Loss =  0.20722\n",
      "Iteration 683800: Avg Loss =  0.20412\n",
      "Iteration 683900: Avg Loss =  0.21103\n",
      "Iteration 684000: Avg Loss =  0.18201\n",
      "Iteration 684100: Avg Loss =  0.20992\n",
      "Iteration 684200: Avg Loss =  0.23820\n",
      "Iteration 684300: Avg Loss =  0.25462\n",
      "Iteration 684400: Avg Loss =  0.21742\n",
      "Iteration 684500: Avg Loss =  0.24342\n",
      "Iteration 684600: Avg Loss =  0.22002\n",
      "Iteration 684700: Avg Loss =  0.26117\n",
      "Iteration 684800: Avg Loss =  0.23185\n",
      "Iteration 684900: Avg Loss =  0.22326\n",
      "Iteration 685000: Avg Loss =  0.19287\n",
      "Iteration 685100: Avg Loss =  0.22547\n",
      "Iteration 685200: Avg Loss =  0.16349\n",
      "Iteration 685300: Avg Loss =  0.21430\n",
      "Iteration 685400: Avg Loss =  0.23535\n",
      "Iteration 685500: Avg Loss =  0.24485\n",
      "Iteration 685600: Avg Loss =  0.23415\n",
      "Iteration 685700: Avg Loss =  0.21004\n",
      "Iteration 685800: Avg Loss =  0.21473\n",
      "Iteration 685900: Avg Loss =  0.24235\n",
      "Iteration 686000: Avg Loss =  0.19974\n",
      "Iteration 686100: Avg Loss =  0.21264\n",
      "Iteration 686200: Avg Loss =  0.21136\n",
      "Iteration 686300: Avg Loss =  0.18682\n",
      "Iteration 686400: Avg Loss =  0.23573\n",
      "Iteration 686500: Avg Loss =  0.19453\n",
      "Iteration 686600: Avg Loss =  0.21651\n",
      "Iteration 686700: Avg Loss =  0.19140\n",
      "Iteration 686800: Avg Loss =  0.22601\n",
      "Iteration 686900: Avg Loss =  0.22624\n",
      "Iteration 687000: Avg Loss =  0.22298\n",
      "Iteration 687100: Avg Loss =  0.22844\n",
      "Iteration 687200: Avg Loss =  0.21084\n",
      "Iteration 687300: Avg Loss =  0.19911\n",
      "Iteration 687400: Avg Loss =  0.21751\n",
      "Iteration 687500: Avg Loss =  0.19729\n",
      "Iteration 687600: Avg Loss =  0.21341\n",
      "Iteration 687700: Avg Loss =  0.19405\n",
      "Iteration 687800: Avg Loss =  0.23109\n",
      "Iteration 687900: Avg Loss =  0.22820\n",
      "Iteration 688000: Avg Loss =  0.23153\n",
      "Iteration 688100: Avg Loss =  0.24076\n",
      "Iteration 688200: Avg Loss =  0.21717\n",
      "Iteration 688300: Avg Loss =  0.19023\n",
      "Iteration 688400: Avg Loss =  0.25206\n",
      "Iteration 688500: Avg Loss =  0.18607\n",
      "Iteration 688600: Avg Loss =  0.18661\n",
      "Iteration 688700: Avg Loss =  0.24523\n",
      "Iteration 688800: Avg Loss =  0.20960\n",
      "Iteration 688900: Avg Loss =  0.18817\n",
      "Iteration 689000: Avg Loss =  0.29259\n",
      "Iteration 689100: Avg Loss =  0.19778\n",
      "Iteration 689200: Avg Loss =  0.23773\n",
      "Iteration 689300: Avg Loss =  0.20484\n",
      "Iteration 689400: Avg Loss =  0.18437\n",
      "Iteration 689500: Avg Loss =  0.20288\n",
      "Iteration 689600: Avg Loss =  0.20837\n",
      "Iteration 689700: Avg Loss =  0.21245\n",
      "Iteration 689800: Avg Loss =  0.24225\n",
      "Iteration 689900: Avg Loss =  0.19345\n",
      "Iteration 690000: Avg Loss =  0.22315\n",
      "Iteration 690100: Avg Loss =  0.22697\n",
      "Iteration 690200: Avg Loss =  0.23127\n",
      "Iteration 690300: Avg Loss =  0.21810\n",
      "Iteration 690400: Avg Loss =  0.23513\n",
      "Iteration 690500: Avg Loss =  0.25136\n",
      "Iteration 690600: Avg Loss =  0.28192\n",
      "Iteration 690700: Avg Loss =  0.21414\n",
      "Iteration 690800: Avg Loss =  0.26066\n",
      "Iteration 690900: Avg Loss =  0.23069\n",
      "Iteration 691000: Avg Loss =  0.25918\n",
      "Iteration 691100: Avg Loss =  0.19381\n",
      "Iteration 691200: Avg Loss =  0.20279\n",
      "Iteration 691300: Avg Loss =  0.19662\n",
      "Iteration 691400: Avg Loss =  0.23730\n",
      "Iteration 691500: Avg Loss =  0.20039\n",
      "Iteration 691600: Avg Loss =  0.21123\n",
      "Iteration 691700: Avg Loss =  0.21801\n",
      "Iteration 691800: Avg Loss =  0.20650\n",
      "Iteration 691900: Avg Loss =  0.24626\n",
      "Iteration 692000: Avg Loss =  0.22095\n",
      "Iteration 692100: Avg Loss =  0.20231\n",
      "Iteration 692200: Avg Loss =  0.24992\n",
      "Iteration 692300: Avg Loss =  0.20095\n",
      "Iteration 692400: Avg Loss =  0.22086\n",
      "Iteration 692500: Avg Loss =  0.17114\n",
      "Iteration 692600: Avg Loss =  0.25005\n",
      "Iteration 692700: Avg Loss =  0.21177\n",
      "Iteration 692800: Avg Loss =  0.19380\n",
      "Iteration 692900: Avg Loss =  0.21364\n",
      "Iteration 693000: Avg Loss =  0.19031\n",
      "Iteration 693100: Avg Loss =  0.26262\n",
      "Iteration 693200: Avg Loss =  0.24352\n",
      "Iteration 693300: Avg Loss =  0.24074\n",
      "Iteration 693400: Avg Loss =  0.19386\n",
      "Iteration 693500: Avg Loss =  0.19144\n",
      "Iteration 693600: Avg Loss =  0.18274\n",
      "Iteration 693700: Avg Loss =  0.18074\n",
      "Iteration 693800: Avg Loss =  0.22973\n",
      "Iteration 693900: Avg Loss =  0.20394\n",
      "Iteration 694000: Avg Loss =  0.23672\n",
      "Iteration 694100: Avg Loss =  0.23415\n",
      "Iteration 694200: Avg Loss =  0.18899\n",
      "Iteration 694300: Avg Loss =  0.19217\n",
      "Iteration 694400: Avg Loss =  0.20763\n",
      "Iteration 694500: Avg Loss =  0.18373\n",
      "Iteration 694600: Avg Loss =  0.22512\n",
      "Iteration 694700: Avg Loss =  0.20993\n",
      "Iteration 694800: Avg Loss =  0.23315\n",
      "Iteration 694900: Avg Loss =  0.19859\n",
      "Iteration 695000: Avg Loss =  0.19703\n",
      "Iteration 695100: Avg Loss =  0.19307\n",
      "Iteration 695200: Avg Loss =  0.22880\n",
      "Iteration 695300: Avg Loss =  0.19237\n",
      "Iteration 695400: Avg Loss =  0.24313\n",
      "Iteration 695500: Avg Loss =  0.17872\n",
      "Iteration 695600: Avg Loss =  0.23732\n",
      "Iteration 695700: Avg Loss =  0.26693\n",
      "Iteration 695800: Avg Loss =  0.21937\n",
      "Iteration 695900: Avg Loss =  0.22725\n",
      "Iteration 696000: Avg Loss =  0.24588\n",
      "Iteration 696100: Avg Loss =  0.25068\n",
      "Iteration 696200: Avg Loss =  0.24632\n",
      "Iteration 696300: Avg Loss =  0.22120\n",
      "Iteration 696400: Avg Loss =  0.25025\n",
      "Iteration 696500: Avg Loss =  0.21746\n",
      "Iteration 696600: Avg Loss =  0.19474\n",
      "Iteration 696700: Avg Loss =  0.22428\n",
      "Iteration 696800: Avg Loss =  0.20175\n",
      "Iteration 696900: Avg Loss =  0.23451\n",
      "Iteration 697000: Avg Loss =  0.26519\n",
      "Iteration 697100: Avg Loss =  0.24353\n",
      "Iteration 697200: Avg Loss =  0.20068\n",
      "Iteration 697300: Avg Loss =  0.19954\n",
      "Iteration 697400: Avg Loss =  0.19992\n",
      "Iteration 697500: Avg Loss =  0.16704\n",
      "Iteration 697600: Avg Loss =  0.21334\n",
      "Iteration 697700: Avg Loss =  0.18378\n",
      "Iteration 697800: Avg Loss =  0.23118\n",
      "Iteration 697900: Avg Loss =  0.23225\n",
      "Iteration 698000: Avg Loss =  0.18533\n",
      "Iteration 698100: Avg Loss =  0.23319\n",
      "Iteration 698200: Avg Loss =  0.27981\n",
      "Iteration 698300: Avg Loss =  0.18816\n",
      "Iteration 698400: Avg Loss =  0.19819\n",
      "Iteration 698500: Avg Loss =  0.21883\n",
      "Iteration 698600: Avg Loss =  0.23064\n",
      "Iteration 698700: Avg Loss =  0.19153\n",
      "Iteration 698800: Avg Loss =  0.24083\n",
      "Iteration 698900: Avg Loss =  0.23727\n",
      "Iteration 699000: Avg Loss =  0.22121\n",
      "Iteration 699100: Avg Loss =  0.17997\n",
      "Iteration 699200: Avg Loss =  0.21740\n",
      "Iteration 699300: Avg Loss =  0.23958\n",
      "Iteration 699400: Avg Loss =  0.25162\n",
      "Iteration 699500: Avg Loss =  0.23476\n",
      "Iteration 699600: Avg Loss =  0.22487\n",
      "Iteration 699700: Avg Loss =  0.22912\n",
      "Iteration 699800: Avg Loss =  0.19552\n",
      "Iteration 699900: Avg Loss =  0.19163\n",
      "Iteration 700000: Avg Loss =  0.23496\n",
      "Iteration 700100: Avg Loss =  0.19991\n",
      "Iteration 700200: Avg Loss =  0.23356\n",
      "Iteration 700300: Avg Loss =  0.20952\n",
      "Iteration 700400: Avg Loss =  0.21210\n",
      "Iteration 700500: Avg Loss =  0.22547\n",
      "Iteration 700600: Avg Loss =  0.17867\n",
      "Iteration 700700: Avg Loss =  0.20497\n",
      "Iteration 700800: Avg Loss =  0.19962\n",
      "Iteration 700900: Avg Loss =  0.27955\n",
      "Iteration 701000: Avg Loss =  0.21170\n",
      "Iteration 701100: Avg Loss =  0.17271\n",
      "Iteration 701200: Avg Loss =  0.21235\n",
      "Iteration 701300: Avg Loss =  0.21158\n",
      "Iteration 701400: Avg Loss =  0.17833\n",
      "Iteration 701500: Avg Loss =  0.24007\n",
      "Iteration 701600: Avg Loss =  0.21314\n",
      "Iteration 701700: Avg Loss =  0.23823\n",
      "Iteration 701800: Avg Loss =  0.22838\n",
      "Iteration 701900: Avg Loss =  0.23539\n",
      "Iteration 702000: Avg Loss =  0.23453\n",
      "Iteration 702100: Avg Loss =  0.20118\n",
      "Iteration 702200: Avg Loss =  0.24100\n",
      "Iteration 702300: Avg Loss =  0.19314\n",
      "Iteration 702400: Avg Loss =  0.19328\n",
      "Iteration 702500: Avg Loss =  0.17975\n",
      "Iteration 702600: Avg Loss =  0.23436\n",
      "Iteration 702700: Avg Loss =  0.20856\n",
      "Iteration 702800: Avg Loss =  0.20301\n",
      "Iteration 702900: Avg Loss =  0.19854\n",
      "Iteration 703000: Avg Loss =  0.23429\n",
      "Iteration 703100: Avg Loss =  0.20554\n",
      "Iteration 703200: Avg Loss =  0.23335\n",
      "Iteration 703300: Avg Loss =  0.19065\n",
      "Iteration 703400: Avg Loss =  0.22496\n",
      "Iteration 703500: Avg Loss =  0.22463\n",
      "Iteration 703600: Avg Loss =  0.20113\n",
      "Iteration 703700: Avg Loss =  0.21699\n",
      "Iteration 703800: Avg Loss =  0.18393\n",
      "Iteration 703900: Avg Loss =  0.23008\n",
      "Iteration 704000: Avg Loss =  0.27937\n",
      "Iteration 704100: Avg Loss =  0.20090\n",
      "Iteration 704200: Avg Loss =  0.19593\n",
      "Iteration 704300: Avg Loss =  0.24767\n",
      "Iteration 704400: Avg Loss =  0.21470\n",
      "Iteration 704500: Avg Loss =  0.19506\n",
      "Iteration 704600: Avg Loss =  0.22167\n",
      "Iteration 704700: Avg Loss =  0.20478\n",
      "Iteration 704800: Avg Loss =  0.17640\n",
      "Iteration 704900: Avg Loss =  0.16068\n",
      "Iteration 705000: Avg Loss =  0.21966\n",
      "Iteration 705100: Avg Loss =  0.23677\n",
      "Iteration 705200: Avg Loss =  0.20732\n",
      "Iteration 705300: Avg Loss =  0.17257\n",
      "Iteration 705400: Avg Loss =  0.21298\n",
      "Iteration 705500: Avg Loss =  0.20991\n",
      "Iteration 705600: Avg Loss =  0.25010\n",
      "Iteration 705700: Avg Loss =  0.24025\n",
      "Iteration 705800: Avg Loss =  0.21339\n",
      "Iteration 705900: Avg Loss =  0.16673\n",
      "Iteration 706000: Avg Loss =  0.23096\n",
      "Iteration 706100: Avg Loss =  0.18729\n",
      "Iteration 706200: Avg Loss =  0.22468\n",
      "Iteration 706300: Avg Loss =  0.23529\n",
      "Iteration 706400: Avg Loss =  0.17579\n",
      "Iteration 706500: Avg Loss =  0.20399\n",
      "Iteration 706600: Avg Loss =  0.21818\n",
      "Iteration 706700: Avg Loss =  0.19090\n",
      "Iteration 706800: Avg Loss =  0.24742\n",
      "Iteration 706900: Avg Loss =  0.21077\n",
      "Iteration 707000: Avg Loss =  0.25372\n",
      "Iteration 707100: Avg Loss =  0.26254\n",
      "Iteration 707200: Avg Loss =  0.24440\n",
      "Iteration 707300: Avg Loss =  0.22645\n",
      "Iteration 707400: Avg Loss =  0.23618\n",
      "Iteration 707500: Avg Loss =  0.20932\n",
      "Iteration 707600: Avg Loss =  0.18792\n",
      "Iteration 707700: Avg Loss =  0.21599\n",
      "Iteration 707800: Avg Loss =  0.26119\n",
      "Iteration 707900: Avg Loss =  0.20535\n",
      "Iteration 708000: Avg Loss =  0.23897\n",
      "Iteration 708100: Avg Loss =  0.18812\n",
      "Iteration 708200: Avg Loss =  0.18903\n",
      "Iteration 708300: Avg Loss =  0.20559\n",
      "Iteration 708400: Avg Loss =  0.20755\n",
      "Iteration 708500: Avg Loss =  0.25204\n",
      "Iteration 708600: Avg Loss =  0.21822\n",
      "Iteration 708700: Avg Loss =  0.21522\n",
      "Iteration 708800: Avg Loss =  0.24495\n",
      "Iteration 708900: Avg Loss =  0.22542\n",
      "Iteration 709000: Avg Loss =  0.23348\n",
      "Iteration 709100: Avg Loss =  0.21403\n",
      "Iteration 709200: Avg Loss =  0.18844\n",
      "Iteration 709300: Avg Loss =  0.20679\n",
      "Iteration 709400: Avg Loss =  0.18440\n",
      "Iteration 709500: Avg Loss =  0.21304\n",
      "Iteration 709600: Avg Loss =  0.21011\n",
      "Iteration 709700: Avg Loss =  0.19714\n",
      "Iteration 709800: Avg Loss =  0.20204\n",
      "Iteration 709900: Avg Loss =  0.20897\n",
      "Iteration 710000: Avg Loss =  0.21400\n",
      "Iteration 710100: Avg Loss =  0.23757\n",
      "Iteration 710200: Avg Loss =  0.24440\n",
      "Iteration 710300: Avg Loss =  0.20898\n",
      "Iteration 710400: Avg Loss =  0.19358\n",
      "Iteration 710500: Avg Loss =  0.21086\n",
      "Iteration 710600: Avg Loss =  0.18115\n",
      "Iteration 710700: Avg Loss =  0.21817\n",
      "Iteration 710800: Avg Loss =  0.20588\n",
      "Iteration 710900: Avg Loss =  0.20670\n",
      "Iteration 711000: Avg Loss =  0.26045\n",
      "Iteration 711100: Avg Loss =  0.19009\n",
      "Iteration 711200: Avg Loss =  0.21721\n",
      "Iteration 711300: Avg Loss =  0.18373\n",
      "Iteration 711400: Avg Loss =  0.20695\n",
      "Iteration 711500: Avg Loss =  0.19806\n",
      "Iteration 711600: Avg Loss =  0.19314\n",
      "Iteration 711700: Avg Loss =  0.24301\n",
      "Iteration 711800: Avg Loss =  0.18517\n",
      "Iteration 711900: Avg Loss =  0.25300\n",
      "Iteration 712000: Avg Loss =  0.21213\n",
      "Iteration 712100: Avg Loss =  0.21515\n",
      "Iteration 712200: Avg Loss =  0.22906\n",
      "Iteration 712300: Avg Loss =  0.25080\n",
      "Iteration 712400: Avg Loss =  0.19568\n",
      "Iteration 712500: Avg Loss =  0.26074\n",
      "Iteration 712600: Avg Loss =  0.18824\n",
      "Iteration 712700: Avg Loss =  0.21180\n",
      "Iteration 712800: Avg Loss =  0.25788\n",
      "Iteration 712900: Avg Loss =  0.26183\n",
      "Iteration 713000: Avg Loss =  0.22169\n",
      "Iteration 713100: Avg Loss =  0.21987\n",
      "Iteration 713200: Avg Loss =  0.19994\n",
      "Iteration 713300: Avg Loss =  0.23075\n",
      "Iteration 713400: Avg Loss =  0.22810\n",
      "Iteration 713500: Avg Loss =  0.22700\n",
      "Iteration 713600: Avg Loss =  0.23616\n",
      "Iteration 713700: Avg Loss =  0.24792\n",
      "Iteration 713800: Avg Loss =  0.24869\n",
      "Iteration 713900: Avg Loss =  0.17072\n",
      "Iteration 714000: Avg Loss =  0.16871\n",
      "Iteration 714100: Avg Loss =  0.19750\n",
      "Iteration 714200: Avg Loss =  0.16696\n",
      "Iteration 714300: Avg Loss =  0.21387\n",
      "Iteration 714400: Avg Loss =  0.22952\n",
      "Iteration 714500: Avg Loss =  0.22901\n",
      "Iteration 714600: Avg Loss =  0.21484\n",
      "Iteration 714700: Avg Loss =  0.17492\n",
      "Iteration 714800: Avg Loss =  0.23503\n",
      "Iteration 714900: Avg Loss =  0.16468\n",
      "Iteration 715000: Avg Loss =  0.17677\n",
      "Iteration 715100: Avg Loss =  0.17522\n",
      "Iteration 715200: Avg Loss =  0.22655\n",
      "Iteration 715300: Avg Loss =  0.24984\n",
      "Iteration 715400: Avg Loss =  0.23820\n",
      "Iteration 715500: Avg Loss =  0.19681\n",
      "Iteration 715600: Avg Loss =  0.21055\n",
      "Iteration 715700: Avg Loss =  0.22253\n",
      "Iteration 715800: Avg Loss =  0.26441\n",
      "Iteration 715900: Avg Loss =  0.24841\n",
      "Iteration 716000: Avg Loss =  0.22426\n",
      "Iteration 716100: Avg Loss =  0.22212\n",
      "Iteration 716200: Avg Loss =  0.18468\n",
      "Iteration 716300: Avg Loss =  0.21739\n",
      "Iteration 716400: Avg Loss =  0.21255\n",
      "Iteration 716500: Avg Loss =  0.21722\n",
      "Iteration 716600: Avg Loss =  0.21913\n",
      "Iteration 716700: Avg Loss =  0.19780\n",
      "Iteration 716800: Avg Loss =  0.23641\n",
      "Iteration 716900: Avg Loss =  0.19575\n",
      "Iteration 717000: Avg Loss =  0.20456\n",
      "Iteration 717100: Avg Loss =  0.17899\n",
      "Iteration 717200: Avg Loss =  0.20586\n",
      "Iteration 717300: Avg Loss =  0.21165\n",
      "Iteration 717400: Avg Loss =  0.20307\n",
      "Iteration 717500: Avg Loss =  0.20892\n",
      "Iteration 717600: Avg Loss =  0.24221\n",
      "Iteration 717700: Avg Loss =  0.21411\n",
      "Iteration 717800: Avg Loss =  0.20020\n",
      "Iteration 717900: Avg Loss =  0.19074\n",
      "Iteration 718000: Avg Loss =  0.18885\n",
      "Iteration 718100: Avg Loss =  0.19245\n",
      "Iteration 718200: Avg Loss =  0.23199\n",
      "Iteration 718300: Avg Loss =  0.18952\n",
      "Iteration 718400: Avg Loss =  0.18533\n",
      "Iteration 718500: Avg Loss =  0.20587\n",
      "Iteration 718600: Avg Loss =  0.21970\n",
      "Iteration 718700: Avg Loss =  0.25797\n",
      "Iteration 718800: Avg Loss =  0.22987\n",
      "Iteration 718900: Avg Loss =  0.22110\n",
      "Iteration 719000: Avg Loss =  0.18924\n",
      "Iteration 719100: Avg Loss =  0.20908\n",
      "Iteration 719200: Avg Loss =  0.20280\n",
      "Iteration 719300: Avg Loss =  0.18940\n",
      "Iteration 719400: Avg Loss =  0.21101\n",
      "Iteration 719500: Avg Loss =  0.20462\n",
      "Iteration 719600: Avg Loss =  0.19880\n",
      "Iteration 719700: Avg Loss =  0.20666\n",
      "Iteration 719800: Avg Loss =  0.19074\n",
      "Iteration 719900: Avg Loss =  0.21519\n",
      "Iteration 720000: Avg Loss =  0.17868\n",
      "Iteration 720100: Avg Loss =  0.22699\n",
      "Iteration 720200: Avg Loss =  0.25246\n",
      "Iteration 720300: Avg Loss =  0.18668\n",
      "Iteration 720400: Avg Loss =  0.24601\n",
      "Iteration 720500: Avg Loss =  0.23250\n",
      "Iteration 720600: Avg Loss =  0.20908\n",
      "Iteration 720700: Avg Loss =  0.19058\n",
      "Iteration 720800: Avg Loss =  0.19257\n",
      "Iteration 720900: Avg Loss =  0.24264\n",
      "Iteration 721000: Avg Loss =  0.21768\n",
      "Iteration 721100: Avg Loss =  0.22547\n",
      "Iteration 721200: Avg Loss =  0.19765\n",
      "Iteration 721300: Avg Loss =  0.17635\n",
      "Iteration 721400: Avg Loss =  0.22165\n",
      "Iteration 721500: Avg Loss =  0.22491\n",
      "Iteration 721600: Avg Loss =  0.23481\n",
      "Iteration 721700: Avg Loss =  0.22890\n",
      "Iteration 721800: Avg Loss =  0.28099\n",
      "Iteration 721900: Avg Loss =  0.20581\n",
      "Iteration 722000: Avg Loss =  0.22827\n",
      "Iteration 722100: Avg Loss =  0.22692\n",
      "Iteration 722200: Avg Loss =  0.19238\n",
      "Iteration 722300: Avg Loss =  0.17519\n",
      "Iteration 722400: Avg Loss =  0.21312\n",
      "Iteration 722500: Avg Loss =  0.21929\n",
      "Iteration 722600: Avg Loss =  0.20868\n",
      "Iteration 722700: Avg Loss =  0.20413\n",
      "Iteration 722800: Avg Loss =  0.18915\n",
      "Iteration 722900: Avg Loss =  0.23685\n",
      "Iteration 723000: Avg Loss =  0.21484\n",
      "Iteration 723100: Avg Loss =  0.20939\n",
      "Iteration 723200: Avg Loss =  0.20025\n",
      "Iteration 723300: Avg Loss =  0.22769\n",
      "Iteration 723400: Avg Loss =  0.19234\n",
      "Iteration 723500: Avg Loss =  0.19436\n",
      "Iteration 723600: Avg Loss =  0.19634\n",
      "Iteration 723700: Avg Loss =  0.21428\n",
      "Iteration 723800: Avg Loss =  0.16786\n",
      "Iteration 723900: Avg Loss =  0.17423\n",
      "Iteration 724000: Avg Loss =  0.22150\n",
      "Iteration 724100: Avg Loss =  0.27517\n",
      "Iteration 724200: Avg Loss =  0.26290\n",
      "Iteration 724300: Avg Loss =  0.26034\n",
      "Iteration 724400: Avg Loss =  0.22414\n",
      "Iteration 724500: Avg Loss =  0.23307\n",
      "Iteration 724600: Avg Loss =  0.20108\n",
      "Iteration 724700: Avg Loss =  0.23282\n",
      "Iteration 724800: Avg Loss =  0.22000\n",
      "Iteration 724900: Avg Loss =  0.20401\n",
      "Iteration 725000: Avg Loss =  0.20294\n",
      "Iteration 725100: Avg Loss =  0.20510\n",
      "Iteration 725200: Avg Loss =  0.25236\n",
      "Iteration 725300: Avg Loss =  0.19876\n",
      "Iteration 725400: Avg Loss =  0.23278\n",
      "Iteration 725500: Avg Loss =  0.24439\n",
      "Iteration 725600: Avg Loss =  0.22148\n",
      "Iteration 725700: Avg Loss =  0.21735\n",
      "Iteration 725800: Avg Loss =  0.19174\n",
      "Iteration 725900: Avg Loss =  0.20776\n",
      "Iteration 726000: Avg Loss =  0.21151\n",
      "Iteration 726100: Avg Loss =  0.29232\n",
      "Iteration 726200: Avg Loss =  0.22465\n",
      "Iteration 726300: Avg Loss =  0.19745\n",
      "Iteration 726400: Avg Loss =  0.21401\n",
      "Iteration 726500: Avg Loss =  0.18076\n",
      "Iteration 726600: Avg Loss =  0.21065\n",
      "Iteration 726700: Avg Loss =  0.20872\n",
      "Iteration 726800: Avg Loss =  0.25550\n",
      "Iteration 726900: Avg Loss =  0.20978\n",
      "Iteration 727000: Avg Loss =  0.22002\n",
      "Iteration 727100: Avg Loss =  0.21802\n",
      "Iteration 727200: Avg Loss =  0.21605\n",
      "Iteration 727300: Avg Loss =  0.25214\n",
      "Iteration 727400: Avg Loss =  0.21338\n",
      "Iteration 727500: Avg Loss =  0.25141\n",
      "Iteration 727600: Avg Loss =  0.19773\n",
      "Iteration 727700: Avg Loss =  0.17870\n",
      "Iteration 727800: Avg Loss =  0.20343\n",
      "Iteration 727900: Avg Loss =  0.24086\n",
      "Iteration 728000: Avg Loss =  0.19830\n",
      "Iteration 728100: Avg Loss =  0.17140\n",
      "Iteration 728200: Avg Loss =  0.19339\n",
      "Iteration 728300: Avg Loss =  0.19501\n",
      "Iteration 728400: Avg Loss =  0.27989\n",
      "Iteration 728500: Avg Loss =  0.21502\n",
      "Iteration 728600: Avg Loss =  0.19969\n",
      "Iteration 728700: Avg Loss =  0.17450\n",
      "Iteration 728800: Avg Loss =  0.20865\n",
      "Iteration 728900: Avg Loss =  0.19571\n",
      "Iteration 729000: Avg Loss =  0.22592\n",
      "Iteration 729100: Avg Loss =  0.21162\n",
      "Iteration 729200: Avg Loss =  0.24107\n",
      "Iteration 729300: Avg Loss =  0.21781\n",
      "Iteration 729400: Avg Loss =  0.18897\n",
      "Iteration 729500: Avg Loss =  0.18660\n",
      "Iteration 729600: Avg Loss =  0.18622\n",
      "Iteration 729700: Avg Loss =  0.20415\n",
      "Iteration 729800: Avg Loss =  0.22114\n",
      "Iteration 729900: Avg Loss =  0.24034\n",
      "Iteration 730000: Avg Loss =  0.23967\n",
      "Iteration 730100: Avg Loss =  0.19259\n",
      "Iteration 730200: Avg Loss =  0.27543\n",
      "Iteration 730300: Avg Loss =  0.24196\n",
      "Iteration 730400: Avg Loss =  0.21315\n",
      "Iteration 730500: Avg Loss =  0.20446\n",
      "Iteration 730600: Avg Loss =  0.21883\n",
      "Iteration 730700: Avg Loss =  0.19175\n",
      "Iteration 730800: Avg Loss =  0.21166\n",
      "Iteration 730900: Avg Loss =  0.21368\n",
      "Iteration 731000: Avg Loss =  0.17217\n",
      "Iteration 731100: Avg Loss =  0.21614\n",
      "Iteration 731200: Avg Loss =  0.22814\n",
      "Iteration 731300: Avg Loss =  0.19721\n",
      "Iteration 731400: Avg Loss =  0.23439\n",
      "Iteration 731500: Avg Loss =  0.20921\n",
      "Iteration 731600: Avg Loss =  0.25102\n",
      "Iteration 731700: Avg Loss =  0.26531\n",
      "Iteration 731800: Avg Loss =  0.25363\n",
      "Iteration 731900: Avg Loss =  0.20727\n",
      "Iteration 732000: Avg Loss =  0.20325\n",
      "Iteration 732100: Avg Loss =  0.15383\n",
      "Iteration 732200: Avg Loss =  0.21089\n",
      "Iteration 732300: Avg Loss =  0.22130\n",
      "Iteration 732400: Avg Loss =  0.21975\n",
      "Iteration 732500: Avg Loss =  0.18641\n",
      "Iteration 732600: Avg Loss =  0.24083\n",
      "Iteration 732700: Avg Loss =  0.20893\n",
      "Iteration 732800: Avg Loss =  0.25244\n",
      "Iteration 732900: Avg Loss =  0.21306\n",
      "Iteration 733000: Avg Loss =  0.20198\n",
      "Iteration 733100: Avg Loss =  0.25374\n",
      "Iteration 733200: Avg Loss =  0.23058\n",
      "Iteration 733300: Avg Loss =  0.21658\n",
      "Iteration 733400: Avg Loss =  0.19327\n",
      "Iteration 733500: Avg Loss =  0.22095\n",
      "Iteration 733600: Avg Loss =  0.24083\n",
      "Iteration 733700: Avg Loss =  0.22660\n",
      "Iteration 733800: Avg Loss =  0.21186\n",
      "Iteration 733900: Avg Loss =  0.24395\n",
      "Iteration 734000: Avg Loss =  0.23081\n",
      "Iteration 734100: Avg Loss =  0.19185\n",
      "Iteration 734200: Avg Loss =  0.21404\n",
      "Iteration 734300: Avg Loss =  0.19188\n",
      "Iteration 734400: Avg Loss =  0.17279\n",
      "Iteration 734500: Avg Loss =  0.21710\n",
      "Iteration 734600: Avg Loss =  0.18326\n",
      "Iteration 734700: Avg Loss =  0.21658\n",
      "Iteration 734800: Avg Loss =  0.21256\n",
      "Iteration 734900: Avg Loss =  0.17354\n",
      "Iteration 735000: Avg Loss =  0.22574\n",
      "Iteration 735100: Avg Loss =  0.24260\n",
      "Iteration 735200: Avg Loss =  0.20528\n",
      "Iteration 735300: Avg Loss =  0.16725\n",
      "Iteration 735400: Avg Loss =  0.17392\n",
      "Iteration 735500: Avg Loss =  0.20436\n",
      "Iteration 735600: Avg Loss =  0.21212\n",
      "Iteration 735700: Avg Loss =  0.22344\n",
      "Iteration 735800: Avg Loss =  0.25753\n",
      "Iteration 735900: Avg Loss =  0.24327\n",
      "Iteration 736000: Avg Loss =  0.25466\n",
      "Iteration 736100: Avg Loss =  0.19007\n",
      "Iteration 736200: Avg Loss =  0.26041\n",
      "Iteration 736300: Avg Loss =  0.19361\n",
      "Iteration 736400: Avg Loss =  0.26003\n",
      "Iteration 736500: Avg Loss =  0.20738\n",
      "Iteration 736600: Avg Loss =  0.22621\n",
      "Iteration 736700: Avg Loss =  0.19056\n",
      "Iteration 736800: Avg Loss =  0.18082\n",
      "Iteration 736900: Avg Loss =  0.19407\n",
      "Iteration 737000: Avg Loss =  0.23658\n",
      "Iteration 737100: Avg Loss =  0.21344\n",
      "Iteration 737200: Avg Loss =  0.24071\n",
      "Iteration 737300: Avg Loss =  0.27112\n",
      "Iteration 737400: Avg Loss =  0.24686\n",
      "Iteration 737500: Avg Loss =  0.19057\n",
      "Iteration 737600: Avg Loss =  0.18768\n",
      "Iteration 737700: Avg Loss =  0.19246\n",
      "Iteration 737800: Avg Loss =  0.23123\n",
      "Iteration 737900: Avg Loss =  0.23601\n",
      "Iteration 738000: Avg Loss =  0.21864\n",
      "Iteration 738100: Avg Loss =  0.22976\n",
      "Iteration 738200: Avg Loss =  0.16929\n",
      "Iteration 738300: Avg Loss =  0.17447\n",
      "Iteration 738400: Avg Loss =  0.25323\n",
      "Iteration 738500: Avg Loss =  0.29885\n",
      "Iteration 738600: Avg Loss =  0.18633\n",
      "Iteration 738700: Avg Loss =  0.27002\n",
      "Iteration 738800: Avg Loss =  0.19318\n",
      "Iteration 738900: Avg Loss =  0.19478\n",
      "Iteration 739000: Avg Loss =  0.20730\n",
      "Iteration 739100: Avg Loss =  0.19255\n",
      "Iteration 739200: Avg Loss =  0.18725\n",
      "Iteration 739300: Avg Loss =  0.26006\n",
      "Iteration 739400: Avg Loss =  0.21212\n",
      "Iteration 739500: Avg Loss =  0.25163\n",
      "Iteration 739600: Avg Loss =  0.21117\n",
      "Iteration 739700: Avg Loss =  0.21537\n",
      "Iteration 739800: Avg Loss =  0.26852\n",
      "Iteration 739900: Avg Loss =  0.23084\n",
      "Iteration 740000: Avg Loss =  0.23017\n",
      "Iteration 740100: Avg Loss =  0.20556\n",
      "Iteration 740200: Avg Loss =  0.20660\n",
      "Iteration 740300: Avg Loss =  0.21369\n",
      "Iteration 740400: Avg Loss =  0.24093\n",
      "Iteration 740500: Avg Loss =  0.17365\n",
      "Iteration 740600: Avg Loss =  0.20491\n",
      "Iteration 740700: Avg Loss =  0.20355\n",
      "Iteration 740800: Avg Loss =  0.20066\n",
      "Iteration 740900: Avg Loss =  0.20753\n",
      "Iteration 741000: Avg Loss =  0.21232\n",
      "Iteration 741100: Avg Loss =  0.21150\n",
      "Iteration 741200: Avg Loss =  0.21844\n",
      "Iteration 741300: Avg Loss =  0.20270\n",
      "Iteration 741400: Avg Loss =  0.21680\n",
      "Iteration 741500: Avg Loss =  0.18871\n",
      "Iteration 741600: Avg Loss =  0.19742\n",
      "Iteration 741700: Avg Loss =  0.18515\n",
      "Iteration 741800: Avg Loss =  0.23754\n",
      "Iteration 741900: Avg Loss =  0.21283\n",
      "Iteration 742000: Avg Loss =  0.24311\n",
      "Iteration 742100: Avg Loss =  0.21311\n",
      "Iteration 742200: Avg Loss =  0.22287\n",
      "Iteration 742300: Avg Loss =  0.17643\n",
      "Iteration 742400: Avg Loss =  0.23450\n",
      "Iteration 742500: Avg Loss =  0.20196\n",
      "Iteration 742600: Avg Loss =  0.20072\n",
      "Iteration 742700: Avg Loss =  0.22447\n",
      "Iteration 742800: Avg Loss =  0.18627\n",
      "Iteration 742900: Avg Loss =  0.19273\n",
      "Iteration 743000: Avg Loss =  0.21516\n",
      "Iteration 743100: Avg Loss =  0.21321\n",
      "Iteration 743200: Avg Loss =  0.23042\n",
      "Iteration 743300: Avg Loss =  0.19830\n",
      "Iteration 743400: Avg Loss =  0.23832\n",
      "Iteration 743500: Avg Loss =  0.20461\n",
      "Iteration 743600: Avg Loss =  0.27649\n",
      "Iteration 743700: Avg Loss =  0.18204\n",
      "Iteration 743800: Avg Loss =  0.17381\n",
      "Iteration 743900: Avg Loss =  0.17618\n",
      "Iteration 744000: Avg Loss =  0.19362\n",
      "Iteration 744100: Avg Loss =  0.20590\n",
      "Iteration 744200: Avg Loss =  0.22100\n",
      "Iteration 744300: Avg Loss =  0.25690\n",
      "Iteration 744400: Avg Loss =  0.23801\n",
      "Iteration 744500: Avg Loss =  0.19493\n",
      "Iteration 744600: Avg Loss =  0.23461\n",
      "Iteration 744700: Avg Loss =  0.20168\n",
      "Iteration 744800: Avg Loss =  0.19534\n",
      "Iteration 744900: Avg Loss =  0.23852\n",
      "Iteration 745000: Avg Loss =  0.21469\n",
      "Iteration 745100: Avg Loss =  0.23057\n",
      "Iteration 745200: Avg Loss =  0.21138\n",
      "Iteration 745300: Avg Loss =  0.23975\n",
      "Iteration 745400: Avg Loss =  0.21123\n",
      "Iteration 745500: Avg Loss =  0.21586\n",
      "Iteration 745600: Avg Loss =  0.25381\n",
      "Iteration 745700: Avg Loss =  0.24602\n",
      "Iteration 745800: Avg Loss =  0.20444\n",
      "Iteration 745900: Avg Loss =  0.24670\n",
      "Iteration 746000: Avg Loss =  0.19911\n",
      "Iteration 746100: Avg Loss =  0.23044\n",
      "Iteration 746200: Avg Loss =  0.18891\n",
      "Iteration 746300: Avg Loss =  0.22742\n",
      "Iteration 746400: Avg Loss =  0.22765\n",
      "Iteration 746500: Avg Loss =  0.19051\n",
      "Iteration 746600: Avg Loss =  0.20262\n",
      "Iteration 746700: Avg Loss =  0.21337\n",
      "Iteration 746800: Avg Loss =  0.19711\n",
      "Iteration 746900: Avg Loss =  0.22189\n",
      "Iteration 747000: Avg Loss =  0.21601\n",
      "Iteration 747100: Avg Loss =  0.28692\n",
      "Iteration 747200: Avg Loss =  0.21251\n",
      "Iteration 747300: Avg Loss =  0.22328\n",
      "Iteration 747400: Avg Loss =  0.23725\n",
      "Iteration 747500: Avg Loss =  0.18065\n",
      "Iteration 747600: Avg Loss =  0.22904\n",
      "Iteration 747700: Avg Loss =  0.22152\n",
      "Iteration 747800: Avg Loss =  0.25323\n",
      "Iteration 747900: Avg Loss =  0.17918\n",
      "Iteration 748000: Avg Loss =  0.25818\n",
      "Iteration 748100: Avg Loss =  0.22154\n",
      "Iteration 748200: Avg Loss =  0.20837\n",
      "Iteration 748300: Avg Loss =  0.21193\n",
      "Iteration 748400: Avg Loss =  0.16664\n",
      "Iteration 748500: Avg Loss =  0.21550\n",
      "Iteration 748600: Avg Loss =  0.19679\n",
      "Iteration 748700: Avg Loss =  0.21904\n",
      "Iteration 748800: Avg Loss =  0.25264\n",
      "Iteration 748900: Avg Loss =  0.21428\n",
      "Iteration 749000: Avg Loss =  0.19426\n",
      "Iteration 749100: Avg Loss =  0.19088\n",
      "Iteration 749200: Avg Loss =  0.20293\n",
      "Iteration 749300: Avg Loss =  0.21540\n",
      "Iteration 749400: Avg Loss =  0.25200\n",
      "Iteration 749500: Avg Loss =  0.24483\n",
      "Iteration 749600: Avg Loss =  0.24923\n",
      "Iteration 749700: Avg Loss =  0.23465\n",
      "Iteration 749800: Avg Loss =  0.19993\n",
      "Iteration 749900: Avg Loss =  0.18432\n",
      "Iteration 750000: Avg Loss =  0.18867\n",
      "Iteration 750100: Avg Loss =  0.25554\n",
      "Iteration 750200: Avg Loss =  0.19819\n",
      "Iteration 750300: Avg Loss =  0.22251\n",
      "Iteration 750400: Avg Loss =  0.19986\n",
      "Iteration 750500: Avg Loss =  0.19362\n",
      "Iteration 750600: Avg Loss =  0.23306\n",
      "Iteration 750700: Avg Loss =  0.21321\n",
      "Iteration 750800: Avg Loss =  0.23120\n",
      "Iteration 750900: Avg Loss =  0.22124\n",
      "Iteration 751000: Avg Loss =  0.24884\n",
      "Iteration 751100: Avg Loss =  0.19338\n",
      "Iteration 751200: Avg Loss =  0.22637\n",
      "Iteration 751300: Avg Loss =  0.21429\n",
      "Iteration 751400: Avg Loss =  0.16489\n",
      "Iteration 751500: Avg Loss =  0.21855\n",
      "Iteration 751600: Avg Loss =  0.21221\n",
      "Iteration 751700: Avg Loss =  0.20122\n",
      "Iteration 751800: Avg Loss =  0.19082\n",
      "Iteration 751900: Avg Loss =  0.24037\n",
      "Iteration 752000: Avg Loss =  0.24277\n",
      "Iteration 752100: Avg Loss =  0.22184\n",
      "Iteration 752200: Avg Loss =  0.19461\n",
      "Iteration 752300: Avg Loss =  0.26734\n",
      "Iteration 752400: Avg Loss =  0.19863\n",
      "Iteration 752500: Avg Loss =  0.19750\n",
      "Iteration 752600: Avg Loss =  0.21626\n",
      "Iteration 752700: Avg Loss =  0.25273\n",
      "Iteration 752800: Avg Loss =  0.22261\n",
      "Iteration 752900: Avg Loss =  0.23532\n",
      "Iteration 753000: Avg Loss =  0.20582\n",
      "Iteration 753100: Avg Loss =  0.24454\n",
      "Iteration 753200: Avg Loss =  0.25520\n",
      "Iteration 753300: Avg Loss =  0.19175\n",
      "Iteration 753400: Avg Loss =  0.19338\n",
      "Iteration 753500: Avg Loss =  0.21241\n",
      "Iteration 753600: Avg Loss =  0.21607\n",
      "Iteration 753700: Avg Loss =  0.18907\n",
      "Iteration 753800: Avg Loss =  0.24847\n",
      "Iteration 753900: Avg Loss =  0.19967\n",
      "Iteration 754000: Avg Loss =  0.23587\n",
      "Iteration 754100: Avg Loss =  0.22814\n",
      "Iteration 754200: Avg Loss =  0.22063\n",
      "Iteration 754300: Avg Loss =  0.18264\n",
      "Iteration 754400: Avg Loss =  0.19190\n",
      "Iteration 754500: Avg Loss =  0.27538\n",
      "Iteration 754600: Avg Loss =  0.22868\n",
      "Iteration 754700: Avg Loss =  0.20647\n",
      "Iteration 754800: Avg Loss =  0.26485\n",
      "Iteration 754900: Avg Loss =  0.22388\n",
      "Iteration 755000: Avg Loss =  0.23390\n",
      "Iteration 755100: Avg Loss =  0.17667\n",
      "Iteration 755200: Avg Loss =  0.21288\n",
      "Iteration 755300: Avg Loss =  0.24401\n",
      "Iteration 755400: Avg Loss =  0.21253\n",
      "Iteration 755500: Avg Loss =  0.21685\n",
      "Iteration 755600: Avg Loss =  0.20987\n",
      "Iteration 755700: Avg Loss =  0.21194\n",
      "Iteration 755800: Avg Loss =  0.19208\n",
      "Iteration 755900: Avg Loss =  0.19988\n",
      "Iteration 756000: Avg Loss =  0.17574\n",
      "Iteration 756100: Avg Loss =  0.23642\n",
      "Iteration 756200: Avg Loss =  0.18485\n",
      "Iteration 756300: Avg Loss =  0.18942\n",
      "Iteration 756400: Avg Loss =  0.20399\n",
      "Iteration 756500: Avg Loss =  0.19945\n",
      "Iteration 756600: Avg Loss =  0.18946\n",
      "Iteration 756700: Avg Loss =  0.18195\n",
      "Iteration 756800: Avg Loss =  0.27561\n",
      "Iteration 756900: Avg Loss =  0.21060\n",
      "Iteration 757000: Avg Loss =  0.19107\n",
      "Iteration 757100: Avg Loss =  0.23222\n",
      "Iteration 757200: Avg Loss =  0.19138\n",
      "Iteration 757300: Avg Loss =  0.22300\n",
      "Iteration 757400: Avg Loss =  0.22671\n",
      "Iteration 757500: Avg Loss =  0.23310\n",
      "Iteration 757600: Avg Loss =  0.17983\n",
      "Iteration 757700: Avg Loss =  0.19809\n",
      "Iteration 757800: Avg Loss =  0.20133\n",
      "Iteration 757900: Avg Loss =  0.21027\n",
      "Iteration 758000: Avg Loss =  0.21106\n",
      "Iteration 758100: Avg Loss =  0.21568\n",
      "Iteration 758200: Avg Loss =  0.18445\n",
      "Iteration 758300: Avg Loss =  0.27829\n",
      "Iteration 758400: Avg Loss =  0.23627\n",
      "Iteration 758500: Avg Loss =  0.22142\n",
      "Iteration 758600: Avg Loss =  0.22982\n",
      "Iteration 758700: Avg Loss =  0.22830\n",
      "Iteration 758800: Avg Loss =  0.23525\n",
      "Iteration 758900: Avg Loss =  0.19648\n",
      "Iteration 759000: Avg Loss =  0.20625\n",
      "Iteration 759100: Avg Loss =  0.20969\n",
      "Iteration 759200: Avg Loss =  0.19482\n",
      "Iteration 759300: Avg Loss =  0.24463\n",
      "Iteration 759400: Avg Loss =  0.20775\n",
      "Iteration 759500: Avg Loss =  0.18861\n",
      "Iteration 759600: Avg Loss =  0.24675\n",
      "Iteration 759700: Avg Loss =  0.21265\n",
      "Iteration 759800: Avg Loss =  0.20954\n",
      "Iteration 759900: Avg Loss =  0.21511\n",
      "Iteration 760000: Avg Loss =  0.20901\n",
      "Iteration 760100: Avg Loss =  0.23394\n",
      "Iteration 760200: Avg Loss =  0.19589\n",
      "Iteration 760300: Avg Loss =  0.20855\n",
      "Iteration 760400: Avg Loss =  0.24962\n",
      "Iteration 760500: Avg Loss =  0.20771\n",
      "Iteration 760600: Avg Loss =  0.20509\n",
      "Iteration 760700: Avg Loss =  0.22803\n",
      "Iteration 760800: Avg Loss =  0.16758\n",
      "Iteration 760900: Avg Loss =  0.18672\n",
      "Iteration 761000: Avg Loss =  0.23029\n",
      "Iteration 761100: Avg Loss =  0.16108\n",
      "Iteration 761200: Avg Loss =  0.17285\n",
      "Iteration 761300: Avg Loss =  0.22419\n",
      "Iteration 761400: Avg Loss =  0.23087\n",
      "Iteration 761500: Avg Loss =  0.19659\n",
      "Iteration 761600: Avg Loss =  0.18070\n",
      "Iteration 761700: Avg Loss =  0.19744\n",
      "Iteration 761800: Avg Loss =  0.21042\n",
      "Iteration 761900: Avg Loss =  0.18725\n",
      "Iteration 762000: Avg Loss =  0.20022\n",
      "Iteration 762100: Avg Loss =  0.17961\n",
      "Iteration 762200: Avg Loss =  0.24383\n",
      "Iteration 762300: Avg Loss =  0.21870\n",
      "Iteration 762400: Avg Loss =  0.22077\n",
      "Iteration 762500: Avg Loss =  0.22012\n",
      "Iteration 762600: Avg Loss =  0.22517\n",
      "Iteration 762700: Avg Loss =  0.17070\n",
      "Iteration 762800: Avg Loss =  0.16505\n",
      "Iteration 762900: Avg Loss =  0.18666\n",
      "Iteration 763000: Avg Loss =  0.19799\n",
      "Iteration 763100: Avg Loss =  0.19431\n",
      "Iteration 763200: Avg Loss =  0.22909\n",
      "Iteration 763300: Avg Loss =  0.21560\n",
      "Iteration 763400: Avg Loss =  0.18875\n",
      "Iteration 763500: Avg Loss =  0.18673\n",
      "Iteration 763600: Avg Loss =  0.18525\n",
      "Iteration 763700: Avg Loss =  0.21209\n",
      "Iteration 763800: Avg Loss =  0.16972\n",
      "Iteration 763900: Avg Loss =  0.19865\n",
      "Iteration 764000: Avg Loss =  0.20014\n",
      "Iteration 764100: Avg Loss =  0.19236\n",
      "Iteration 764200: Avg Loss =  0.17210\n",
      "Iteration 764300: Avg Loss =  0.24852\n",
      "Iteration 764400: Avg Loss =  0.16998\n",
      "Iteration 764500: Avg Loss =  0.19704\n",
      "Iteration 764600: Avg Loss =  0.16364\n",
      "Iteration 764700: Avg Loss =  0.18723\n",
      "Iteration 764800: Avg Loss =  0.21594\n",
      "Iteration 764900: Avg Loss =  0.21826\n",
      "Iteration 765000: Avg Loss =  0.19401\n",
      "Iteration 765100: Avg Loss =  0.23992\n",
      "Iteration 765200: Avg Loss =  0.21867\n",
      "Iteration 765300: Avg Loss =  0.24253\n",
      "Iteration 765400: Avg Loss =  0.22985\n",
      "Iteration 765500: Avg Loss =  0.19318\n",
      "Iteration 765600: Avg Loss =  0.22139\n",
      "Iteration 765700: Avg Loss =  0.23762\n",
      "Iteration 765800: Avg Loss =  0.21839\n",
      "Iteration 765900: Avg Loss =  0.22506\n",
      "Iteration 766000: Avg Loss =  0.22146\n",
      "Iteration 766100: Avg Loss =  0.17175\n",
      "Iteration 766200: Avg Loss =  0.21187\n",
      "Iteration 766300: Avg Loss =  0.20466\n",
      "Iteration 766400: Avg Loss =  0.23508\n",
      "Iteration 766500: Avg Loss =  0.17746\n",
      "Iteration 766600: Avg Loss =  0.19643\n",
      "Iteration 766700: Avg Loss =  0.23266\n",
      "Iteration 766800: Avg Loss =  0.20923\n",
      "Iteration 766900: Avg Loss =  0.21725\n",
      "Iteration 767000: Avg Loss =  0.19963\n",
      "Iteration 767100: Avg Loss =  0.21141\n",
      "Iteration 767200: Avg Loss =  0.19656\n",
      "Iteration 767300: Avg Loss =  0.18383\n",
      "Iteration 767400: Avg Loss =  0.18301\n",
      "Iteration 767500: Avg Loss =  0.18151\n",
      "Iteration 767600: Avg Loss =  0.21018\n",
      "Iteration 767700: Avg Loss =  0.18634\n",
      "Iteration 767800: Avg Loss =  0.20387\n",
      "Iteration 767900: Avg Loss =  0.21279\n",
      "Iteration 768000: Avg Loss =  0.25139\n",
      "Iteration 768100: Avg Loss =  0.21044\n",
      "Iteration 768200: Avg Loss =  0.17895\n",
      "Iteration 768300: Avg Loss =  0.19751\n",
      "Iteration 768400: Avg Loss =  0.20106\n",
      "Iteration 768500: Avg Loss =  0.21662\n",
      "Iteration 768600: Avg Loss =  0.21551\n",
      "Iteration 768700: Avg Loss =  0.20627\n",
      "Iteration 768800: Avg Loss =  0.21975\n",
      "Iteration 768900: Avg Loss =  0.26423\n",
      "Iteration 769000: Avg Loss =  0.19793\n",
      "Iteration 769100: Avg Loss =  0.22768\n",
      "Iteration 769200: Avg Loss =  0.21201\n",
      "Iteration 769300: Avg Loss =  0.19803\n",
      "Iteration 769400: Avg Loss =  0.26199\n",
      "Iteration 769500: Avg Loss =  0.20065\n",
      "Iteration 769600: Avg Loss =  0.19662\n",
      "Iteration 769700: Avg Loss =  0.17457\n",
      "Iteration 769800: Avg Loss =  0.19380\n",
      "Iteration 769900: Avg Loss =  0.20707\n",
      "Iteration 770000: Avg Loss =  0.16680\n",
      "Iteration 770100: Avg Loss =  0.26497\n",
      "Iteration 770200: Avg Loss =  0.18247\n",
      "Iteration 770300: Avg Loss =  0.19793\n",
      "Iteration 770400: Avg Loss =  0.19748\n",
      "Iteration 770500: Avg Loss =  0.18813\n",
      "Iteration 770600: Avg Loss =  0.23676\n",
      "Iteration 770700: Avg Loss =  0.20103\n",
      "Iteration 770800: Avg Loss =  0.26450\n",
      "Iteration 770900: Avg Loss =  0.18931\n",
      "Iteration 771000: Avg Loss =  0.17661\n",
      "Iteration 771100: Avg Loss =  0.23497\n",
      "Iteration 771200: Avg Loss =  0.18906\n",
      "Iteration 771300: Avg Loss =  0.24975\n",
      "Iteration 771400: Avg Loss =  0.21284\n",
      "Iteration 771500: Avg Loss =  0.24336\n",
      "Iteration 771600: Avg Loss =  0.19843\n",
      "Iteration 771700: Avg Loss =  0.22022\n",
      "Iteration 771800: Avg Loss =  0.24186\n",
      "Iteration 771900: Avg Loss =  0.23855\n",
      "Iteration 772000: Avg Loss =  0.23990\n",
      "Iteration 772100: Avg Loss =  0.21739\n",
      "Iteration 772200: Avg Loss =  0.25302\n",
      "Iteration 772300: Avg Loss =  0.26711\n",
      "Iteration 772400: Avg Loss =  0.21273\n",
      "Iteration 772500: Avg Loss =  0.23767\n",
      "Iteration 772600: Avg Loss =  0.18817\n",
      "Iteration 772700: Avg Loss =  0.19982\n",
      "Iteration 772800: Avg Loss =  0.19354\n",
      "Iteration 772900: Avg Loss =  0.21689\n",
      "Iteration 773000: Avg Loss =  0.24510\n",
      "Iteration 773100: Avg Loss =  0.19741\n",
      "Iteration 773200: Avg Loss =  0.20682\n",
      "Iteration 773300: Avg Loss =  0.23524\n",
      "Iteration 773400: Avg Loss =  0.18941\n",
      "Iteration 773500: Avg Loss =  0.20029\n",
      "Iteration 773600: Avg Loss =  0.22942\n",
      "Iteration 773700: Avg Loss =  0.23322\n",
      "Iteration 773800: Avg Loss =  0.19711\n",
      "Iteration 773900: Avg Loss =  0.18347\n",
      "Iteration 774000: Avg Loss =  0.18870\n",
      "Iteration 774100: Avg Loss =  0.23963\n",
      "Iteration 774200: Avg Loss =  0.18854\n",
      "Iteration 774300: Avg Loss =  0.19832\n",
      "Iteration 774400: Avg Loss =  0.18793\n",
      "Iteration 774500: Avg Loss =  0.22971\n",
      "Iteration 774600: Avg Loss =  0.25639\n",
      "Iteration 774700: Avg Loss =  0.23363\n",
      "Iteration 774800: Avg Loss =  0.18533\n",
      "Iteration 774900: Avg Loss =  0.21913\n",
      "Iteration 775000: Avg Loss =  0.21219\n",
      "Iteration 775100: Avg Loss =  0.19335\n",
      "Iteration 775200: Avg Loss =  0.22253\n",
      "Iteration 775300: Avg Loss =  0.23841\n",
      "Iteration 775400: Avg Loss =  0.22456\n",
      "Iteration 775500: Avg Loss =  0.20354\n",
      "Iteration 775600: Avg Loss =  0.20317\n",
      "Iteration 775700: Avg Loss =  0.23448\n",
      "Iteration 775800: Avg Loss =  0.22128\n",
      "Iteration 775900: Avg Loss =  0.19004\n",
      "Iteration 776000: Avg Loss =  0.18987\n",
      "Iteration 776100: Avg Loss =  0.23019\n",
      "Iteration 776200: Avg Loss =  0.20404\n",
      "Iteration 776300: Avg Loss =  0.18635\n",
      "Iteration 776400: Avg Loss =  0.19813\n",
      "Iteration 776500: Avg Loss =  0.20572\n",
      "Iteration 776600: Avg Loss =  0.25959\n",
      "Iteration 776700: Avg Loss =  0.21041\n",
      "Iteration 776800: Avg Loss =  0.23636\n",
      "Iteration 776900: Avg Loss =  0.17779\n",
      "Iteration 777000: Avg Loss =  0.19212\n",
      "Iteration 777100: Avg Loss =  0.22951\n",
      "Iteration 777200: Avg Loss =  0.21401\n",
      "Iteration 777300: Avg Loss =  0.21319\n",
      "Iteration 777400: Avg Loss =  0.20042\n",
      "Iteration 777500: Avg Loss =  0.21284\n",
      "Iteration 777600: Avg Loss =  0.22308\n",
      "Iteration 777700: Avg Loss =  0.18260\n",
      "Iteration 777800: Avg Loss =  0.20216\n",
      "Iteration 777900: Avg Loss =  0.22942\n",
      "Iteration 778000: Avg Loss =  0.19093\n",
      "Iteration 778100: Avg Loss =  0.18892\n",
      "Iteration 778200: Avg Loss =  0.23395\n",
      "Iteration 778300: Avg Loss =  0.21010\n",
      "Iteration 778400: Avg Loss =  0.18589\n",
      "Iteration 778500: Avg Loss =  0.21043\n",
      "Iteration 778600: Avg Loss =  0.19595\n",
      "Iteration 778700: Avg Loss =  0.21597\n",
      "Iteration 778800: Avg Loss =  0.20231\n",
      "Iteration 778900: Avg Loss =  0.19777\n",
      "Iteration 779000: Avg Loss =  0.25271\n",
      "Iteration 779100: Avg Loss =  0.16340\n",
      "Iteration 779200: Avg Loss =  0.22036\n",
      "Iteration 779300: Avg Loss =  0.22361\n",
      "Iteration 779400: Avg Loss =  0.20942\n",
      "Iteration 779500: Avg Loss =  0.17829\n",
      "Iteration 779600: Avg Loss =  0.16454\n",
      "Iteration 779700: Avg Loss =  0.21058\n",
      "Iteration 779800: Avg Loss =  0.26892\n",
      "Iteration 779900: Avg Loss =  0.20108\n",
      "Iteration 780000: Avg Loss =  0.21164\n",
      "Iteration 780100: Avg Loss =  0.18116\n",
      "Iteration 780200: Avg Loss =  0.21259\n",
      "Iteration 780300: Avg Loss =  0.23564\n",
      "Iteration 780400: Avg Loss =  0.22402\n",
      "Iteration 780500: Avg Loss =  0.21300\n",
      "Iteration 780600: Avg Loss =  0.21688\n",
      "Iteration 780700: Avg Loss =  0.22045\n",
      "Iteration 780800: Avg Loss =  0.27870\n",
      "Iteration 780900: Avg Loss =  0.19297\n",
      "Iteration 781000: Avg Loss =  0.24390\n",
      "Iteration 781100: Avg Loss =  0.20744\n",
      "Iteration 781200: Avg Loss =  0.20407\n",
      "Iteration 781300: Avg Loss =  0.21962\n",
      "Iteration 781400: Avg Loss =  0.20030\n",
      "Iteration 781500: Avg Loss =  0.19460\n",
      "Iteration 781600: Avg Loss =  0.19879\n",
      "Iteration 781700: Avg Loss =  0.19506\n",
      "Iteration 781800: Avg Loss =  0.17629\n",
      "Iteration 781900: Avg Loss =  0.18797\n",
      "Iteration 782000: Avg Loss =  0.20756\n",
      "Iteration 782100: Avg Loss =  0.21317\n",
      "Iteration 782200: Avg Loss =  0.20156\n",
      "Iteration 782300: Avg Loss =  0.23302\n",
      "Iteration 782400: Avg Loss =  0.20821\n",
      "Iteration 782500: Avg Loss =  0.22408\n",
      "Iteration 782600: Avg Loss =  0.25435\n",
      "Iteration 782700: Avg Loss =  0.19650\n",
      "Iteration 782800: Avg Loss =  0.17611\n",
      "Iteration 782900: Avg Loss =  0.20169\n",
      "Iteration 783000: Avg Loss =  0.20986\n",
      "Iteration 783100: Avg Loss =  0.20571\n",
      "Iteration 783200: Avg Loss =  0.16683\n",
      "Iteration 783300: Avg Loss =  0.19151\n",
      "Iteration 783400: Avg Loss =  0.21246\n",
      "Iteration 783500: Avg Loss =  0.20458\n",
      "Iteration 783600: Avg Loss =  0.24152\n",
      "Iteration 783700: Avg Loss =  0.17131\n",
      "Iteration 783800: Avg Loss =  0.20041\n",
      "Iteration 783900: Avg Loss =  0.20707\n",
      "Iteration 784000: Avg Loss =  0.19036\n",
      "Iteration 784100: Avg Loss =  0.23292\n",
      "Iteration 784200: Avg Loss =  0.18941\n",
      "Iteration 784300: Avg Loss =  0.24439\n",
      "Iteration 784400: Avg Loss =  0.20383\n",
      "Iteration 784500: Avg Loss =  0.22049\n",
      "Iteration 784600: Avg Loss =  0.20586\n",
      "Iteration 784700: Avg Loss =  0.18394\n",
      "Iteration 784800: Avg Loss =  0.17423\n",
      "Iteration 784900: Avg Loss =  0.24200\n",
      "Iteration 785000: Avg Loss =  0.15617\n",
      "Iteration 785100: Avg Loss =  0.27294\n",
      "Iteration 785200: Avg Loss =  0.23371\n",
      "Iteration 785300: Avg Loss =  0.18899\n",
      "Iteration 785400: Avg Loss =  0.22525\n",
      "Iteration 785500: Avg Loss =  0.21318\n",
      "Iteration 785600: Avg Loss =  0.22573\n",
      "Iteration 785700: Avg Loss =  0.20119\n",
      "Iteration 785800: Avg Loss =  0.24088\n",
      "Iteration 785900: Avg Loss =  0.20303\n",
      "Iteration 786000: Avg Loss =  0.17768\n",
      "Iteration 786100: Avg Loss =  0.19109\n",
      "Iteration 786200: Avg Loss =  0.20011\n",
      "Iteration 786300: Avg Loss =  0.18158\n",
      "Iteration 786400: Avg Loss =  0.19805\n",
      "Iteration 786500: Avg Loss =  0.21760\n",
      "Iteration 786600: Avg Loss =  0.22968\n",
      "Iteration 786700: Avg Loss =  0.21355\n",
      "Iteration 786800: Avg Loss =  0.18782\n",
      "Iteration 786900: Avg Loss =  0.22844\n",
      "Iteration 787000: Avg Loss =  0.20949\n",
      "Iteration 787100: Avg Loss =  0.20482\n",
      "Iteration 787200: Avg Loss =  0.17267\n",
      "Iteration 787300: Avg Loss =  0.19327\n",
      "Iteration 787400: Avg Loss =  0.26491\n",
      "Iteration 787500: Avg Loss =  0.19397\n",
      "Iteration 787600: Avg Loss =  0.20084\n",
      "Iteration 787700: Avg Loss =  0.18361\n",
      "Iteration 787800: Avg Loss =  0.23583\n",
      "Iteration 787900: Avg Loss =  0.20318\n",
      "Iteration 788000: Avg Loss =  0.24478\n",
      "Iteration 788100: Avg Loss =  0.20055\n",
      "Iteration 788200: Avg Loss =  0.19974\n",
      "Iteration 788300: Avg Loss =  0.19134\n",
      "Iteration 788400: Avg Loss =  0.31805\n",
      "Iteration 788500: Avg Loss =  0.22057\n",
      "Iteration 788600: Avg Loss =  0.18732\n",
      "Iteration 788700: Avg Loss =  0.21765\n",
      "Iteration 788800: Avg Loss =  0.18901\n",
      "Iteration 788900: Avg Loss =  0.19778\n",
      "Iteration 789000: Avg Loss =  0.17433\n",
      "Iteration 789100: Avg Loss =  0.19671\n",
      "Iteration 789200: Avg Loss =  0.14644\n",
      "Iteration 789300: Avg Loss =  0.19837\n",
      "Iteration 789400: Avg Loss =  0.20240\n",
      "Iteration 789500: Avg Loss =  0.20146\n",
      "Iteration 789600: Avg Loss =  0.18283\n",
      "Iteration 789700: Avg Loss =  0.23765\n",
      "Iteration 789800: Avg Loss =  0.24842\n",
      "Iteration 789900: Avg Loss =  0.19843\n",
      "Iteration 790000: Avg Loss =  0.21026\n",
      "Iteration 790100: Avg Loss =  0.20017\n",
      "Iteration 790200: Avg Loss =  0.25334\n",
      "Iteration 790300: Avg Loss =  0.20498\n",
      "Iteration 790400: Avg Loss =  0.25196\n",
      "Iteration 790500: Avg Loss =  0.20123\n",
      "Iteration 790600: Avg Loss =  0.21087\n",
      "Iteration 790700: Avg Loss =  0.22864\n",
      "Iteration 790800: Avg Loss =  0.18658\n",
      "Iteration 790900: Avg Loss =  0.23647\n",
      "Iteration 791000: Avg Loss =  0.20392\n",
      "Iteration 791100: Avg Loss =  0.20962\n",
      "Iteration 791200: Avg Loss =  0.17831\n",
      "Iteration 791300: Avg Loss =  0.23615\n",
      "Iteration 791400: Avg Loss =  0.20936\n",
      "Iteration 791500: Avg Loss =  0.18107\n",
      "Iteration 791600: Avg Loss =  0.18540\n",
      "Iteration 791700: Avg Loss =  0.19540\n",
      "Iteration 791800: Avg Loss =  0.20419\n",
      "Iteration 791900: Avg Loss =  0.21208\n",
      "Iteration 792000: Avg Loss =  0.19824\n",
      "Iteration 792100: Avg Loss =  0.28245\n",
      "Iteration 792200: Avg Loss =  0.20703\n",
      "Iteration 792300: Avg Loss =  0.22122\n",
      "Iteration 792400: Avg Loss =  0.19982\n",
      "Iteration 792500: Avg Loss =  0.19060\n",
      "Iteration 792600: Avg Loss =  0.21285\n",
      "Iteration 792700: Avg Loss =  0.19972\n",
      "Iteration 792800: Avg Loss =  0.19200\n",
      "Iteration 792900: Avg Loss =  0.19804\n",
      "Iteration 793000: Avg Loss =  0.21413\n",
      "Iteration 793100: Avg Loss =  0.20088\n",
      "Iteration 793200: Avg Loss =  0.25901\n",
      "Iteration 793300: Avg Loss =  0.25564\n",
      "Iteration 793400: Avg Loss =  0.19812\n",
      "Iteration 793500: Avg Loss =  0.18450\n",
      "Iteration 793600: Avg Loss =  0.23953\n",
      "Iteration 793700: Avg Loss =  0.20963\n",
      "Iteration 793800: Avg Loss =  0.18127\n",
      "Iteration 793900: Avg Loss =  0.22385\n",
      "Iteration 794000: Avg Loss =  0.17804\n",
      "Iteration 794100: Avg Loss =  0.23364\n",
      "Iteration 794200: Avg Loss =  0.22743\n",
      "Iteration 794300: Avg Loss =  0.23325\n",
      "Iteration 794400: Avg Loss =  0.18646\n",
      "Iteration 794500: Avg Loss =  0.18505\n",
      "Iteration 794600: Avg Loss =  0.19121\n",
      "Iteration 794700: Avg Loss =  0.19846\n",
      "Iteration 794800: Avg Loss =  0.19883\n",
      "Iteration 794900: Avg Loss =  0.25515\n",
      "Iteration 795000: Avg Loss =  0.20687\n",
      "Iteration 795100: Avg Loss =  0.20923\n",
      "Iteration 795200: Avg Loss =  0.24281\n",
      "Iteration 795300: Avg Loss =  0.22633\n",
      "Iteration 795400: Avg Loss =  0.21235\n",
      "Iteration 795500: Avg Loss =  0.19658\n",
      "Iteration 795600: Avg Loss =  0.20883\n",
      "Iteration 795700: Avg Loss =  0.20031\n",
      "Iteration 795800: Avg Loss =  0.18133\n",
      "Iteration 795900: Avg Loss =  0.19034\n",
      "Iteration 796000: Avg Loss =  0.19994\n",
      "Iteration 796100: Avg Loss =  0.20060\n",
      "Iteration 796200: Avg Loss =  0.19864\n",
      "Iteration 796300: Avg Loss =  0.21912\n",
      "Iteration 796400: Avg Loss =  0.18463\n",
      "Iteration 796500: Avg Loss =  0.18980\n",
      "Iteration 796600: Avg Loss =  0.24780\n",
      "Iteration 796700: Avg Loss =  0.21296\n",
      "Iteration 796800: Avg Loss =  0.21295\n",
      "Iteration 796900: Avg Loss =  0.22430\n",
      "Iteration 797000: Avg Loss =  0.23984\n",
      "Iteration 797100: Avg Loss =  0.20244\n",
      "Iteration 797200: Avg Loss =  0.20101\n",
      "Iteration 797300: Avg Loss =  0.19448\n",
      "Iteration 797400: Avg Loss =  0.23479\n",
      "Iteration 797500: Avg Loss =  0.17413\n",
      "Iteration 797600: Avg Loss =  0.18594\n",
      "Iteration 797700: Avg Loss =  0.21047\n",
      "Iteration 797800: Avg Loss =  0.19690\n",
      "Iteration 797900: Avg Loss =  0.20562\n",
      "Iteration 798000: Avg Loss =  0.17363\n",
      "Iteration 798100: Avg Loss =  0.19698\n",
      "Iteration 798200: Avg Loss =  0.21531\n",
      "Iteration 798300: Avg Loss =  0.19673\n",
      "Iteration 798400: Avg Loss =  0.20924\n",
      "Iteration 798500: Avg Loss =  0.22855\n",
      "Iteration 798600: Avg Loss =  0.20365\n",
      "Iteration 798700: Avg Loss =  0.21813\n",
      "Iteration 798800: Avg Loss =  0.20531\n",
      "Iteration 798900: Avg Loss =  0.25482\n",
      "Iteration 799000: Avg Loss =  0.22320\n",
      "Iteration 799100: Avg Loss =  0.18544\n",
      "Iteration 799200: Avg Loss =  0.20077\n",
      "Iteration 799300: Avg Loss =  0.28194\n",
      "Iteration 799400: Avg Loss =  0.18475\n",
      "Iteration 799500: Avg Loss =  0.20914\n",
      "Iteration 799600: Avg Loss =  0.21965\n",
      "Iteration 799700: Avg Loss =  0.20521\n",
      "Iteration 799800: Avg Loss =  0.21101\n",
      "Iteration 799900: Avg Loss =  0.20878\n",
      "Iteration 800000: Avg Loss =  0.23069\n",
      "Iteration 800100: Avg Loss =  0.17488\n",
      "Iteration 800200: Avg Loss =  0.20248\n",
      "Iteration 800300: Avg Loss =  0.16396\n",
      "Iteration 800400: Avg Loss =  0.19023\n",
      "Iteration 800500: Avg Loss =  0.17893\n",
      "Iteration 800600: Avg Loss =  0.22312\n",
      "Iteration 800700: Avg Loss =  0.18784\n",
      "Iteration 800800: Avg Loss =  0.19714\n",
      "Iteration 800900: Avg Loss =  0.17397\n",
      "Iteration 801000: Avg Loss =  0.23888\n",
      "Iteration 801100: Avg Loss =  0.20456\n",
      "Iteration 801200: Avg Loss =  0.19863\n",
      "Iteration 801300: Avg Loss =  0.20220\n",
      "Iteration 801400: Avg Loss =  0.23367\n",
      "Iteration 801500: Avg Loss =  0.22373\n",
      "Iteration 801600: Avg Loss =  0.25500\n",
      "Iteration 801700: Avg Loss =  0.21105\n",
      "Iteration 801800: Avg Loss =  0.18191\n",
      "Iteration 801900: Avg Loss =  0.24281\n",
      "Iteration 802000: Avg Loss =  0.17105\n",
      "Iteration 802100: Avg Loss =  0.20867\n",
      "Iteration 802200: Avg Loss =  0.20954\n",
      "Iteration 802300: Avg Loss =  0.18271\n",
      "Iteration 802400: Avg Loss =  0.19832\n",
      "Iteration 802500: Avg Loss =  0.19202\n",
      "Iteration 802600: Avg Loss =  0.18379\n",
      "Iteration 802700: Avg Loss =  0.22649\n",
      "Iteration 802800: Avg Loss =  0.19597\n",
      "Iteration 802900: Avg Loss =  0.19598\n",
      "Iteration 803000: Avg Loss =  0.19694\n",
      "Iteration 803100: Avg Loss =  0.20651\n",
      "Iteration 803200: Avg Loss =  0.18655\n",
      "Iteration 803300: Avg Loss =  0.17964\n",
      "Iteration 803400: Avg Loss =  0.20351\n",
      "Iteration 803500: Avg Loss =  0.23316\n",
      "Iteration 803600: Avg Loss =  0.20445\n",
      "Iteration 803700: Avg Loss =  0.25986\n",
      "Iteration 803800: Avg Loss =  0.21664\n",
      "Iteration 803900: Avg Loss =  0.19119\n",
      "Iteration 804000: Avg Loss =  0.21114\n",
      "Iteration 804100: Avg Loss =  0.22417\n",
      "Iteration 804200: Avg Loss =  0.22654\n",
      "Iteration 804300: Avg Loss =  0.23458\n",
      "Iteration 804400: Avg Loss =  0.21231\n",
      "Iteration 804500: Avg Loss =  0.19421\n",
      "Iteration 804600: Avg Loss =  0.20415\n",
      "Iteration 804700: Avg Loss =  0.19438\n",
      "Iteration 804800: Avg Loss =  0.17082\n",
      "Iteration 804900: Avg Loss =  0.20085\n",
      "Iteration 805000: Avg Loss =  0.23589\n",
      "Iteration 805100: Avg Loss =  0.18528\n",
      "Iteration 805200: Avg Loss =  0.17510\n",
      "Iteration 805300: Avg Loss =  0.20763\n",
      "Iteration 805400: Avg Loss =  0.20103\n",
      "Iteration 805500: Avg Loss =  0.18237\n",
      "Iteration 805600: Avg Loss =  0.17881\n",
      "Iteration 805700: Avg Loss =  0.19700\n",
      "Iteration 805800: Avg Loss =  0.21219\n",
      "Iteration 805900: Avg Loss =  0.21382\n",
      "Iteration 806000: Avg Loss =  0.19605\n",
      "Iteration 806100: Avg Loss =  0.23851\n",
      "Iteration 806200: Avg Loss =  0.19001\n",
      "Iteration 806300: Avg Loss =  0.20765\n",
      "Iteration 806400: Avg Loss =  0.16797\n",
      "Iteration 806500: Avg Loss =  0.15952\n",
      "Iteration 806600: Avg Loss =  0.23344\n",
      "Iteration 806700: Avg Loss =  0.21946\n",
      "Iteration 806800: Avg Loss =  0.17810\n",
      "Iteration 806900: Avg Loss =  0.16465\n",
      "Iteration 807000: Avg Loss =  0.20497\n",
      "Iteration 807100: Avg Loss =  0.21755\n",
      "Iteration 807200: Avg Loss =  0.20429\n",
      "Iteration 807300: Avg Loss =  0.24558\n",
      "Iteration 807400: Avg Loss =  0.18556\n",
      "Iteration 807500: Avg Loss =  0.17564\n",
      "Iteration 807600: Avg Loss =  0.18377\n",
      "Iteration 807700: Avg Loss =  0.18796\n",
      "Iteration 807800: Avg Loss =  0.22175\n",
      "Iteration 807900: Avg Loss =  0.18943\n",
      "Iteration 808000: Avg Loss =  0.20557\n",
      "Iteration 808100: Avg Loss =  0.20306\n",
      "Iteration 808200: Avg Loss =  0.18736\n",
      "Iteration 808300: Avg Loss =  0.20003\n",
      "Iteration 808400: Avg Loss =  0.20035\n",
      "Iteration 808500: Avg Loss =  0.20773\n",
      "Iteration 808600: Avg Loss =  0.20327\n",
      "Iteration 808700: Avg Loss =  0.18362\n",
      "Iteration 808800: Avg Loss =  0.22282\n",
      "Iteration 808900: Avg Loss =  0.20998\n",
      "Iteration 809000: Avg Loss =  0.21109\n",
      "Iteration 809100: Avg Loss =  0.16767\n",
      "Iteration 809200: Avg Loss =  0.15568\n",
      "Iteration 809300: Avg Loss =  0.24776\n",
      "Iteration 809400: Avg Loss =  0.20114\n",
      "Iteration 809500: Avg Loss =  0.21607\n",
      "Iteration 809600: Avg Loss =  0.23369\n",
      "Iteration 809700: Avg Loss =  0.25460\n",
      "Iteration 809800: Avg Loss =  0.19753\n",
      "Iteration 809900: Avg Loss =  0.19775\n",
      "Iteration 810000: Avg Loss =  0.21256\n",
      "Iteration 810100: Avg Loss =  0.17991\n",
      "Iteration 810200: Avg Loss =  0.23361\n",
      "Iteration 810300: Avg Loss =  0.20997\n",
      "Iteration 810400: Avg Loss =  0.22036\n",
      "Iteration 810500: Avg Loss =  0.22145\n",
      "Iteration 810600: Avg Loss =  0.19088\n",
      "Iteration 810700: Avg Loss =  0.17937\n",
      "Iteration 810800: Avg Loss =  0.24328\n",
      "Iteration 810900: Avg Loss =  0.20796\n",
      "Iteration 811000: Avg Loss =  0.19805\n",
      "Iteration 811100: Avg Loss =  0.22342\n",
      "Iteration 811200: Avg Loss =  0.19213\n",
      "Iteration 811300: Avg Loss =  0.18069\n",
      "Iteration 811400: Avg Loss =  0.20864\n",
      "Iteration 811500: Avg Loss =  0.19253\n",
      "Iteration 811600: Avg Loss =  0.19229\n",
      "Iteration 811700: Avg Loss =  0.21741\n",
      "Iteration 811800: Avg Loss =  0.20691\n",
      "Iteration 811900: Avg Loss =  0.19787\n",
      "Iteration 812000: Avg Loss =  0.21984\n",
      "Iteration 812100: Avg Loss =  0.22652\n",
      "Iteration 812200: Avg Loss =  0.20305\n",
      "Iteration 812300: Avg Loss =  0.20163\n",
      "Iteration 812400: Avg Loss =  0.20292\n",
      "Iteration 812500: Avg Loss =  0.19942\n",
      "Iteration 812600: Avg Loss =  0.18912\n",
      "Iteration 812700: Avg Loss =  0.27498\n",
      "Iteration 812800: Avg Loss =  0.18861\n",
      "Iteration 812900: Avg Loss =  0.21173\n",
      "Iteration 813000: Avg Loss =  0.20951\n",
      "Iteration 813100: Avg Loss =  0.19340\n",
      "Iteration 813200: Avg Loss =  0.22442\n",
      "Iteration 813300: Avg Loss =  0.24043\n",
      "Iteration 813400: Avg Loss =  0.23092\n",
      "Iteration 813500: Avg Loss =  0.19771\n",
      "Iteration 813600: Avg Loss =  0.18533\n",
      "Iteration 813700: Avg Loss =  0.24156\n",
      "Iteration 813800: Avg Loss =  0.22361\n",
      "Iteration 813900: Avg Loss =  0.18888\n",
      "Iteration 814000: Avg Loss =  0.20544\n",
      "Iteration 814100: Avg Loss =  0.19846\n",
      "Iteration 814200: Avg Loss =  0.22243\n",
      "Iteration 814300: Avg Loss =  0.17739\n",
      "Iteration 814400: Avg Loss =  0.18853\n",
      "Iteration 814500: Avg Loss =  0.23655\n",
      "Iteration 814600: Avg Loss =  0.19868\n",
      "Iteration 814700: Avg Loss =  0.22655\n",
      "Iteration 814800: Avg Loss =  0.19710\n",
      "Iteration 814900: Avg Loss =  0.18711\n",
      "Iteration 815000: Avg Loss =  0.18241\n",
      "Iteration 815100: Avg Loss =  0.23021\n",
      "Iteration 815200: Avg Loss =  0.20486\n",
      "Iteration 815300: Avg Loss =  0.21176\n",
      "Iteration 815400: Avg Loss =  0.19778\n",
      "Iteration 815500: Avg Loss =  0.19539\n",
      "Iteration 815600: Avg Loss =  0.22111\n",
      "Iteration 815700: Avg Loss =  0.20189\n",
      "Iteration 815800: Avg Loss =  0.21780\n",
      "Iteration 815900: Avg Loss =  0.22375\n",
      "Iteration 816000: Avg Loss =  0.17100\n",
      "Iteration 816100: Avg Loss =  0.19048\n",
      "Iteration 816200: Avg Loss =  0.16673\n",
      "Iteration 816300: Avg Loss =  0.20480\n",
      "Iteration 816400: Avg Loss =  0.17551\n",
      "Iteration 816500: Avg Loss =  0.22848\n",
      "Iteration 816600: Avg Loss =  0.24547\n",
      "Iteration 816700: Avg Loss =  0.18060\n",
      "Iteration 816800: Avg Loss =  0.21489\n",
      "Iteration 816900: Avg Loss =  0.19812\n",
      "Iteration 817000: Avg Loss =  0.18893\n",
      "Iteration 817100: Avg Loss =  0.20739\n",
      "Iteration 817200: Avg Loss =  0.20553\n",
      "Iteration 817300: Avg Loss =  0.21627\n",
      "Iteration 817400: Avg Loss =  0.18769\n",
      "Iteration 817500: Avg Loss =  0.20506\n",
      "Iteration 817600: Avg Loss =  0.20801\n",
      "Iteration 817700: Avg Loss =  0.19807\n",
      "Iteration 817800: Avg Loss =  0.18404\n",
      "Iteration 817900: Avg Loss =  0.17347\n",
      "Iteration 818000: Avg Loss =  0.19888\n",
      "Iteration 818100: Avg Loss =  0.17301\n",
      "Iteration 818200: Avg Loss =  0.20476\n",
      "Iteration 818300: Avg Loss =  0.16019\n",
      "Iteration 818400: Avg Loss =  0.19329\n",
      "Iteration 818500: Avg Loss =  0.21955\n",
      "Iteration 818600: Avg Loss =  0.21712\n",
      "Iteration 818700: Avg Loss =  0.18338\n",
      "Iteration 818800: Avg Loss =  0.20070\n",
      "Iteration 818900: Avg Loss =  0.19510\n",
      "Iteration 819000: Avg Loss =  0.20187\n",
      "Iteration 819100: Avg Loss =  0.22320\n",
      "Iteration 819200: Avg Loss =  0.25292\n",
      "Iteration 819300: Avg Loss =  0.23443\n",
      "Iteration 819400: Avg Loss =  0.19348\n",
      "Iteration 819500: Avg Loss =  0.16708\n",
      "Iteration 819600: Avg Loss =  0.20848\n",
      "Iteration 819700: Avg Loss =  0.19433\n",
      "Iteration 819800: Avg Loss =  0.18376\n",
      "Iteration 819900: Avg Loss =  0.20513\n",
      "Iteration 820000: Avg Loss =  0.21889\n",
      "Iteration 820100: Avg Loss =  0.19172\n",
      "Iteration 820200: Avg Loss =  0.19707\n",
      "Iteration 820300: Avg Loss =  0.23438\n",
      "Iteration 820400: Avg Loss =  0.17686\n",
      "Iteration 820500: Avg Loss =  0.19115\n",
      "Iteration 820600: Avg Loss =  0.24687\n",
      "Iteration 820700: Avg Loss =  0.17906\n",
      "Iteration 820800: Avg Loss =  0.19416\n",
      "Iteration 820900: Avg Loss =  0.20526\n",
      "Iteration 821000: Avg Loss =  0.21721\n",
      "Iteration 821100: Avg Loss =  0.20563\n",
      "Iteration 821200: Avg Loss =  0.23560\n",
      "Iteration 821300: Avg Loss =  0.21650\n",
      "Iteration 821400: Avg Loss =  0.19205\n",
      "Iteration 821500: Avg Loss =  0.19882\n",
      "Iteration 821600: Avg Loss =  0.21867\n",
      "Iteration 821700: Avg Loss =  0.19977\n",
      "Iteration 821800: Avg Loss =  0.23540\n",
      "Iteration 821900: Avg Loss =  0.19124\n",
      "Iteration 822000: Avg Loss =  0.20092\n",
      "Iteration 822100: Avg Loss =  0.18897\n",
      "Iteration 822200: Avg Loss =  0.19899\n",
      "Iteration 822300: Avg Loss =  0.19066\n",
      "Iteration 822400: Avg Loss =  0.15964\n",
      "Iteration 822500: Avg Loss =  0.21242\n",
      "Iteration 822600: Avg Loss =  0.22988\n",
      "Iteration 822700: Avg Loss =  0.23768\n",
      "Iteration 822800: Avg Loss =  0.27254\n",
      "Iteration 822900: Avg Loss =  0.18545\n",
      "Iteration 823000: Avg Loss =  0.19024\n",
      "Iteration 823100: Avg Loss =  0.22464\n",
      "Iteration 823200: Avg Loss =  0.21007\n",
      "Iteration 823300: Avg Loss =  0.20857\n",
      "Iteration 823400: Avg Loss =  0.19829\n",
      "Iteration 823500: Avg Loss =  0.19538\n",
      "Iteration 823600: Avg Loss =  0.17368\n",
      "Iteration 823700: Avg Loss =  0.19202\n",
      "Iteration 823800: Avg Loss =  0.24364\n",
      "Iteration 823900: Avg Loss =  0.24786\n",
      "Iteration 824000: Avg Loss =  0.18191\n",
      "Iteration 824100: Avg Loss =  0.18283\n",
      "Iteration 824200: Avg Loss =  0.20266\n",
      "Iteration 824300: Avg Loss =  0.23354\n",
      "Iteration 824400: Avg Loss =  0.17881\n",
      "Iteration 824500: Avg Loss =  0.21880\n",
      "Iteration 824600: Avg Loss =  0.22606\n",
      "Iteration 824700: Avg Loss =  0.20392\n",
      "Iteration 824800: Avg Loss =  0.23357\n",
      "Iteration 824900: Avg Loss =  0.18185\n",
      "Iteration 825000: Avg Loss =  0.21043\n",
      "Iteration 825100: Avg Loss =  0.15272\n",
      "Iteration 825200: Avg Loss =  0.16241\n",
      "Iteration 825300: Avg Loss =  0.19152\n",
      "Iteration 825400: Avg Loss =  0.19472\n",
      "Iteration 825500: Avg Loss =  0.22738\n",
      "Iteration 825600: Avg Loss =  0.21663\n",
      "Iteration 825700: Avg Loss =  0.20729\n",
      "Iteration 825800: Avg Loss =  0.22754\n",
      "Iteration 825900: Avg Loss =  0.14798\n",
      "Iteration 826000: Avg Loss =  0.17602\n",
      "Iteration 826100: Avg Loss =  0.20223\n",
      "Iteration 826200: Avg Loss =  0.19026\n",
      "Iteration 826300: Avg Loss =  0.21771\n",
      "Iteration 826400: Avg Loss =  0.23848\n",
      "Iteration 826500: Avg Loss =  0.20560\n",
      "Iteration 826600: Avg Loss =  0.20664\n",
      "Iteration 826700: Avg Loss =  0.20544\n",
      "Iteration 826800: Avg Loss =  0.19441\n",
      "Iteration 826900: Avg Loss =  0.21202\n",
      "Iteration 827000: Avg Loss =  0.17233\n",
      "Iteration 827100: Avg Loss =  0.21969\n",
      "Iteration 827200: Avg Loss =  0.21774\n",
      "Iteration 827300: Avg Loss =  0.25774\n",
      "Iteration 827400: Avg Loss =  0.17185\n",
      "Iteration 827500: Avg Loss =  0.18072\n",
      "Iteration 827600: Avg Loss =  0.19252\n",
      "Iteration 827700: Avg Loss =  0.17586\n",
      "Iteration 827800: Avg Loss =  0.25303\n",
      "Iteration 827900: Avg Loss =  0.20492\n",
      "Iteration 828000: Avg Loss =  0.21241\n",
      "Iteration 828100: Avg Loss =  0.20760\n",
      "Iteration 828200: Avg Loss =  0.19729\n",
      "Iteration 828300: Avg Loss =  0.23188\n",
      "Iteration 828400: Avg Loss =  0.18752\n",
      "Iteration 828500: Avg Loss =  0.19639\n",
      "Iteration 828600: Avg Loss =  0.18677\n",
      "Iteration 828700: Avg Loss =  0.20331\n",
      "Iteration 828800: Avg Loss =  0.18390\n",
      "Iteration 828900: Avg Loss =  0.18139\n",
      "Iteration 829000: Avg Loss =  0.20638\n",
      "Iteration 829100: Avg Loss =  0.17136\n",
      "Iteration 829200: Avg Loss =  0.20667\n",
      "Iteration 829300: Avg Loss =  0.15693\n",
      "Iteration 829400: Avg Loss =  0.24549\n",
      "Iteration 829500: Avg Loss =  0.16719\n",
      "Iteration 829600: Avg Loss =  0.17904\n",
      "Iteration 829700: Avg Loss =  0.19400\n",
      "Iteration 829800: Avg Loss =  0.17643\n",
      "Iteration 829900: Avg Loss =  0.18060\n",
      "Iteration 830000: Avg Loss =  0.23731\n",
      "Iteration 830100: Avg Loss =  0.18037\n",
      "Iteration 830200: Avg Loss =  0.21668\n",
      "Iteration 830300: Avg Loss =  0.21657\n",
      "Iteration 830400: Avg Loss =  0.19999\n",
      "Iteration 830500: Avg Loss =  0.21334\n",
      "Iteration 830600: Avg Loss =  0.16813\n",
      "Iteration 830700: Avg Loss =  0.16964\n",
      "Iteration 830800: Avg Loss =  0.22729\n",
      "Iteration 830900: Avg Loss =  0.19344\n",
      "Iteration 831000: Avg Loss =  0.17862\n",
      "Iteration 831100: Avg Loss =  0.18503\n",
      "Iteration 831200: Avg Loss =  0.20617\n",
      "Iteration 831300: Avg Loss =  0.17426\n",
      "Iteration 831400: Avg Loss =  0.23092\n",
      "Iteration 831500: Avg Loss =  0.23658\n",
      "Iteration 831600: Avg Loss =  0.22078\n",
      "Iteration 831700: Avg Loss =  0.21205\n",
      "Iteration 831800: Avg Loss =  0.24300\n",
      "Iteration 831900: Avg Loss =  0.21175\n",
      "Iteration 832000: Avg Loss =  0.18340\n",
      "Iteration 832100: Avg Loss =  0.18005\n",
      "Iteration 832200: Avg Loss =  0.19107\n",
      "Iteration 832300: Avg Loss =  0.21212\n",
      "Iteration 832400: Avg Loss =  0.19535\n",
      "Iteration 832500: Avg Loss =  0.20147\n",
      "Iteration 832600: Avg Loss =  0.21094\n",
      "Iteration 832700: Avg Loss =  0.24163\n",
      "Iteration 832800: Avg Loss =  0.16422\n",
      "Iteration 832900: Avg Loss =  0.17742\n",
      "Iteration 833000: Avg Loss =  0.15769\n",
      "Iteration 833100: Avg Loss =  0.20458\n",
      "Iteration 833200: Avg Loss =  0.17840\n",
      "Iteration 833300: Avg Loss =  0.17508\n",
      "Iteration 833400: Avg Loss =  0.18181\n",
      "Iteration 833500: Avg Loss =  0.18099\n",
      "Iteration 833600: Avg Loss =  0.20795\n",
      "Iteration 833700: Avg Loss =  0.20161\n",
      "Iteration 833800: Avg Loss =  0.21395\n",
      "Iteration 833900: Avg Loss =  0.20582\n",
      "Iteration 834000: Avg Loss =  0.21753\n",
      "Iteration 834100: Avg Loss =  0.17089\n",
      "Iteration 834200: Avg Loss =  0.17261\n",
      "Iteration 834300: Avg Loss =  0.16195\n",
      "Iteration 834400: Avg Loss =  0.17903\n",
      "Iteration 834500: Avg Loss =  0.25450\n",
      "Iteration 834600: Avg Loss =  0.18742\n",
      "Iteration 834700: Avg Loss =  0.20486\n",
      "Iteration 834800: Avg Loss =  0.18736\n",
      "Iteration 834900: Avg Loss =  0.25862\n",
      "Iteration 835000: Avg Loss =  0.23070\n",
      "Iteration 835100: Avg Loss =  0.22269\n",
      "Iteration 835200: Avg Loss =  0.16221\n",
      "Iteration 835300: Avg Loss =  0.21132\n",
      "Iteration 835400: Avg Loss =  0.20830\n",
      "Iteration 835500: Avg Loss =  0.19515\n",
      "Iteration 835600: Avg Loss =  0.19348\n",
      "Iteration 835700: Avg Loss =  0.15125\n",
      "Iteration 835800: Avg Loss =  0.19465\n",
      "Iteration 835900: Avg Loss =  0.23141\n",
      "Iteration 836000: Avg Loss =  0.18252\n",
      "Iteration 836100: Avg Loss =  0.23224\n",
      "Iteration 836200: Avg Loss =  0.21400\n",
      "Iteration 836300: Avg Loss =  0.20275\n",
      "Iteration 836400: Avg Loss =  0.23969\n",
      "Iteration 836500: Avg Loss =  0.17676\n",
      "Iteration 836600: Avg Loss =  0.18092\n",
      "Iteration 836700: Avg Loss =  0.20393\n",
      "Iteration 836800: Avg Loss =  0.18978\n",
      "Iteration 836900: Avg Loss =  0.20405\n",
      "Iteration 837000: Avg Loss =  0.19114\n",
      "Iteration 837100: Avg Loss =  0.23613\n",
      "Iteration 837200: Avg Loss =  0.19680\n",
      "Iteration 837300: Avg Loss =  0.16644\n",
      "Iteration 837400: Avg Loss =  0.18287\n",
      "Iteration 837500: Avg Loss =  0.19984\n",
      "Iteration 837600: Avg Loss =  0.18147\n",
      "Iteration 837700: Avg Loss =  0.20137\n",
      "Iteration 837800: Avg Loss =  0.19765\n",
      "Iteration 837900: Avg Loss =  0.20656\n",
      "Iteration 838000: Avg Loss =  0.22017\n",
      "Iteration 838100: Avg Loss =  0.20331\n",
      "Iteration 838200: Avg Loss =  0.24045\n",
      "Iteration 838300: Avg Loss =  0.16940\n",
      "Iteration 838400: Avg Loss =  0.18722\n",
      "Iteration 838500: Avg Loss =  0.17869\n",
      "Iteration 838600: Avg Loss =  0.20431\n",
      "Iteration 838700: Avg Loss =  0.17995\n",
      "Iteration 838800: Avg Loss =  0.20854\n",
      "Iteration 838900: Avg Loss =  0.25074\n",
      "Iteration 839000: Avg Loss =  0.18047\n",
      "Iteration 839100: Avg Loss =  0.20898\n",
      "Iteration 839200: Avg Loss =  0.22264\n",
      "Iteration 839300: Avg Loss =  0.22420\n",
      "Iteration 839400: Avg Loss =  0.18753\n",
      "Iteration 839500: Avg Loss =  0.18572\n",
      "Iteration 839600: Avg Loss =  0.18374\n",
      "Iteration 839700: Avg Loss =  0.19594\n",
      "Iteration 839800: Avg Loss =  0.19635\n",
      "Iteration 839900: Avg Loss =  0.18443\n",
      "Iteration 840000: Avg Loss =  0.19115\n",
      "Iteration 840100: Avg Loss =  0.21375\n",
      "Iteration 840200: Avg Loss =  0.23636\n",
      "Iteration 840300: Avg Loss =  0.24153\n",
      "Iteration 840400: Avg Loss =  0.22836\n",
      "Iteration 840500: Avg Loss =  0.16815\n",
      "Iteration 840600: Avg Loss =  0.22067\n",
      "Iteration 840700: Avg Loss =  0.23887\n",
      "Iteration 840800: Avg Loss =  0.18014\n",
      "Iteration 840900: Avg Loss =  0.21330\n",
      "Iteration 841000: Avg Loss =  0.14712\n",
      "Iteration 841100: Avg Loss =  0.18665\n",
      "Iteration 841200: Avg Loss =  0.22295\n",
      "Iteration 841300: Avg Loss =  0.19670\n",
      "Iteration 841400: Avg Loss =  0.20463\n",
      "Iteration 841500: Avg Loss =  0.18743\n",
      "Iteration 841600: Avg Loss =  0.18851\n",
      "Iteration 841700: Avg Loss =  0.20825\n",
      "Iteration 841800: Avg Loss =  0.21976\n",
      "Iteration 841900: Avg Loss =  0.21841\n",
      "Iteration 842000: Avg Loss =  0.24103\n",
      "Iteration 842100: Avg Loss =  0.19090\n",
      "Iteration 842200: Avg Loss =  0.21902\n",
      "Iteration 842300: Avg Loss =  0.19008\n",
      "Iteration 842400: Avg Loss =  0.17804\n",
      "Iteration 842500: Avg Loss =  0.17711\n",
      "Iteration 842600: Avg Loss =  0.24622\n",
      "Iteration 842700: Avg Loss =  0.20709\n",
      "Iteration 842800: Avg Loss =  0.24275\n",
      "Iteration 842900: Avg Loss =  0.15534\n",
      "Iteration 843000: Avg Loss =  0.17218\n",
      "Iteration 843100: Avg Loss =  0.18975\n",
      "Iteration 843200: Avg Loss =  0.18499\n",
      "Iteration 843300: Avg Loss =  0.17945\n",
      "Iteration 843400: Avg Loss =  0.19940\n",
      "Iteration 843500: Avg Loss =  0.19478\n",
      "Iteration 843600: Avg Loss =  0.23637\n",
      "Iteration 843700: Avg Loss =  0.18210\n",
      "Iteration 843800: Avg Loss =  0.20450\n",
      "Iteration 843900: Avg Loss =  0.24617\n",
      "Iteration 844000: Avg Loss =  0.23753\n",
      "Iteration 844100: Avg Loss =  0.16292\n",
      "Iteration 844200: Avg Loss =  0.22532\n",
      "Iteration 844300: Avg Loss =  0.22874\n",
      "Iteration 844400: Avg Loss =  0.19945\n",
      "Iteration 844500: Avg Loss =  0.18926\n",
      "Iteration 844600: Avg Loss =  0.21255\n",
      "Iteration 844700: Avg Loss =  0.19181\n",
      "Iteration 844800: Avg Loss =  0.22177\n",
      "Iteration 844900: Avg Loss =  0.20543\n",
      "Iteration 845000: Avg Loss =  0.17591\n",
      "Iteration 845100: Avg Loss =  0.20166\n",
      "Iteration 845200: Avg Loss =  0.15381\n",
      "Iteration 845300: Avg Loss =  0.21291\n",
      "Iteration 845400: Avg Loss =  0.19023\n",
      "Iteration 845500: Avg Loss =  0.20306\n",
      "Iteration 845600: Avg Loss =  0.20696\n",
      "Iteration 845700: Avg Loss =  0.20047\n",
      "Iteration 845800: Avg Loss =  0.20767\n",
      "Iteration 845900: Avg Loss =  0.20841\n",
      "Iteration 846000: Avg Loss =  0.17179\n",
      "Iteration 846100: Avg Loss =  0.26481\n",
      "Iteration 846200: Avg Loss =  0.20627\n",
      "Iteration 846300: Avg Loss =  0.19920\n",
      "Iteration 846400: Avg Loss =  0.20508\n",
      "Iteration 846500: Avg Loss =  0.21482\n",
      "Iteration 846600: Avg Loss =  0.23424\n",
      "Iteration 846700: Avg Loss =  0.20864\n",
      "Iteration 846800: Avg Loss =  0.19869\n",
      "Iteration 846900: Avg Loss =  0.22983\n",
      "Iteration 847000: Avg Loss =  0.19058\n",
      "Iteration 847100: Avg Loss =  0.20394\n",
      "Iteration 847200: Avg Loss =  0.22517\n",
      "Iteration 847300: Avg Loss =  0.19058\n",
      "Iteration 847400: Avg Loss =  0.19931\n",
      "Iteration 847500: Avg Loss =  0.22035\n",
      "Iteration 847600: Avg Loss =  0.19680\n",
      "Iteration 847700: Avg Loss =  0.22954\n",
      "Iteration 847800: Avg Loss =  0.19476\n",
      "Iteration 847900: Avg Loss =  0.19528\n",
      "Iteration 848000: Avg Loss =  0.19640\n",
      "Iteration 848100: Avg Loss =  0.16609\n",
      "Iteration 848200: Avg Loss =  0.19660\n",
      "Iteration 848300: Avg Loss =  0.18960\n",
      "Iteration 848400: Avg Loss =  0.18334\n",
      "Iteration 848500: Avg Loss =  0.17354\n",
      "Iteration 848600: Avg Loss =  0.20318\n",
      "Iteration 848700: Avg Loss =  0.17808\n",
      "Iteration 848800: Avg Loss =  0.22283\n",
      "Iteration 848900: Avg Loss =  0.15746\n",
      "Iteration 849000: Avg Loss =  0.18711\n",
      "Iteration 849100: Avg Loss =  0.16232\n",
      "Iteration 849200: Avg Loss =  0.16822\n",
      "Iteration 849300: Avg Loss =  0.19571\n",
      "Iteration 849400: Avg Loss =  0.26024\n",
      "Iteration 849500: Avg Loss =  0.20779\n",
      "Iteration 849600: Avg Loss =  0.19306\n",
      "Iteration 849700: Avg Loss =  0.20462\n",
      "Iteration 849800: Avg Loss =  0.19858\n",
      "Iteration 849900: Avg Loss =  0.20284\n",
      "Iteration 850000: Avg Loss =  0.17932\n",
      "Iteration 850100: Avg Loss =  0.16472\n",
      "Iteration 850200: Avg Loss =  0.26549\n",
      "Iteration 850300: Avg Loss =  0.20307\n",
      "Iteration 850400: Avg Loss =  0.23297\n",
      "Iteration 850500: Avg Loss =  0.22527\n",
      "Iteration 850600: Avg Loss =  0.18383\n",
      "Iteration 850700: Avg Loss =  0.24731\n",
      "Iteration 850800: Avg Loss =  0.20086\n",
      "Iteration 850900: Avg Loss =  0.23503\n",
      "Iteration 851000: Avg Loss =  0.18275\n",
      "Iteration 851100: Avg Loss =  0.19973\n",
      "Iteration 851200: Avg Loss =  0.19163\n",
      "Iteration 851300: Avg Loss =  0.19304\n",
      "Iteration 851400: Avg Loss =  0.20585\n",
      "Iteration 851500: Avg Loss =  0.20136\n",
      "Iteration 851600: Avg Loss =  0.18283\n",
      "Iteration 851700: Avg Loss =  0.15476\n",
      "Iteration 851800: Avg Loss =  0.17515\n",
      "Iteration 851900: Avg Loss =  0.21654\n",
      "Iteration 852000: Avg Loss =  0.17324\n",
      "Iteration 852100: Avg Loss =  0.21907\n",
      "Iteration 852200: Avg Loss =  0.18439\n",
      "Iteration 852300: Avg Loss =  0.23037\n",
      "Iteration 852400: Avg Loss =  0.18358\n",
      "Iteration 852500: Avg Loss =  0.17567\n",
      "Iteration 852600: Avg Loss =  0.20435\n",
      "Iteration 852700: Avg Loss =  0.23758\n",
      "Iteration 852800: Avg Loss =  0.15952\n",
      "Iteration 852900: Avg Loss =  0.19713\n",
      "Iteration 853000: Avg Loss =  0.17583\n",
      "Iteration 853100: Avg Loss =  0.16282\n",
      "Iteration 853200: Avg Loss =  0.20996\n",
      "Iteration 853300: Avg Loss =  0.20990\n",
      "Iteration 853400: Avg Loss =  0.18554\n",
      "Iteration 853500: Avg Loss =  0.21331\n",
      "Iteration 853600: Avg Loss =  0.20997\n",
      "Iteration 853700: Avg Loss =  0.20972\n",
      "Iteration 853800: Avg Loss =  0.18610\n",
      "Iteration 853900: Avg Loss =  0.21497\n",
      "Iteration 854000: Avg Loss =  0.20442\n",
      "Iteration 854100: Avg Loss =  0.22546\n",
      "Iteration 854200: Avg Loss =  0.18193\n",
      "Iteration 854300: Avg Loss =  0.19209\n",
      "Iteration 854400: Avg Loss =  0.20506\n",
      "Iteration 854500: Avg Loss =  0.20911\n",
      "Iteration 854600: Avg Loss =  0.20024\n",
      "Iteration 854700: Avg Loss =  0.17624\n",
      "Iteration 854800: Avg Loss =  0.20492\n",
      "Iteration 854900: Avg Loss =  0.18103\n",
      "Iteration 855000: Avg Loss =  0.16404\n",
      "Iteration 855100: Avg Loss =  0.23162\n",
      "Iteration 855200: Avg Loss =  0.19762\n",
      "Iteration 855300: Avg Loss =  0.20375\n",
      "Iteration 855400: Avg Loss =  0.22257\n",
      "Iteration 855500: Avg Loss =  0.23368\n",
      "Iteration 855600: Avg Loss =  0.19998\n",
      "Iteration 855700: Avg Loss =  0.16235\n",
      "Iteration 855800: Avg Loss =  0.18310\n",
      "Iteration 855900: Avg Loss =  0.21504\n",
      "Iteration 856000: Avg Loss =  0.21210\n",
      "Iteration 856100: Avg Loss =  0.23002\n",
      "Iteration 856200: Avg Loss =  0.20898\n",
      "Iteration 856300: Avg Loss =  0.18942\n",
      "Iteration 856400: Avg Loss =  0.19067\n",
      "Iteration 856500: Avg Loss =  0.22157\n",
      "Iteration 856600: Avg Loss =  0.20166\n",
      "Iteration 856700: Avg Loss =  0.21589\n",
      "Iteration 856800: Avg Loss =  0.23868\n",
      "Iteration 856900: Avg Loss =  0.21646\n",
      "Iteration 857000: Avg Loss =  0.16030\n",
      "Iteration 857100: Avg Loss =  0.19285\n",
      "Iteration 857200: Avg Loss =  0.16855\n",
      "Iteration 857300: Avg Loss =  0.19262\n",
      "Iteration 857400: Avg Loss =  0.18544\n",
      "Iteration 857500: Avg Loss =  0.20522\n",
      "Iteration 857600: Avg Loss =  0.20759\n",
      "Iteration 857700: Avg Loss =  0.17780\n",
      "Iteration 857800: Avg Loss =  0.20284\n",
      "Iteration 857900: Avg Loss =  0.18678\n",
      "Iteration 858000: Avg Loss =  0.19320\n",
      "Iteration 858100: Avg Loss =  0.19693\n",
      "Iteration 858200: Avg Loss =  0.19817\n",
      "Iteration 858300: Avg Loss =  0.16959\n",
      "Iteration 858400: Avg Loss =  0.19489\n",
      "Iteration 858500: Avg Loss =  0.22518\n",
      "Iteration 858600: Avg Loss =  0.16459\n",
      "Iteration 858700: Avg Loss =  0.18956\n",
      "Iteration 858800: Avg Loss =  0.22972\n",
      "Iteration 858900: Avg Loss =  0.20497\n",
      "Iteration 859000: Avg Loss =  0.18890\n",
      "Iteration 859100: Avg Loss =  0.18474\n",
      "Iteration 859200: Avg Loss =  0.22924\n",
      "Iteration 859300: Avg Loss =  0.18385\n",
      "Iteration 859400: Avg Loss =  0.18721\n",
      "Iteration 859500: Avg Loss =  0.19321\n",
      "Iteration 859600: Avg Loss =  0.17571\n",
      "Iteration 859700: Avg Loss =  0.21862\n",
      "Iteration 859800: Avg Loss =  0.24151\n",
      "Iteration 859900: Avg Loss =  0.18933\n",
      "Iteration 860000: Avg Loss =  0.21291\n",
      "Iteration 860100: Avg Loss =  0.19939\n",
      "Iteration 860200: Avg Loss =  0.19382\n",
      "Iteration 860300: Avg Loss =  0.24113\n",
      "Iteration 860400: Avg Loss =  0.24763\n",
      "Iteration 860500: Avg Loss =  0.22025\n",
      "Iteration 860600: Avg Loss =  0.21243\n",
      "Iteration 860700: Avg Loss =  0.17172\n",
      "Iteration 860800: Avg Loss =  0.17634\n",
      "Iteration 860900: Avg Loss =  0.21050\n",
      "Iteration 861000: Avg Loss =  0.18391\n",
      "Iteration 861100: Avg Loss =  0.19461\n",
      "Iteration 861200: Avg Loss =  0.19672\n",
      "Iteration 861300: Avg Loss =  0.25814\n",
      "Iteration 861400: Avg Loss =  0.18013\n",
      "Iteration 861500: Avg Loss =  0.24164\n",
      "Iteration 861600: Avg Loss =  0.19830\n",
      "Iteration 861700: Avg Loss =  0.22913\n",
      "Iteration 861800: Avg Loss =  0.19621\n",
      "Iteration 861900: Avg Loss =  0.19912\n",
      "Iteration 862000: Avg Loss =  0.17616\n",
      "Iteration 862100: Avg Loss =  0.18834\n",
      "Iteration 862200: Avg Loss =  0.21083\n",
      "Iteration 862300: Avg Loss =  0.21185\n",
      "Iteration 862400: Avg Loss =  0.20412\n",
      "Iteration 862500: Avg Loss =  0.21192\n",
      "Iteration 862600: Avg Loss =  0.19395\n",
      "Iteration 862700: Avg Loss =  0.19606\n",
      "Iteration 862800: Avg Loss =  0.18963\n",
      "Iteration 862900: Avg Loss =  0.22282\n",
      "Iteration 863000: Avg Loss =  0.17888\n",
      "Iteration 863100: Avg Loss =  0.21295\n",
      "Iteration 863200: Avg Loss =  0.20761\n",
      "Iteration 863300: Avg Loss =  0.19310\n",
      "Iteration 863400: Avg Loss =  0.18524\n",
      "Iteration 863500: Avg Loss =  0.15944\n",
      "Iteration 863600: Avg Loss =  0.23996\n",
      "Iteration 863700: Avg Loss =  0.25506\n",
      "Iteration 863800: Avg Loss =  0.18908\n",
      "Iteration 863900: Avg Loss =  0.18709\n",
      "Iteration 864000: Avg Loss =  0.20919\n",
      "Iteration 864100: Avg Loss =  0.24247\n",
      "Iteration 864200: Avg Loss =  0.22757\n",
      "Iteration 864300: Avg Loss =  0.20710\n",
      "Iteration 864400: Avg Loss =  0.21700\n",
      "Iteration 864500: Avg Loss =  0.21420\n",
      "Iteration 864600: Avg Loss =  0.17545\n",
      "Iteration 864700: Avg Loss =  0.16215\n",
      "Iteration 864800: Avg Loss =  0.16840\n",
      "Iteration 864900: Avg Loss =  0.18897\n",
      "Iteration 865000: Avg Loss =  0.19971\n",
      "Iteration 865100: Avg Loss =  0.19400\n",
      "Iteration 865200: Avg Loss =  0.17671\n",
      "Iteration 865300: Avg Loss =  0.16857\n",
      "Iteration 865400: Avg Loss =  0.23368\n",
      "Iteration 865500: Avg Loss =  0.14633\n",
      "Iteration 865600: Avg Loss =  0.20102\n",
      "Iteration 865700: Avg Loss =  0.22308\n",
      "Iteration 865800: Avg Loss =  0.20326\n",
      "Iteration 865900: Avg Loss =  0.22008\n",
      "Iteration 866000: Avg Loss =  0.23376\n",
      "Iteration 866100: Avg Loss =  0.23422\n",
      "Iteration 866200: Avg Loss =  0.19579\n",
      "Iteration 866300: Avg Loss =  0.19749\n",
      "Iteration 866400: Avg Loss =  0.17394\n",
      "Iteration 866500: Avg Loss =  0.23949\n",
      "Iteration 866600: Avg Loss =  0.16504\n",
      "Iteration 866700: Avg Loss =  0.20673\n",
      "Iteration 866800: Avg Loss =  0.17437\n",
      "Iteration 866900: Avg Loss =  0.18366\n",
      "Iteration 867000: Avg Loss =  0.23157\n",
      "Iteration 867100: Avg Loss =  0.16360\n",
      "Iteration 867200: Avg Loss =  0.21113\n",
      "Iteration 867300: Avg Loss =  0.16548\n",
      "Iteration 867400: Avg Loss =  0.19885\n",
      "Iteration 867500: Avg Loss =  0.19604\n",
      "Iteration 867600: Avg Loss =  0.15554\n",
      "Iteration 867700: Avg Loss =  0.17325\n",
      "Iteration 867800: Avg Loss =  0.21156\n",
      "Iteration 867900: Avg Loss =  0.20572\n",
      "Iteration 868000: Avg Loss =  0.16793\n",
      "Iteration 868100: Avg Loss =  0.23534\n",
      "Iteration 868200: Avg Loss =  0.17923\n",
      "Iteration 868300: Avg Loss =  0.19883\n",
      "Iteration 868400: Avg Loss =  0.23277\n",
      "Iteration 868500: Avg Loss =  0.18918\n",
      "Iteration 868600: Avg Loss =  0.21946\n",
      "Iteration 868700: Avg Loss =  0.22053\n",
      "Iteration 868800: Avg Loss =  0.19549\n",
      "Iteration 868900: Avg Loss =  0.21889\n",
      "Iteration 869000: Avg Loss =  0.23291\n",
      "Iteration 869100: Avg Loss =  0.24690\n",
      "Iteration 869200: Avg Loss =  0.19825\n",
      "Iteration 869300: Avg Loss =  0.18301\n",
      "Iteration 869400: Avg Loss =  0.15719\n",
      "Iteration 869500: Avg Loss =  0.16152\n",
      "Iteration 869600: Avg Loss =  0.19344\n",
      "Iteration 869700: Avg Loss =  0.17870\n",
      "Iteration 869800: Avg Loss =  0.23026\n",
      "Iteration 869900: Avg Loss =  0.24884\n",
      "Iteration 870000: Avg Loss =  0.17170\n",
      "Iteration 870100: Avg Loss =  0.19781\n",
      "Iteration 870200: Avg Loss =  0.19699\n",
      "Iteration 870300: Avg Loss =  0.22816\n",
      "Iteration 870400: Avg Loss =  0.17278\n",
      "Iteration 870500: Avg Loss =  0.21587\n",
      "Iteration 870600: Avg Loss =  0.15514\n",
      "Iteration 870700: Avg Loss =  0.20473\n",
      "Iteration 870800: Avg Loss =  0.17819\n",
      "Iteration 870900: Avg Loss =  0.21045\n",
      "Iteration 871000: Avg Loss =  0.24152\n",
      "Iteration 871100: Avg Loss =  0.19302\n",
      "Iteration 871200: Avg Loss =  0.20264\n",
      "Iteration 871300: Avg Loss =  0.21750\n",
      "Iteration 871400: Avg Loss =  0.18848\n",
      "Iteration 871500: Avg Loss =  0.14042\n",
      "Iteration 871600: Avg Loss =  0.21535\n",
      "Iteration 871700: Avg Loss =  0.21008\n",
      "Iteration 871800: Avg Loss =  0.17683\n",
      "Iteration 871900: Avg Loss =  0.21407\n",
      "Iteration 872000: Avg Loss =  0.21228\n",
      "Iteration 872100: Avg Loss =  0.15633\n",
      "Iteration 872200: Avg Loss =  0.16460\n",
      "Iteration 872300: Avg Loss =  0.20750\n",
      "Iteration 872400: Avg Loss =  0.20581\n",
      "Iteration 872500: Avg Loss =  0.22180\n",
      "Iteration 872600: Avg Loss =  0.20845\n",
      "Iteration 872700: Avg Loss =  0.17162\n",
      "Iteration 872800: Avg Loss =  0.18507\n",
      "Iteration 872900: Avg Loss =  0.18310\n",
      "Iteration 873000: Avg Loss =  0.20244\n",
      "Iteration 873100: Avg Loss =  0.18960\n",
      "Iteration 873200: Avg Loss =  0.21283\n",
      "Iteration 873300: Avg Loss =  0.15193\n",
      "Iteration 873400: Avg Loss =  0.17718\n",
      "Iteration 873500: Avg Loss =  0.22152\n",
      "Iteration 873600: Avg Loss =  0.15125\n",
      "Iteration 873700: Avg Loss =  0.18325\n",
      "Iteration 873800: Avg Loss =  0.22271\n",
      "Iteration 873900: Avg Loss =  0.16616\n",
      "Iteration 874000: Avg Loss =  0.17068\n",
      "Iteration 874100: Avg Loss =  0.22582\n",
      "Iteration 874200: Avg Loss =  0.20395\n",
      "Iteration 874300: Avg Loss =  0.20022\n",
      "Iteration 874400: Avg Loss =  0.19856\n",
      "Iteration 874500: Avg Loss =  0.17186\n",
      "Iteration 874600: Avg Loss =  0.19550\n",
      "Iteration 874700: Avg Loss =  0.20793\n",
      "Iteration 874800: Avg Loss =  0.19998\n",
      "Iteration 874900: Avg Loss =  0.20565\n",
      "Iteration 875000: Avg Loss =  0.21405\n",
      "Iteration 875100: Avg Loss =  0.23087\n",
      "Iteration 875200: Avg Loss =  0.17175\n",
      "Iteration 875300: Avg Loss =  0.19824\n",
      "Iteration 875400: Avg Loss =  0.19265\n",
      "Iteration 875500: Avg Loss =  0.14778\n",
      "Iteration 875600: Avg Loss =  0.20136\n",
      "Iteration 875700: Avg Loss =  0.20370\n",
      "Iteration 875800: Avg Loss =  0.24013\n",
      "Iteration 875900: Avg Loss =  0.19942\n",
      "Iteration 876000: Avg Loss =  0.17697\n",
      "Iteration 876100: Avg Loss =  0.18747\n",
      "Iteration 876200: Avg Loss =  0.17392\n",
      "Iteration 876300: Avg Loss =  0.17405\n",
      "Iteration 876400: Avg Loss =  0.16785\n",
      "Iteration 876500: Avg Loss =  0.18044\n",
      "Iteration 876600: Avg Loss =  0.20019\n",
      "Iteration 876700: Avg Loss =  0.16682\n",
      "Iteration 876800: Avg Loss =  0.17984\n",
      "Iteration 876900: Avg Loss =  0.20360\n",
      "Iteration 877000: Avg Loss =  0.19976\n",
      "Iteration 877100: Avg Loss =  0.19036\n",
      "Iteration 877200: Avg Loss =  0.15852\n",
      "Iteration 877300: Avg Loss =  0.20857\n",
      "Iteration 877400: Avg Loss =  0.19426\n",
      "Iteration 877500: Avg Loss =  0.15729\n",
      "Iteration 877600: Avg Loss =  0.19250\n",
      "Iteration 877700: Avg Loss =  0.20242\n",
      "Iteration 877800: Avg Loss =  0.20018\n",
      "Iteration 877900: Avg Loss =  0.20239\n",
      "Iteration 878000: Avg Loss =  0.17416\n",
      "Iteration 878100: Avg Loss =  0.16226\n",
      "Iteration 878200: Avg Loss =  0.18002\n",
      "Iteration 878300: Avg Loss =  0.18561\n",
      "Iteration 878400: Avg Loss =  0.19930\n",
      "Iteration 878500: Avg Loss =  0.19767\n",
      "Iteration 878600: Avg Loss =  0.19782\n",
      "Iteration 878700: Avg Loss =  0.21301\n",
      "Iteration 878800: Avg Loss =  0.18433\n",
      "Iteration 878900: Avg Loss =  0.20399\n",
      "Iteration 879000: Avg Loss =  0.20802\n",
      "Iteration 879100: Avg Loss =  0.17894\n",
      "Iteration 879200: Avg Loss =  0.17151\n",
      "Iteration 879300: Avg Loss =  0.19340\n",
      "Iteration 879400: Avg Loss =  0.17795\n",
      "Iteration 879500: Avg Loss =  0.20768\n",
      "Iteration 879600: Avg Loss =  0.18602\n",
      "Iteration 879700: Avg Loss =  0.18548\n",
      "Iteration 879800: Avg Loss =  0.21032\n",
      "Iteration 879900: Avg Loss =  0.21746\n",
      "Iteration 880000: Avg Loss =  0.19346\n",
      "Iteration 880100: Avg Loss =  0.20514\n",
      "Iteration 880200: Avg Loss =  0.23169\n",
      "Iteration 880300: Avg Loss =  0.24138\n",
      "Iteration 880400: Avg Loss =  0.19638\n",
      "Iteration 880500: Avg Loss =  0.17784\n",
      "Iteration 880600: Avg Loss =  0.23072\n",
      "Iteration 880700: Avg Loss =  0.18317\n",
      "Iteration 880800: Avg Loss =  0.21331\n",
      "Iteration 880900: Avg Loss =  0.20545\n",
      "Iteration 881000: Avg Loss =  0.21980\n",
      "Iteration 881100: Avg Loss =  0.16936\n",
      "Iteration 881200: Avg Loss =  0.21306\n",
      "Iteration 881300: Avg Loss =  0.18722\n",
      "Iteration 881400: Avg Loss =  0.17673\n",
      "Iteration 881500: Avg Loss =  0.23125\n",
      "Iteration 881600: Avg Loss =  0.17933\n",
      "Iteration 881700: Avg Loss =  0.18158\n",
      "Iteration 881800: Avg Loss =  0.19285\n",
      "Iteration 881900: Avg Loss =  0.22612\n",
      "Iteration 882000: Avg Loss =  0.18290\n",
      "Iteration 882100: Avg Loss =  0.20987\n",
      "Iteration 882200: Avg Loss =  0.22146\n",
      "Iteration 882300: Avg Loss =  0.16984\n",
      "Iteration 882400: Avg Loss =  0.19898\n",
      "Iteration 882500: Avg Loss =  0.21074\n",
      "Iteration 882600: Avg Loss =  0.22386\n",
      "Iteration 882700: Avg Loss =  0.18433\n",
      "Iteration 882800: Avg Loss =  0.21472\n",
      "Iteration 882900: Avg Loss =  0.21426\n",
      "Iteration 883000: Avg Loss =  0.19802\n",
      "Iteration 883100: Avg Loss =  0.19339\n",
      "Iteration 883200: Avg Loss =  0.15954\n",
      "Iteration 883300: Avg Loss =  0.16919\n",
      "Iteration 883400: Avg Loss =  0.19607\n",
      "Iteration 883500: Avg Loss =  0.21934\n",
      "Iteration 883600: Avg Loss =  0.19536\n",
      "Iteration 883700: Avg Loss =  0.18132\n",
      "Iteration 883800: Avg Loss =  0.21279\n",
      "Iteration 883900: Avg Loss =  0.25472\n",
      "Iteration 884000: Avg Loss =  0.19487\n",
      "Iteration 884100: Avg Loss =  0.20957\n",
      "Iteration 884200: Avg Loss =  0.23077\n",
      "Iteration 884300: Avg Loss =  0.20318\n",
      "Iteration 884400: Avg Loss =  0.22556\n",
      "Iteration 884500: Avg Loss =  0.19426\n",
      "Iteration 884600: Avg Loss =  0.16200\n",
      "Iteration 884700: Avg Loss =  0.21566\n",
      "Iteration 884800: Avg Loss =  0.22780\n",
      "Iteration 884900: Avg Loss =  0.21980\n",
      "Iteration 885000: Avg Loss =  0.17856\n",
      "Iteration 885100: Avg Loss =  0.18067\n",
      "Iteration 885200: Avg Loss =  0.18961\n",
      "Iteration 885300: Avg Loss =  0.18915\n",
      "Iteration 885400: Avg Loss =  0.17222\n",
      "Iteration 885500: Avg Loss =  0.19940\n",
      "Iteration 885600: Avg Loss =  0.18524\n",
      "Iteration 885700: Avg Loss =  0.23481\n",
      "Iteration 885800: Avg Loss =  0.21102\n",
      "Iteration 885900: Avg Loss =  0.17921\n",
      "Iteration 886000: Avg Loss =  0.18960\n",
      "Iteration 886100: Avg Loss =  0.16501\n",
      "Iteration 886200: Avg Loss =  0.16745\n",
      "Iteration 886300: Avg Loss =  0.19923\n",
      "Iteration 886400: Avg Loss =  0.20771\n",
      "Iteration 886500: Avg Loss =  0.17577\n",
      "Iteration 886600: Avg Loss =  0.15846\n",
      "Iteration 886700: Avg Loss =  0.17751\n",
      "Iteration 886800: Avg Loss =  0.17698\n",
      "Iteration 886900: Avg Loss =  0.17020\n",
      "Iteration 887000: Avg Loss =  0.17605\n",
      "Iteration 887100: Avg Loss =  0.21858\n",
      "Iteration 887200: Avg Loss =  0.19163\n",
      "Iteration 887300: Avg Loss =  0.19256\n",
      "Iteration 887400: Avg Loss =  0.17199\n",
      "Iteration 887500: Avg Loss =  0.16503\n",
      "Iteration 887600: Avg Loss =  0.18211\n",
      "Iteration 887700: Avg Loss =  0.21983\n",
      "Iteration 887800: Avg Loss =  0.17838\n",
      "Iteration 887900: Avg Loss =  0.18881\n",
      "Iteration 888000: Avg Loss =  0.18371\n",
      "Iteration 888100: Avg Loss =  0.20306\n",
      "Iteration 888200: Avg Loss =  0.18069\n",
      "Iteration 888300: Avg Loss =  0.18348\n",
      "Iteration 888400: Avg Loss =  0.21484\n",
      "Iteration 888500: Avg Loss =  0.18292\n",
      "Iteration 888600: Avg Loss =  0.23834\n",
      "Iteration 888700: Avg Loss =  0.16250\n",
      "Iteration 888800: Avg Loss =  0.19944\n",
      "Iteration 888900: Avg Loss =  0.17655\n",
      "Iteration 889000: Avg Loss =  0.16458\n",
      "Iteration 889100: Avg Loss =  0.25116\n",
      "Iteration 889200: Avg Loss =  0.18692\n",
      "Iteration 889300: Avg Loss =  0.17064\n",
      "Iteration 889400: Avg Loss =  0.15844\n",
      "Iteration 889500: Avg Loss =  0.18223\n",
      "Iteration 889600: Avg Loss =  0.22457\n",
      "Iteration 889700: Avg Loss =  0.17963\n",
      "Iteration 889800: Avg Loss =  0.16391\n",
      "Iteration 889900: Avg Loss =  0.21887\n",
      "Iteration 890000: Avg Loss =  0.16964\n",
      "Iteration 890100: Avg Loss =  0.20194\n",
      "Iteration 890200: Avg Loss =  0.17214\n",
      "Iteration 890300: Avg Loss =  0.19231\n",
      "Iteration 890400: Avg Loss =  0.15626\n",
      "Iteration 890500: Avg Loss =  0.19494\n",
      "Iteration 890600: Avg Loss =  0.16625\n",
      "Iteration 890700: Avg Loss =  0.18295\n",
      "Iteration 890800: Avg Loss =  0.22451\n",
      "Iteration 890900: Avg Loss =  0.17651\n",
      "Iteration 891000: Avg Loss =  0.18109\n",
      "Iteration 891100: Avg Loss =  0.19938\n",
      "Iteration 891200: Avg Loss =  0.21500\n",
      "Iteration 891300: Avg Loss =  0.22301\n",
      "Iteration 891400: Avg Loss =  0.17529\n",
      "Iteration 891500: Avg Loss =  0.21357\n",
      "Iteration 891600: Avg Loss =  0.17253\n",
      "Iteration 891700: Avg Loss =  0.18803\n",
      "Iteration 891800: Avg Loss =  0.19094\n",
      "Iteration 891900: Avg Loss =  0.24510\n",
      "Iteration 892000: Avg Loss =  0.17262\n",
      "Iteration 892100: Avg Loss =  0.17498\n",
      "Iteration 892200: Avg Loss =  0.18907\n",
      "Iteration 892300: Avg Loss =  0.21789\n",
      "Iteration 892400: Avg Loss =  0.17612\n",
      "Iteration 892500: Avg Loss =  0.17385\n",
      "Iteration 892600: Avg Loss =  0.18352\n",
      "Iteration 892700: Avg Loss =  0.22694\n",
      "Iteration 892800: Avg Loss =  0.22057\n",
      "Iteration 892900: Avg Loss =  0.19653\n",
      "Iteration 893000: Avg Loss =  0.22324\n",
      "Iteration 893100: Avg Loss =  0.23891\n",
      "Iteration 893200: Avg Loss =  0.23848\n",
      "Iteration 893300: Avg Loss =  0.20568\n",
      "Iteration 893400: Avg Loss =  0.16024\n",
      "Iteration 893500: Avg Loss =  0.19461\n",
      "Iteration 893600: Avg Loss =  0.21353\n",
      "Iteration 893700: Avg Loss =  0.16288\n",
      "Iteration 893800: Avg Loss =  0.20276\n",
      "Iteration 893900: Avg Loss =  0.20353\n",
      "Iteration 894000: Avg Loss =  0.15043\n",
      "Iteration 894100: Avg Loss =  0.17000\n",
      "Iteration 894200: Avg Loss =  0.22791\n",
      "Iteration 894300: Avg Loss =  0.22601\n",
      "Iteration 894400: Avg Loss =  0.16174\n",
      "Iteration 894500: Avg Loss =  0.16022\n",
      "Iteration 894600: Avg Loss =  0.16580\n",
      "Iteration 894700: Avg Loss =  0.18132\n",
      "Iteration 894800: Avg Loss =  0.18528\n",
      "Iteration 894900: Avg Loss =  0.17467\n",
      "Iteration 895000: Avg Loss =  0.21328\n",
      "Iteration 895100: Avg Loss =  0.14668\n",
      "Iteration 895200: Avg Loss =  0.19300\n",
      "Iteration 895300: Avg Loss =  0.19246\n",
      "Iteration 895400: Avg Loss =  0.19731\n",
      "Iteration 895500: Avg Loss =  0.18912\n",
      "Iteration 895600: Avg Loss =  0.19457\n",
      "Iteration 895700: Avg Loss =  0.20684\n",
      "Iteration 895800: Avg Loss =  0.21949\n",
      "Iteration 895900: Avg Loss =  0.16715\n",
      "Iteration 896000: Avg Loss =  0.14662\n",
      "Iteration 896100: Avg Loss =  0.20280\n",
      "Iteration 896200: Avg Loss =  0.19800\n",
      "Iteration 896300: Avg Loss =  0.20104\n",
      "Iteration 896400: Avg Loss =  0.22590\n",
      "Iteration 896500: Avg Loss =  0.19939\n",
      "Iteration 896600: Avg Loss =  0.16801\n",
      "Iteration 896700: Avg Loss =  0.15916\n",
      "Iteration 896800: Avg Loss =  0.17914\n",
      "Iteration 896900: Avg Loss =  0.20202\n",
      "Iteration 897000: Avg Loss =  0.19740\n",
      "Iteration 897100: Avg Loss =  0.18523\n",
      "Iteration 897200: Avg Loss =  0.18467\n",
      "Iteration 897300: Avg Loss =  0.17553\n",
      "Iteration 897400: Avg Loss =  0.18296\n",
      "Iteration 897500: Avg Loss =  0.17620\n",
      "Iteration 897600: Avg Loss =  0.20977\n",
      "Iteration 897700: Avg Loss =  0.21927\n",
      "Iteration 897800: Avg Loss =  0.23370\n",
      "Iteration 897900: Avg Loss =  0.17959\n",
      "Iteration 898000: Avg Loss =  0.20135\n",
      "Iteration 898100: Avg Loss =  0.18465\n",
      "Iteration 898200: Avg Loss =  0.16545\n",
      "Iteration 898300: Avg Loss =  0.21866\n",
      "Iteration 898400: Avg Loss =  0.21427\n",
      "Iteration 898500: Avg Loss =  0.17381\n",
      "Iteration 898600: Avg Loss =  0.19737\n",
      "Iteration 898700: Avg Loss =  0.19821\n",
      "Iteration 898800: Avg Loss =  0.17142\n",
      "Iteration 898900: Avg Loss =  0.14040\n",
      "Iteration 899000: Avg Loss =  0.19721\n",
      "Iteration 899100: Avg Loss =  0.16075\n",
      "Iteration 899200: Avg Loss =  0.17156\n",
      "Iteration 899300: Avg Loss =  0.20760\n",
      "Iteration 899400: Avg Loss =  0.19235\n",
      "Iteration 899500: Avg Loss =  0.19444\n",
      "Iteration 899600: Avg Loss =  0.21982\n",
      "Iteration 899700: Avg Loss =  0.20382\n",
      "Iteration 899800: Avg Loss =  0.17676\n",
      "Iteration 899900: Avg Loss =  0.19010\n",
      "Iteration 900000: Avg Loss =  0.16290\n",
      "Iteration 900100: Avg Loss =  0.19574\n",
      "Iteration 900200: Avg Loss =  0.21273\n",
      "Iteration 900300: Avg Loss =  0.18232\n",
      "Iteration 900400: Avg Loss =  0.17515\n",
      "Iteration 900500: Avg Loss =  0.21440\n",
      "Iteration 900600: Avg Loss =  0.18234\n",
      "Iteration 900700: Avg Loss =  0.20277\n",
      "Iteration 900800: Avg Loss =  0.17772\n",
      "Iteration 900900: Avg Loss =  0.21907\n",
      "Iteration 901000: Avg Loss =  0.19074\n",
      "Iteration 901100: Avg Loss =  0.17149\n",
      "Iteration 901200: Avg Loss =  0.19445\n",
      "Iteration 901300: Avg Loss =  0.22416\n",
      "Iteration 901400: Avg Loss =  0.17852\n",
      "Iteration 901500: Avg Loss =  0.19862\n",
      "Iteration 901600: Avg Loss =  0.19247\n",
      "Iteration 901700: Avg Loss =  0.14820\n",
      "Iteration 901800: Avg Loss =  0.19456\n",
      "Iteration 901900: Avg Loss =  0.16126\n",
      "Iteration 902000: Avg Loss =  0.19456\n",
      "Iteration 902100: Avg Loss =  0.17288\n",
      "Iteration 902200: Avg Loss =  0.17039\n",
      "Iteration 902300: Avg Loss =  0.21121\n",
      "Iteration 902400: Avg Loss =  0.16769\n",
      "Iteration 902500: Avg Loss =  0.13872\n",
      "Iteration 902600: Avg Loss =  0.15420\n",
      "Iteration 902700: Avg Loss =  0.15735\n",
      "Iteration 902800: Avg Loss =  0.16924\n",
      "Iteration 902900: Avg Loss =  0.18835\n",
      "Iteration 903000: Avg Loss =  0.22621\n",
      "Iteration 903100: Avg Loss =  0.20366\n",
      "Iteration 903200: Avg Loss =  0.21882\n",
      "Iteration 903300: Avg Loss =  0.18415\n",
      "Iteration 903400: Avg Loss =  0.19261\n",
      "Iteration 903500: Avg Loss =  0.16224\n",
      "Iteration 903600: Avg Loss =  0.20358\n",
      "Iteration 903700: Avg Loss =  0.16211\n",
      "Iteration 903800: Avg Loss =  0.17814\n",
      "Iteration 903900: Avg Loss =  0.21416\n",
      "Iteration 904000: Avg Loss =  0.16360\n",
      "Iteration 904100: Avg Loss =  0.17761\n",
      "Iteration 904200: Avg Loss =  0.20048\n",
      "Iteration 904300: Avg Loss =  0.18199\n",
      "Iteration 904400: Avg Loss =  0.16251\n",
      "Iteration 904500: Avg Loss =  0.17917\n",
      "Iteration 904600: Avg Loss =  0.20663\n",
      "Iteration 904700: Avg Loss =  0.23486\n",
      "Iteration 904800: Avg Loss =  0.19018\n",
      "Iteration 904900: Avg Loss =  0.19336\n",
      "Iteration 905000: Avg Loss =  0.14747\n",
      "Iteration 905100: Avg Loss =  0.18515\n",
      "Iteration 905200: Avg Loss =  0.22358\n",
      "Iteration 905300: Avg Loss =  0.14326\n",
      "Iteration 905400: Avg Loss =  0.19230\n",
      "Iteration 905500: Avg Loss =  0.20313\n",
      "Iteration 905600: Avg Loss =  0.17679\n",
      "Iteration 905700: Avg Loss =  0.21892\n",
      "Iteration 905800: Avg Loss =  0.20340\n",
      "Iteration 905900: Avg Loss =  0.18797\n",
      "Iteration 906000: Avg Loss =  0.19469\n",
      "Iteration 906100: Avg Loss =  0.21231\n",
      "Iteration 906200: Avg Loss =  0.20167\n",
      "Iteration 906300: Avg Loss =  0.17999\n",
      "Iteration 906400: Avg Loss =  0.14589\n",
      "Iteration 906500: Avg Loss =  0.18142\n",
      "Iteration 906600: Avg Loss =  0.15852\n",
      "Iteration 906700: Avg Loss =  0.20248\n",
      "Iteration 906800: Avg Loss =  0.16454\n",
      "Iteration 906900: Avg Loss =  0.19675\n",
      "Iteration 907000: Avg Loss =  0.16204\n",
      "Iteration 907100: Avg Loss =  0.18276\n",
      "Iteration 907200: Avg Loss =  0.17224\n",
      "Iteration 907300: Avg Loss =  0.18844\n",
      "Iteration 907400: Avg Loss =  0.20433\n",
      "Iteration 907500: Avg Loss =  0.18201\n",
      "Iteration 907600: Avg Loss =  0.15847\n",
      "Iteration 907700: Avg Loss =  0.21666\n",
      "Iteration 907800: Avg Loss =  0.17987\n",
      "Iteration 907900: Avg Loss =  0.18387\n",
      "Iteration 908000: Avg Loss =  0.17205\n",
      "Iteration 908100: Avg Loss =  0.18089\n",
      "Iteration 908200: Avg Loss =  0.16815\n",
      "Iteration 908300: Avg Loss =  0.19050\n",
      "Iteration 908400: Avg Loss =  0.17292\n",
      "Iteration 908500: Avg Loss =  0.18782\n",
      "Iteration 908600: Avg Loss =  0.14491\n",
      "Iteration 908700: Avg Loss =  0.17257\n",
      "Iteration 908800: Avg Loss =  0.17478\n",
      "Iteration 908900: Avg Loss =  0.18112\n",
      "Iteration 909000: Avg Loss =  0.16894\n",
      "Iteration 909100: Avg Loss =  0.18216\n",
      "Iteration 909200: Avg Loss =  0.19939\n",
      "Iteration 909300: Avg Loss =  0.18884\n",
      "Iteration 909400: Avg Loss =  0.22413\n",
      "Iteration 909500: Avg Loss =  0.21620\n",
      "Iteration 909600: Avg Loss =  0.18606\n",
      "Iteration 909700: Avg Loss =  0.15213\n",
      "Iteration 909800: Avg Loss =  0.19764\n",
      "Iteration 909900: Avg Loss =  0.20678\n",
      "Iteration 910000: Avg Loss =  0.19365\n",
      "Iteration 910100: Avg Loss =  0.20278\n",
      "Iteration 910200: Avg Loss =  0.17918\n",
      "Iteration 910300: Avg Loss =  0.17820\n",
      "Iteration 910400: Avg Loss =  0.21746\n",
      "Iteration 910500: Avg Loss =  0.18306\n",
      "Iteration 910600: Avg Loss =  0.19242\n",
      "Iteration 910700: Avg Loss =  0.17498\n",
      "Iteration 910800: Avg Loss =  0.17177\n",
      "Iteration 910900: Avg Loss =  0.19456\n",
      "Iteration 911000: Avg Loss =  0.22825\n",
      "Iteration 911100: Avg Loss =  0.19997\n",
      "Iteration 911200: Avg Loss =  0.22045\n",
      "Iteration 911300: Avg Loss =  0.22633\n",
      "Iteration 911400: Avg Loss =  0.17750\n",
      "Iteration 911500: Avg Loss =  0.17071\n",
      "Iteration 911600: Avg Loss =  0.24579\n",
      "Iteration 911700: Avg Loss =  0.17511\n",
      "Iteration 911800: Avg Loss =  0.21958\n",
      "Iteration 911900: Avg Loss =  0.17326\n",
      "Iteration 912000: Avg Loss =  0.17722\n",
      "Iteration 912100: Avg Loss =  0.19326\n",
      "Iteration 912200: Avg Loss =  0.18282\n",
      "Iteration 912300: Avg Loss =  0.22369\n",
      "Iteration 912400: Avg Loss =  0.16149\n",
      "Iteration 912500: Avg Loss =  0.15968\n",
      "Iteration 912600: Avg Loss =  0.18258\n",
      "Iteration 912700: Avg Loss =  0.17524\n",
      "Iteration 912800: Avg Loss =  0.18983\n",
      "Iteration 912900: Avg Loss =  0.15949\n",
      "Iteration 913000: Avg Loss =  0.21381\n",
      "Iteration 913100: Avg Loss =  0.17160\n",
      "Iteration 913200: Avg Loss =  0.16672\n",
      "Iteration 913300: Avg Loss =  0.17473\n",
      "Iteration 913400: Avg Loss =  0.14165\n",
      "Iteration 913500: Avg Loss =  0.15932\n",
      "Iteration 913600: Avg Loss =  0.16020\n",
      "Iteration 913700: Avg Loss =  0.18047\n",
      "Iteration 913800: Avg Loss =  0.16687\n",
      "Iteration 913900: Avg Loss =  0.15387\n",
      "Iteration 914000: Avg Loss =  0.19689\n",
      "Iteration 914100: Avg Loss =  0.19133\n",
      "Iteration 914200: Avg Loss =  0.14117\n",
      "Iteration 914300: Avg Loss =  0.16140\n",
      "Iteration 914400: Avg Loss =  0.19122\n",
      "Iteration 914500: Avg Loss =  0.20848\n",
      "Iteration 914600: Avg Loss =  0.16398\n",
      "Iteration 914700: Avg Loss =  0.20488\n",
      "Iteration 914800: Avg Loss =  0.17521\n",
      "Iteration 914900: Avg Loss =  0.16685\n",
      "Iteration 915000: Avg Loss =  0.21799\n",
      "Iteration 915100: Avg Loss =  0.19575\n",
      "Iteration 915200: Avg Loss =  0.19449\n",
      "Iteration 915300: Avg Loss =  0.20887\n",
      "Iteration 915400: Avg Loss =  0.19869\n",
      "Iteration 915500: Avg Loss =  0.17695\n",
      "Iteration 915600: Avg Loss =  0.20340\n",
      "Iteration 915700: Avg Loss =  0.16710\n",
      "Iteration 915800: Avg Loss =  0.16199\n",
      "Iteration 915900: Avg Loss =  0.17674\n",
      "Iteration 916000: Avg Loss =  0.18515\n",
      "Iteration 916100: Avg Loss =  0.15053\n",
      "Iteration 916200: Avg Loss =  0.22182\n",
      "Iteration 916300: Avg Loss =  0.20304\n",
      "Iteration 916400: Avg Loss =  0.17934\n",
      "Iteration 916500: Avg Loss =  0.24963\n",
      "Iteration 916600: Avg Loss =  0.19850\n",
      "Iteration 916700: Avg Loss =  0.21224\n",
      "Iteration 916800: Avg Loss =  0.18598\n",
      "Iteration 916900: Avg Loss =  0.19716\n",
      "Iteration 917000: Avg Loss =  0.20082\n",
      "Iteration 917100: Avg Loss =  0.17781\n",
      "Iteration 917200: Avg Loss =  0.22483\n",
      "Iteration 917300: Avg Loss =  0.21335\n",
      "Iteration 917400: Avg Loss =  0.17967\n",
      "Iteration 917500: Avg Loss =  0.19783\n",
      "Iteration 917600: Avg Loss =  0.15695\n",
      "Iteration 917700: Avg Loss =  0.20136\n",
      "Iteration 917800: Avg Loss =  0.20527\n",
      "Iteration 917900: Avg Loss =  0.16835\n",
      "Iteration 918000: Avg Loss =  0.15822\n",
      "Iteration 918100: Avg Loss =  0.17842\n",
      "Iteration 918200: Avg Loss =  0.19994\n",
      "Iteration 918300: Avg Loss =  0.17834\n",
      "Iteration 918400: Avg Loss =  0.16827\n",
      "Iteration 918500: Avg Loss =  0.21072\n",
      "Iteration 918600: Avg Loss =  0.18601\n",
      "Iteration 918700: Avg Loss =  0.18315\n",
      "Iteration 918800: Avg Loss =  0.21111\n",
      "Iteration 918900: Avg Loss =  0.17943\n",
      "Iteration 919000: Avg Loss =  0.14382\n",
      "Iteration 919100: Avg Loss =  0.16427\n",
      "Iteration 919200: Avg Loss =  0.19256\n",
      "Iteration 919300: Avg Loss =  0.18643\n",
      "Iteration 919400: Avg Loss =  0.17207\n",
      "Iteration 919500: Avg Loss =  0.22712\n",
      "Iteration 919600: Avg Loss =  0.21007\n",
      "Iteration 919700: Avg Loss =  0.20964\n",
      "Iteration 919800: Avg Loss =  0.14558\n",
      "Iteration 919900: Avg Loss =  0.14606\n",
      "Iteration 920000: Avg Loss =  0.16995\n",
      "Iteration 920100: Avg Loss =  0.20164\n",
      "Iteration 920200: Avg Loss =  0.19262\n",
      "Iteration 920300: Avg Loss =  0.18969\n",
      "Iteration 920400: Avg Loss =  0.18795\n",
      "Iteration 920500: Avg Loss =  0.13870\n",
      "Iteration 920600: Avg Loss =  0.23976\n",
      "Iteration 920700: Avg Loss =  0.21586\n",
      "Iteration 920800: Avg Loss =  0.21834\n",
      "Iteration 920900: Avg Loss =  0.19034\n",
      "Iteration 921000: Avg Loss =  0.19337\n",
      "Iteration 921100: Avg Loss =  0.19211\n",
      "Iteration 921200: Avg Loss =  0.18810\n",
      "Iteration 921300: Avg Loss =  0.18553\n",
      "Iteration 921400: Avg Loss =  0.21238\n",
      "Iteration 921500: Avg Loss =  0.18657\n",
      "Iteration 921600: Avg Loss =  0.16587\n",
      "Iteration 921700: Avg Loss =  0.18526\n",
      "Iteration 921800: Avg Loss =  0.20396\n",
      "Iteration 921900: Avg Loss =  0.17109\n",
      "Iteration 922000: Avg Loss =  0.20973\n",
      "Iteration 922100: Avg Loss =  0.19300\n",
      "Iteration 922200: Avg Loss =  0.21637\n",
      "Iteration 922300: Avg Loss =  0.16177\n",
      "Iteration 922400: Avg Loss =  0.19227\n",
      "Iteration 922500: Avg Loss =  0.16106\n",
      "Iteration 922600: Avg Loss =  0.17690\n",
      "Iteration 922700: Avg Loss =  0.22449\n",
      "Iteration 922800: Avg Loss =  0.14604\n",
      "Iteration 922900: Avg Loss =  0.15860\n",
      "Iteration 923000: Avg Loss =  0.19888\n",
      "Iteration 923100: Avg Loss =  0.22515\n",
      "Iteration 923200: Avg Loss =  0.16909\n",
      "Iteration 923300: Avg Loss =  0.16244\n",
      "Iteration 923400: Avg Loss =  0.22593\n",
      "Iteration 923500: Avg Loss =  0.14251\n",
      "Iteration 923600: Avg Loss =  0.18991\n",
      "Iteration 923700: Avg Loss =  0.20716\n",
      "Iteration 923800: Avg Loss =  0.22378\n",
      "Iteration 923900: Avg Loss =  0.17413\n",
      "Iteration 924000: Avg Loss =  0.18030\n",
      "Iteration 924100: Avg Loss =  0.17348\n",
      "Iteration 924200: Avg Loss =  0.13954\n",
      "Iteration 924300: Avg Loss =  0.22587\n",
      "Iteration 924400: Avg Loss =  0.15472\n",
      "Iteration 924500: Avg Loss =  0.15771\n",
      "Iteration 924600: Avg Loss =  0.19693\n",
      "Iteration 924700: Avg Loss =  0.16428\n",
      "Iteration 924800: Avg Loss =  0.20395\n",
      "Iteration 924900: Avg Loss =  0.19631\n",
      "Iteration 925000: Avg Loss =  0.20310\n",
      "Iteration 925100: Avg Loss =  0.17907\n",
      "Iteration 925200: Avg Loss =  0.18721\n",
      "Iteration 925300: Avg Loss =  0.19270\n",
      "Iteration 925400: Avg Loss =  0.18014\n",
      "Iteration 925500: Avg Loss =  0.19654\n",
      "Iteration 925600: Avg Loss =  0.15754\n",
      "Iteration 925700: Avg Loss =  0.21426\n",
      "Iteration 925800: Avg Loss =  0.19542\n",
      "Iteration 925900: Avg Loss =  0.20675\n",
      "Iteration 926000: Avg Loss =  0.18920\n",
      "Iteration 926100: Avg Loss =  0.23310\n",
      "Iteration 926200: Avg Loss =  0.18179\n",
      "Iteration 926300: Avg Loss =  0.20674\n",
      "Iteration 926400: Avg Loss =  0.26087\n",
      "Iteration 926500: Avg Loss =  0.16967\n",
      "Iteration 926600: Avg Loss =  0.20280\n",
      "Iteration 926700: Avg Loss =  0.15931\n",
      "Iteration 926800: Avg Loss =  0.18908\n",
      "Iteration 926900: Avg Loss =  0.23340\n",
      "Iteration 927000: Avg Loss =  0.19732\n",
      "Iteration 927100: Avg Loss =  0.19647\n",
      "Iteration 927200: Avg Loss =  0.23726\n",
      "Iteration 927300: Avg Loss =  0.17095\n",
      "Iteration 927400: Avg Loss =  0.15874\n",
      "Iteration 927500: Avg Loss =  0.15170\n",
      "Iteration 927600: Avg Loss =  0.20007\n",
      "Iteration 927700: Avg Loss =  0.15549\n",
      "Iteration 927800: Avg Loss =  0.19377\n",
      "Iteration 927900: Avg Loss =  0.19491\n",
      "Iteration 928000: Avg Loss =  0.18784\n",
      "Iteration 928100: Avg Loss =  0.19307\n",
      "Iteration 928200: Avg Loss =  0.18806\n",
      "Iteration 928300: Avg Loss =  0.21331\n",
      "Iteration 928400: Avg Loss =  0.18056\n",
      "Iteration 928500: Avg Loss =  0.20021\n",
      "Iteration 928600: Avg Loss =  0.15157\n",
      "Iteration 928700: Avg Loss =  0.17843\n",
      "Iteration 928800: Avg Loss =  0.20904\n",
      "Iteration 928900: Avg Loss =  0.18935\n",
      "Iteration 929000: Avg Loss =  0.22279\n",
      "Iteration 929100: Avg Loss =  0.20024\n",
      "Iteration 929200: Avg Loss =  0.23105\n",
      "Iteration 929300: Avg Loss =  0.20772\n",
      "Iteration 929400: Avg Loss =  0.19105\n",
      "Iteration 929500: Avg Loss =  0.21522\n",
      "Iteration 929600: Avg Loss =  0.19116\n",
      "Iteration 929700: Avg Loss =  0.18858\n",
      "Iteration 929800: Avg Loss =  0.16160\n",
      "Iteration 929900: Avg Loss =  0.20916\n",
      "Iteration 930000: Avg Loss =  0.22323\n",
      "Iteration 930100: Avg Loss =  0.17612\n",
      "Iteration 930200: Avg Loss =  0.19148\n",
      "Iteration 930300: Avg Loss =  0.19840\n",
      "Iteration 930400: Avg Loss =  0.15461\n",
      "Iteration 930500: Avg Loss =  0.18107\n",
      "Iteration 930600: Avg Loss =  0.21771\n",
      "Iteration 930700: Avg Loss =  0.21308\n",
      "Iteration 930800: Avg Loss =  0.17310\n",
      "Iteration 930900: Avg Loss =  0.18632\n",
      "Iteration 931000: Avg Loss =  0.14478\n",
      "Iteration 931100: Avg Loss =  0.17725\n",
      "Iteration 931200: Avg Loss =  0.24659\n",
      "Iteration 931300: Avg Loss =  0.16923\n",
      "Iteration 931400: Avg Loss =  0.18543\n",
      "Iteration 931500: Avg Loss =  0.20759\n",
      "Iteration 931600: Avg Loss =  0.21980\n",
      "Iteration 931700: Avg Loss =  0.18587\n",
      "Iteration 931800: Avg Loss =  0.19176\n",
      "Iteration 931900: Avg Loss =  0.17916\n",
      "Iteration 932000: Avg Loss =  0.20438\n",
      "Iteration 932100: Avg Loss =  0.18810\n",
      "Iteration 932200: Avg Loss =  0.16850\n",
      "Iteration 932300: Avg Loss =  0.18836\n",
      "Iteration 932400: Avg Loss =  0.16447\n",
      "Iteration 932500: Avg Loss =  0.19758\n",
      "Iteration 932600: Avg Loss =  0.16704\n",
      "Iteration 932700: Avg Loss =  0.19775\n",
      "Iteration 932800: Avg Loss =  0.23410\n",
      "Iteration 932900: Avg Loss =  0.21930\n",
      "Iteration 933000: Avg Loss =  0.20404\n",
      "Iteration 933100: Avg Loss =  0.22492\n",
      "Iteration 933200: Avg Loss =  0.19668\n",
      "Iteration 933300: Avg Loss =  0.22913\n",
      "Iteration 933400: Avg Loss =  0.20493\n",
      "Iteration 933500: Avg Loss =  0.15805\n",
      "Iteration 933600: Avg Loss =  0.19438\n",
      "Iteration 933700: Avg Loss =  0.19483\n",
      "Iteration 933800: Avg Loss =  0.17998\n",
      "Iteration 933900: Avg Loss =  0.21732\n",
      "Iteration 934000: Avg Loss =  0.20594\n",
      "Iteration 934100: Avg Loss =  0.18667\n",
      "Iteration 934200: Avg Loss =  0.22511\n",
      "Iteration 934300: Avg Loss =  0.20458\n",
      "Iteration 934400: Avg Loss =  0.19569\n",
      "Iteration 934500: Avg Loss =  0.19667\n",
      "Iteration 934600: Avg Loss =  0.15564\n",
      "Iteration 934700: Avg Loss =  0.20343\n",
      "Iteration 934800: Avg Loss =  0.18325\n",
      "Iteration 934900: Avg Loss =  0.17418\n",
      "Iteration 935000: Avg Loss =  0.16552\n",
      "Iteration 935100: Avg Loss =  0.17097\n",
      "Iteration 935200: Avg Loss =  0.19869\n",
      "Iteration 935300: Avg Loss =  0.18500\n",
      "Iteration 935400: Avg Loss =  0.21825\n",
      "Iteration 935500: Avg Loss =  0.19308\n",
      "Iteration 935600: Avg Loss =  0.19255\n",
      "Iteration 935700: Avg Loss =  0.21620\n",
      "Iteration 935800: Avg Loss =  0.20173\n",
      "Iteration 935900: Avg Loss =  0.15885\n",
      "Iteration 936000: Avg Loss =  0.19010\n",
      "Iteration 936100: Avg Loss =  0.17442\n",
      "Iteration 936200: Avg Loss =  0.21464\n",
      "Iteration 936300: Avg Loss =  0.18997\n",
      "Iteration 936400: Avg Loss =  0.21212\n",
      "Iteration 936500: Avg Loss =  0.17088\n",
      "Iteration 936600: Avg Loss =  0.23913\n",
      "Iteration 936700: Avg Loss =  0.17413\n",
      "Iteration 936800: Avg Loss =  0.20059\n",
      "Iteration 936900: Avg Loss =  0.16673\n",
      "Iteration 937000: Avg Loss =  0.20146\n",
      "Iteration 937100: Avg Loss =  0.17127\n",
      "Iteration 937200: Avg Loss =  0.17269\n",
      "Iteration 937300: Avg Loss =  0.20905\n",
      "Iteration 937400: Avg Loss =  0.18432\n",
      "Iteration 937500: Avg Loss =  0.17541\n",
      "Iteration 937600: Avg Loss =  0.20514\n",
      "Iteration 937700: Avg Loss =  0.23399\n",
      "Iteration 937800: Avg Loss =  0.20292\n",
      "Iteration 937900: Avg Loss =  0.18020\n",
      "Iteration 938000: Avg Loss =  0.17764\n",
      "Iteration 938100: Avg Loss =  0.13787\n",
      "Iteration 938200: Avg Loss =  0.17362\n",
      "Iteration 938300: Avg Loss =  0.18302\n",
      "Iteration 938400: Avg Loss =  0.16456\n",
      "Iteration 938500: Avg Loss =  0.17269\n",
      "Iteration 938600: Avg Loss =  0.21139\n",
      "Iteration 938700: Avg Loss =  0.18440\n",
      "Iteration 938800: Avg Loss =  0.17808\n",
      "Iteration 938900: Avg Loss =  0.21915\n",
      "Iteration 939000: Avg Loss =  0.17388\n",
      "Iteration 939100: Avg Loss =  0.17292\n",
      "Iteration 939200: Avg Loss =  0.18767\n",
      "Iteration 939300: Avg Loss =  0.24231\n",
      "Iteration 939400: Avg Loss =  0.22281\n",
      "Iteration 939500: Avg Loss =  0.24088\n",
      "Iteration 939600: Avg Loss =  0.17310\n",
      "Iteration 939700: Avg Loss =  0.21247\n",
      "Iteration 939800: Avg Loss =  0.20221\n",
      "Iteration 939900: Avg Loss =  0.21016\n",
      "Iteration 940000: Avg Loss =  0.20896\n",
      "Iteration 940100: Avg Loss =  0.14246\n",
      "Iteration 940200: Avg Loss =  0.16785\n",
      "Iteration 940300: Avg Loss =  0.19116\n",
      "Iteration 940400: Avg Loss =  0.18151\n",
      "Iteration 940500: Avg Loss =  0.18336\n",
      "Iteration 940600: Avg Loss =  0.18890\n",
      "Iteration 940700: Avg Loss =  0.18668\n",
      "Iteration 940800: Avg Loss =  0.16201\n",
      "Iteration 940900: Avg Loss =  0.17385\n",
      "Iteration 941000: Avg Loss =  0.18592\n",
      "Iteration 941100: Avg Loss =  0.17825\n",
      "Iteration 941200: Avg Loss =  0.19064\n",
      "Iteration 941300: Avg Loss =  0.15129\n",
      "Iteration 941400: Avg Loss =  0.18708\n",
      "Iteration 941500: Avg Loss =  0.19412\n",
      "Iteration 941600: Avg Loss =  0.19007\n",
      "Iteration 941700: Avg Loss =  0.21143\n",
      "Iteration 941800: Avg Loss =  0.15710\n",
      "Iteration 941900: Avg Loss =  0.21657\n",
      "Iteration 942000: Avg Loss =  0.22016\n",
      "Iteration 942100: Avg Loss =  0.18409\n",
      "Iteration 942200: Avg Loss =  0.22284\n",
      "Iteration 942300: Avg Loss =  0.22344\n",
      "Iteration 942400: Avg Loss =  0.20630\n",
      "Iteration 942500: Avg Loss =  0.20545\n",
      "Iteration 942600: Avg Loss =  0.18847\n",
      "Iteration 942700: Avg Loss =  0.19429\n",
      "Iteration 942800: Avg Loss =  0.17380\n",
      "Iteration 942900: Avg Loss =  0.20682\n",
      "Iteration 943000: Avg Loss =  0.19457\n",
      "Iteration 943100: Avg Loss =  0.21082\n",
      "Iteration 943200: Avg Loss =  0.17360\n",
      "Iteration 943300: Avg Loss =  0.14761\n",
      "Iteration 943400: Avg Loss =  0.20663\n",
      "Iteration 943500: Avg Loss =  0.21376\n",
      "Iteration 943600: Avg Loss =  0.20427\n",
      "Iteration 943700: Avg Loss =  0.20027\n",
      "Iteration 943800: Avg Loss =  0.17272\n",
      "Iteration 943900: Avg Loss =  0.20887\n",
      "Iteration 944000: Avg Loss =  0.18300\n",
      "Iteration 944100: Avg Loss =  0.21073\n",
      "Iteration 944200: Avg Loss =  0.20460\n",
      "Iteration 944300: Avg Loss =  0.22305\n",
      "Iteration 944400: Avg Loss =  0.21517\n",
      "Iteration 944500: Avg Loss =  0.18398\n",
      "Iteration 944600: Avg Loss =  0.18584\n",
      "Iteration 944700: Avg Loss =  0.15533\n",
      "Iteration 944800: Avg Loss =  0.18762\n",
      "Iteration 944900: Avg Loss =  0.19188\n",
      "Iteration 945000: Avg Loss =  0.15531\n",
      "Iteration 945100: Avg Loss =  0.19407\n",
      "Iteration 945200: Avg Loss =  0.16066\n",
      "Iteration 945300: Avg Loss =  0.17385\n",
      "Iteration 945400: Avg Loss =  0.17915\n",
      "Iteration 945500: Avg Loss =  0.17010\n",
      "Iteration 945600: Avg Loss =  0.22551\n",
      "Iteration 945700: Avg Loss =  0.21003\n",
      "Iteration 945800: Avg Loss =  0.17323\n",
      "Iteration 945900: Avg Loss =  0.15872\n",
      "Iteration 946000: Avg Loss =  0.17188\n",
      "Iteration 946100: Avg Loss =  0.17239\n",
      "Iteration 946200: Avg Loss =  0.23090\n",
      "Iteration 946300: Avg Loss =  0.19278\n",
      "Iteration 946400: Avg Loss =  0.18004\n",
      "Iteration 946500: Avg Loss =  0.20056\n",
      "Iteration 946600: Avg Loss =  0.19174\n",
      "Iteration 946700: Avg Loss =  0.22900\n",
      "Iteration 946800: Avg Loss =  0.15937\n",
      "Iteration 946900: Avg Loss =  0.18360\n",
      "Iteration 947000: Avg Loss =  0.18179\n",
      "Iteration 947100: Avg Loss =  0.19954\n",
      "Iteration 947200: Avg Loss =  0.24219\n",
      "Iteration 947300: Avg Loss =  0.18245\n",
      "Iteration 947400: Avg Loss =  0.14592\n",
      "Iteration 947500: Avg Loss =  0.18463\n",
      "Iteration 947600: Avg Loss =  0.14665\n",
      "Iteration 947700: Avg Loss =  0.19595\n",
      "Iteration 947800: Avg Loss =  0.15795\n",
      "Iteration 947900: Avg Loss =  0.15996\n",
      "Iteration 948000: Avg Loss =  0.17275\n",
      "Iteration 948100: Avg Loss =  0.18520\n",
      "Iteration 948200: Avg Loss =  0.17384\n",
      "Iteration 948300: Avg Loss =  0.19139\n",
      "Iteration 948400: Avg Loss =  0.17748\n",
      "Iteration 948500: Avg Loss =  0.19427\n",
      "Iteration 948600: Avg Loss =  0.17768\n",
      "Iteration 948700: Avg Loss =  0.14752\n",
      "Iteration 948800: Avg Loss =  0.19817\n",
      "Iteration 948900: Avg Loss =  0.18582\n",
      "Iteration 949000: Avg Loss =  0.18512\n",
      "Iteration 949100: Avg Loss =  0.16022\n",
      "Iteration 949200: Avg Loss =  0.18187\n",
      "Iteration 949300: Avg Loss =  0.18559\n",
      "Iteration 949400: Avg Loss =  0.17535\n",
      "Iteration 949500: Avg Loss =  0.21678\n",
      "Iteration 949600: Avg Loss =  0.19336\n",
      "Iteration 949700: Avg Loss =  0.20621\n",
      "Iteration 949800: Avg Loss =  0.19832\n",
      "Iteration 949900: Avg Loss =  0.18917\n",
      "Iteration 950000: Avg Loss =  0.19948\n",
      "Iteration 950100: Avg Loss =  0.23127\n",
      "Iteration 950200: Avg Loss =  0.21498\n",
      "Iteration 950300: Avg Loss =  0.15307\n",
      "Iteration 950400: Avg Loss =  0.18542\n",
      "Iteration 950500: Avg Loss =  0.16575\n",
      "Iteration 950600: Avg Loss =  0.19437\n",
      "Iteration 950700: Avg Loss =  0.18065\n",
      "Iteration 950800: Avg Loss =  0.17529\n",
      "Iteration 950900: Avg Loss =  0.16763\n",
      "Iteration 951000: Avg Loss =  0.19829\n",
      "Iteration 951100: Avg Loss =  0.19908\n",
      "Iteration 951200: Avg Loss =  0.17725\n",
      "Iteration 951300: Avg Loss =  0.21802\n",
      "Iteration 951400: Avg Loss =  0.21123\n",
      "Iteration 951500: Avg Loss =  0.21582\n",
      "Iteration 951600: Avg Loss =  0.18276\n",
      "Iteration 951700: Avg Loss =  0.17110\n",
      "Iteration 951800: Avg Loss =  0.13333\n",
      "Iteration 951900: Avg Loss =  0.17614\n",
      "Iteration 952000: Avg Loss =  0.18700\n",
      "Iteration 952100: Avg Loss =  0.21771\n",
      "Iteration 952200: Avg Loss =  0.21640\n",
      "Iteration 952300: Avg Loss =  0.19722\n",
      "Iteration 952400: Avg Loss =  0.19575\n",
      "Iteration 952500: Avg Loss =  0.16369\n",
      "Iteration 952600: Avg Loss =  0.21339\n",
      "Iteration 952700: Avg Loss =  0.21723\n",
      "Iteration 952800: Avg Loss =  0.18311\n",
      "Iteration 952900: Avg Loss =  0.18778\n",
      "Iteration 953000: Avg Loss =  0.17129\n",
      "Iteration 953100: Avg Loss =  0.17082\n",
      "Iteration 953200: Avg Loss =  0.17082\n",
      "Iteration 953300: Avg Loss =  0.20934\n",
      "Iteration 953400: Avg Loss =  0.25632\n",
      "Iteration 953500: Avg Loss =  0.18748\n",
      "Iteration 953600: Avg Loss =  0.16024\n",
      "Iteration 953700: Avg Loss =  0.16552\n",
      "Iteration 953800: Avg Loss =  0.14395\n",
      "Iteration 953900: Avg Loss =  0.22589\n",
      "Iteration 954000: Avg Loss =  0.20491\n",
      "Iteration 954100: Avg Loss =  0.17119\n",
      "Iteration 954200: Avg Loss =  0.19233\n",
      "Iteration 954300: Avg Loss =  0.21612\n",
      "Iteration 954400: Avg Loss =  0.17048\n",
      "Iteration 954500: Avg Loss =  0.16696\n",
      "Iteration 954600: Avg Loss =  0.13475\n",
      "Iteration 954700: Avg Loss =  0.16450\n",
      "Iteration 954800: Avg Loss =  0.19720\n",
      "Iteration 954900: Avg Loss =  0.18561\n",
      "Iteration 955000: Avg Loss =  0.20939\n",
      "Iteration 955100: Avg Loss =  0.16717\n",
      "Iteration 955200: Avg Loss =  0.21164\n",
      "Iteration 955300: Avg Loss =  0.20117\n",
      "Iteration 955400: Avg Loss =  0.18972\n",
      "Iteration 955500: Avg Loss =  0.19494\n",
      "Iteration 955600: Avg Loss =  0.15202\n",
      "Iteration 955700: Avg Loss =  0.16320\n",
      "Iteration 955800: Avg Loss =  0.17246\n",
      "Iteration 955900: Avg Loss =  0.17366\n",
      "Iteration 956000: Avg Loss =  0.16084\n",
      "Iteration 956100: Avg Loss =  0.18436\n",
      "Iteration 956200: Avg Loss =  0.17381\n",
      "Iteration 956300: Avg Loss =  0.19492\n",
      "Iteration 956400: Avg Loss =  0.21598\n",
      "Iteration 956500: Avg Loss =  0.19708\n",
      "Iteration 956600: Avg Loss =  0.15562\n",
      "Iteration 956700: Avg Loss =  0.19511\n",
      "Iteration 956800: Avg Loss =  0.16135\n",
      "Iteration 956900: Avg Loss =  0.19874\n",
      "Iteration 957000: Avg Loss =  0.19011\n",
      "Iteration 957100: Avg Loss =  0.18590\n",
      "Iteration 957200: Avg Loss =  0.19342\n",
      "Iteration 957300: Avg Loss =  0.25630\n",
      "Iteration 957400: Avg Loss =  0.15508\n",
      "Iteration 957500: Avg Loss =  0.18151\n",
      "Iteration 957600: Avg Loss =  0.23105\n",
      "Iteration 957700: Avg Loss =  0.19406\n",
      "Iteration 957800: Avg Loss =  0.18796\n",
      "Iteration 957900: Avg Loss =  0.25856\n",
      "Iteration 958000: Avg Loss =  0.19557\n",
      "Iteration 958100: Avg Loss =  0.18689\n",
      "Iteration 958200: Avg Loss =  0.17851\n",
      "Iteration 958300: Avg Loss =  0.21941\n",
      "Iteration 958400: Avg Loss =  0.15995\n",
      "Iteration 958500: Avg Loss =  0.18565\n",
      "Iteration 958600: Avg Loss =  0.18605\n",
      "Iteration 958700: Avg Loss =  0.20279\n",
      "Iteration 958800: Avg Loss =  0.16690\n",
      "Iteration 958900: Avg Loss =  0.17580\n",
      "Iteration 959000: Avg Loss =  0.15222\n",
      "Iteration 959100: Avg Loss =  0.16929\n",
      "Iteration 959200: Avg Loss =  0.17176\n",
      "Iteration 959300: Avg Loss =  0.17438\n",
      "Iteration 959400: Avg Loss =  0.19540\n",
      "Iteration 959500: Avg Loss =  0.18510\n",
      "Iteration 959600: Avg Loss =  0.16853\n",
      "Iteration 959700: Avg Loss =  0.20360\n",
      "Iteration 959800: Avg Loss =  0.16083\n",
      "Iteration 959900: Avg Loss =  0.19292\n",
      "Iteration 960000: Avg Loss =  0.19406\n",
      "Iteration 960100: Avg Loss =  0.15403\n",
      "Iteration 960200: Avg Loss =  0.15971\n",
      "Iteration 960300: Avg Loss =  0.20673\n",
      "Iteration 960400: Avg Loss =  0.20027\n",
      "Iteration 960500: Avg Loss =  0.20462\n",
      "Iteration 960600: Avg Loss =  0.17704\n",
      "Iteration 960700: Avg Loss =  0.17530\n",
      "Iteration 960800: Avg Loss =  0.14613\n",
      "Iteration 960900: Avg Loss =  0.20393\n",
      "Iteration 961000: Avg Loss =  0.18406\n",
      "Iteration 961100: Avg Loss =  0.21573\n",
      "Iteration 961200: Avg Loss =  0.20206\n",
      "Iteration 961300: Avg Loss =  0.21163\n",
      "Iteration 961400: Avg Loss =  0.23186\n",
      "Iteration 961500: Avg Loss =  0.18148\n",
      "Iteration 961600: Avg Loss =  0.16307\n",
      "Iteration 961700: Avg Loss =  0.17679\n",
      "Iteration 961800: Avg Loss =  0.21939\n",
      "Iteration 961900: Avg Loss =  0.19595\n",
      "Iteration 962000: Avg Loss =  0.15512\n",
      "Iteration 962100: Avg Loss =  0.19386\n",
      "Iteration 962200: Avg Loss =  0.17006\n",
      "Iteration 962300: Avg Loss =  0.17439\n",
      "Iteration 962400: Avg Loss =  0.16615\n",
      "Iteration 962500: Avg Loss =  0.19775\n",
      "Iteration 962600: Avg Loss =  0.16480\n",
      "Iteration 962700: Avg Loss =  0.18860\n",
      "Iteration 962800: Avg Loss =  0.22625\n",
      "Iteration 962900: Avg Loss =  0.15658\n",
      "Iteration 963000: Avg Loss =  0.21945\n",
      "Iteration 963100: Avg Loss =  0.15954\n",
      "Iteration 963200: Avg Loss =  0.20012\n",
      "Iteration 963300: Avg Loss =  0.21099\n",
      "Iteration 963400: Avg Loss =  0.19085\n",
      "Iteration 963500: Avg Loss =  0.19564\n",
      "Iteration 963600: Avg Loss =  0.15297\n",
      "Iteration 963700: Avg Loss =  0.15703\n",
      "Iteration 963800: Avg Loss =  0.20673\n",
      "Iteration 963900: Avg Loss =  0.18938\n",
      "Iteration 964000: Avg Loss =  0.18724\n",
      "Iteration 964100: Avg Loss =  0.17519\n",
      "Iteration 964200: Avg Loss =  0.19400\n",
      "Iteration 964300: Avg Loss =  0.18950\n",
      "Iteration 964400: Avg Loss =  0.18586\n",
      "Iteration 964500: Avg Loss =  0.17739\n",
      "Iteration 964600: Avg Loss =  0.19022\n",
      "Iteration 964700: Avg Loss =  0.18285\n",
      "Iteration 964800: Avg Loss =  0.20032\n",
      "Iteration 964900: Avg Loss =  0.19665\n",
      "Iteration 965000: Avg Loss =  0.21078\n",
      "Iteration 965100: Avg Loss =  0.20753\n",
      "Iteration 965200: Avg Loss =  0.18603\n",
      "Iteration 965300: Avg Loss =  0.20074\n",
      "Iteration 965400: Avg Loss =  0.19177\n",
      "Iteration 965500: Avg Loss =  0.23028\n",
      "Iteration 965600: Avg Loss =  0.17530\n",
      "Iteration 965700: Avg Loss =  0.16086\n",
      "Iteration 965800: Avg Loss =  0.18605\n",
      "Iteration 965900: Avg Loss =  0.19930\n",
      "Iteration 966000: Avg Loss =  0.23688\n",
      "Iteration 966100: Avg Loss =  0.14992\n",
      "Iteration 966200: Avg Loss =  0.16867\n",
      "Iteration 966300: Avg Loss =  0.15119\n",
      "Iteration 966400: Avg Loss =  0.18812\n",
      "Iteration 966500: Avg Loss =  0.19297\n",
      "Iteration 966600: Avg Loss =  0.17713\n",
      "Iteration 966700: Avg Loss =  0.20961\n",
      "Iteration 966800: Avg Loss =  0.18012\n",
      "Iteration 966900: Avg Loss =  0.17450\n",
      "Iteration 967000: Avg Loss =  0.19915\n",
      "Iteration 967100: Avg Loss =  0.19726\n",
      "Iteration 967200: Avg Loss =  0.17484\n",
      "Iteration 967300: Avg Loss =  0.18443\n",
      "Iteration 967400: Avg Loss =  0.18537\n",
      "Iteration 967500: Avg Loss =  0.18230\n",
      "Iteration 967600: Avg Loss =  0.17544\n",
      "Iteration 967700: Avg Loss =  0.17900\n",
      "Iteration 967800: Avg Loss =  0.21665\n",
      "Iteration 967900: Avg Loss =  0.18878\n",
      "Iteration 968000: Avg Loss =  0.18522\n",
      "Iteration 968100: Avg Loss =  0.19591\n",
      "Iteration 968200: Avg Loss =  0.19621\n",
      "Iteration 968300: Avg Loss =  0.18554\n",
      "Iteration 968400: Avg Loss =  0.18582\n",
      "Iteration 968500: Avg Loss =  0.20092\n",
      "Iteration 968600: Avg Loss =  0.19911\n",
      "Iteration 968700: Avg Loss =  0.16322\n",
      "Iteration 968800: Avg Loss =  0.19097\n",
      "Iteration 968900: Avg Loss =  0.17718\n",
      "Iteration 969000: Avg Loss =  0.15164\n",
      "Iteration 969100: Avg Loss =  0.13504\n",
      "Iteration 969200: Avg Loss =  0.20414\n",
      "Iteration 969300: Avg Loss =  0.18505\n",
      "Iteration 969400: Avg Loss =  0.15367\n",
      "Iteration 969500: Avg Loss =  0.16171\n",
      "Iteration 969600: Avg Loss =  0.21359\n",
      "Iteration 969700: Avg Loss =  0.20015\n",
      "Iteration 969800: Avg Loss =  0.15558\n",
      "Iteration 969900: Avg Loss =  0.19375\n",
      "Iteration 970000: Avg Loss =  0.18198\n",
      "Iteration 970100: Avg Loss =  0.15672\n",
      "Iteration 970200: Avg Loss =  0.18375\n",
      "Iteration 970300: Avg Loss =  0.15981\n",
      "Iteration 970400: Avg Loss =  0.20186\n",
      "Iteration 970500: Avg Loss =  0.19844\n",
      "Iteration 970600: Avg Loss =  0.18279\n",
      "Iteration 970700: Avg Loss =  0.16442\n",
      "Iteration 970800: Avg Loss =  0.17951\n",
      "Iteration 970900: Avg Loss =  0.24077\n",
      "Iteration 971000: Avg Loss =  0.22435\n",
      "Iteration 971100: Avg Loss =  0.18995\n",
      "Iteration 971200: Avg Loss =  0.17447\n",
      "Iteration 971300: Avg Loss =  0.16051\n",
      "Iteration 971400: Avg Loss =  0.13738\n",
      "Iteration 971500: Avg Loss =  0.17077\n",
      "Iteration 971600: Avg Loss =  0.16110\n",
      "Iteration 971700: Avg Loss =  0.19628\n",
      "Iteration 971800: Avg Loss =  0.18655\n",
      "Iteration 971900: Avg Loss =  0.22345\n",
      "Iteration 972000: Avg Loss =  0.18811\n",
      "Iteration 972100: Avg Loss =  0.18300\n",
      "Iteration 972200: Avg Loss =  0.17341\n",
      "Iteration 972300: Avg Loss =  0.21854\n",
      "Iteration 972400: Avg Loss =  0.17057\n",
      "Iteration 972500: Avg Loss =  0.22910\n",
      "Iteration 972600: Avg Loss =  0.18525\n",
      "Iteration 972700: Avg Loss =  0.16165\n",
      "Iteration 972800: Avg Loss =  0.20125\n",
      "Iteration 972900: Avg Loss =  0.24219\n",
      "Iteration 973000: Avg Loss =  0.21646\n",
      "Iteration 973100: Avg Loss =  0.20364\n",
      "Iteration 973200: Avg Loss =  0.22128\n",
      "Iteration 973300: Avg Loss =  0.17542\n",
      "Iteration 973400: Avg Loss =  0.19995\n",
      "Iteration 973500: Avg Loss =  0.17710\n",
      "Iteration 973600: Avg Loss =  0.16400\n",
      "Iteration 973700: Avg Loss =  0.18251\n",
      "Iteration 973800: Avg Loss =  0.17652\n",
      "Iteration 973900: Avg Loss =  0.15102\n",
      "Iteration 974000: Avg Loss =  0.19389\n",
      "Iteration 974100: Avg Loss =  0.16874\n",
      "Iteration 974200: Avg Loss =  0.17228\n",
      "Iteration 974300: Avg Loss =  0.18771\n",
      "Iteration 974400: Avg Loss =  0.16327\n",
      "Iteration 974500: Avg Loss =  0.15634\n",
      "Iteration 974600: Avg Loss =  0.20592\n",
      "Iteration 974700: Avg Loss =  0.18988\n",
      "Iteration 974800: Avg Loss =  0.19701\n",
      "Iteration 974900: Avg Loss =  0.17060\n",
      "Iteration 975000: Avg Loss =  0.17278\n",
      "Iteration 975100: Avg Loss =  0.18091\n",
      "Iteration 975200: Avg Loss =  0.17841\n",
      "Iteration 975300: Avg Loss =  0.16195\n",
      "Iteration 975400: Avg Loss =  0.14420\n",
      "Iteration 975500: Avg Loss =  0.20141\n",
      "Iteration 975600: Avg Loss =  0.17684\n",
      "Iteration 975700: Avg Loss =  0.18442\n",
      "Iteration 975800: Avg Loss =  0.18687\n",
      "Iteration 975900: Avg Loss =  0.16894\n",
      "Iteration 976000: Avg Loss =  0.16601\n",
      "Iteration 976100: Avg Loss =  0.18822\n",
      "Iteration 976200: Avg Loss =  0.17091\n",
      "Iteration 976300: Avg Loss =  0.20782\n",
      "Iteration 976400: Avg Loss =  0.15893\n",
      "Iteration 976500: Avg Loss =  0.23298\n",
      "Iteration 976600: Avg Loss =  0.20033\n",
      "Iteration 976700: Avg Loss =  0.21484\n",
      "Iteration 976800: Avg Loss =  0.24774\n",
      "Iteration 976900: Avg Loss =  0.20742\n",
      "Iteration 977000: Avg Loss =  0.18653\n",
      "Iteration 977100: Avg Loss =  0.16679\n",
      "Iteration 977200: Avg Loss =  0.22653\n",
      "Iteration 977300: Avg Loss =  0.17485\n",
      "Iteration 977400: Avg Loss =  0.23004\n",
      "Iteration 977500: Avg Loss =  0.19029\n",
      "Iteration 977600: Avg Loss =  0.17643\n",
      "Iteration 977700: Avg Loss =  0.15199\n",
      "Iteration 977800: Avg Loss =  0.17611\n",
      "Iteration 977900: Avg Loss =  0.16248\n",
      "Iteration 978000: Avg Loss =  0.22846\n",
      "Iteration 978100: Avg Loss =  0.20549\n",
      "Iteration 978200: Avg Loss =  0.15298\n",
      "Iteration 978300: Avg Loss =  0.17671\n",
      "Iteration 978400: Avg Loss =  0.17294\n",
      "Iteration 978500: Avg Loss =  0.17841\n",
      "Iteration 978600: Avg Loss =  0.16457\n",
      "Iteration 978700: Avg Loss =  0.21680\n",
      "Iteration 978800: Avg Loss =  0.23092\n",
      "Iteration 978900: Avg Loss =  0.16822\n",
      "Iteration 979000: Avg Loss =  0.18173\n",
      "Iteration 979100: Avg Loss =  0.18288\n",
      "Iteration 979200: Avg Loss =  0.16048\n",
      "Iteration 979300: Avg Loss =  0.17527\n",
      "Iteration 979400: Avg Loss =  0.20081\n",
      "Iteration 979500: Avg Loss =  0.20580\n",
      "Iteration 979600: Avg Loss =  0.16957\n",
      "Iteration 979700: Avg Loss =  0.18539\n",
      "Iteration 979800: Avg Loss =  0.18732\n",
      "Iteration 979900: Avg Loss =  0.21519\n",
      "Iteration 980000: Avg Loss =  0.17777\n",
      "Iteration 980100: Avg Loss =  0.20062\n",
      "Iteration 980200: Avg Loss =  0.17774\n",
      "Iteration 980300: Avg Loss =  0.22481\n",
      "Iteration 980400: Avg Loss =  0.16922\n",
      "Iteration 980500: Avg Loss =  0.17215\n",
      "Iteration 980600: Avg Loss =  0.16589\n",
      "Iteration 980700: Avg Loss =  0.15410\n",
      "Iteration 980800: Avg Loss =  0.15396\n",
      "Iteration 980900: Avg Loss =  0.13250\n",
      "Iteration 981000: Avg Loss =  0.14454\n",
      "Iteration 981100: Avg Loss =  0.18677\n",
      "Iteration 981200: Avg Loss =  0.21307\n",
      "Iteration 981300: Avg Loss =  0.19025\n",
      "Iteration 981400: Avg Loss =  0.19783\n",
      "Iteration 981500: Avg Loss =  0.23551\n",
      "Iteration 981600: Avg Loss =  0.21113\n",
      "Iteration 981700: Avg Loss =  0.19208\n",
      "Iteration 981800: Avg Loss =  0.19967\n",
      "Iteration 981900: Avg Loss =  0.18211\n",
      "Iteration 982000: Avg Loss =  0.18563\n",
      "Iteration 982100: Avg Loss =  0.19170\n",
      "Iteration 982200: Avg Loss =  0.23421\n",
      "Iteration 982300: Avg Loss =  0.14547\n",
      "Iteration 982400: Avg Loss =  0.20635\n",
      "Iteration 982500: Avg Loss =  0.19088\n",
      "Iteration 982600: Avg Loss =  0.18675\n",
      "Iteration 982700: Avg Loss =  0.21163\n",
      "Iteration 982800: Avg Loss =  0.20131\n",
      "Iteration 982900: Avg Loss =  0.16040\n",
      "Iteration 983000: Avg Loss =  0.20398\n",
      "Iteration 983100: Avg Loss =  0.15811\n",
      "Iteration 983200: Avg Loss =  0.20451\n",
      "Iteration 983300: Avg Loss =  0.17158\n",
      "Iteration 983400: Avg Loss =  0.16887\n",
      "Iteration 983500: Avg Loss =  0.20937\n",
      "Iteration 983600: Avg Loss =  0.17695\n",
      "Iteration 983700: Avg Loss =  0.18365\n",
      "Iteration 983800: Avg Loss =  0.21818\n",
      "Iteration 983900: Avg Loss =  0.18457\n",
      "Iteration 984000: Avg Loss =  0.19979\n",
      "Iteration 984100: Avg Loss =  0.18326\n",
      "Iteration 984200: Avg Loss =  0.19769\n",
      "Iteration 984300: Avg Loss =  0.18957\n",
      "Iteration 984400: Avg Loss =  0.22332\n",
      "Iteration 984500: Avg Loss =  0.14444\n",
      "Iteration 984600: Avg Loss =  0.17595\n",
      "Iteration 984700: Avg Loss =  0.18630\n",
      "Iteration 984800: Avg Loss =  0.15893\n",
      "Iteration 984900: Avg Loss =  0.19305\n",
      "Iteration 985000: Avg Loss =  0.16425\n",
      "Iteration 985100: Avg Loss =  0.19559\n",
      "Iteration 985200: Avg Loss =  0.15680\n",
      "Iteration 985300: Avg Loss =  0.20096\n",
      "Iteration 985400: Avg Loss =  0.14292\n",
      "Iteration 985500: Avg Loss =  0.18414\n",
      "Iteration 985600: Avg Loss =  0.14622\n",
      "Iteration 985700: Avg Loss =  0.15216\n",
      "Iteration 985800: Avg Loss =  0.20155\n",
      "Iteration 985900: Avg Loss =  0.18814\n",
      "Iteration 986000: Avg Loss =  0.20903\n",
      "Iteration 986100: Avg Loss =  0.21011\n",
      "Iteration 986200: Avg Loss =  0.16087\n",
      "Iteration 986300: Avg Loss =  0.14683\n",
      "Iteration 986400: Avg Loss =  0.19325\n",
      "Iteration 986500: Avg Loss =  0.19493\n",
      "Iteration 986600: Avg Loss =  0.15604\n",
      "Iteration 986700: Avg Loss =  0.18299\n",
      "Iteration 986800: Avg Loss =  0.18360\n",
      "Iteration 986900: Avg Loss =  0.17995\n",
      "Iteration 987000: Avg Loss =  0.19760\n",
      "Iteration 987100: Avg Loss =  0.14406\n",
      "Iteration 987200: Avg Loss =  0.14631\n",
      "Iteration 987300: Avg Loss =  0.19517\n",
      "Iteration 987400: Avg Loss =  0.21713\n",
      "Iteration 987500: Avg Loss =  0.17501\n",
      "Iteration 987600: Avg Loss =  0.17322\n",
      "Iteration 987700: Avg Loss =  0.18061\n",
      "Iteration 987800: Avg Loss =  0.23207\n",
      "Iteration 987900: Avg Loss =  0.18058\n",
      "Iteration 988000: Avg Loss =  0.20831\n",
      "Iteration 988100: Avg Loss =  0.20537\n",
      "Iteration 988200: Avg Loss =  0.20016\n",
      "Iteration 988300: Avg Loss =  0.14950\n",
      "Iteration 988400: Avg Loss =  0.21545\n",
      "Iteration 988500: Avg Loss =  0.17017\n",
      "Iteration 988600: Avg Loss =  0.20552\n",
      "Iteration 988700: Avg Loss =  0.19097\n",
      "Iteration 988800: Avg Loss =  0.19236\n",
      "Iteration 988900: Avg Loss =  0.18440\n",
      "Iteration 989000: Avg Loss =  0.16178\n",
      "Iteration 989100: Avg Loss =  0.17136\n",
      "Iteration 989200: Avg Loss =  0.19556\n",
      "Iteration 989300: Avg Loss =  0.21902\n",
      "Iteration 989400: Avg Loss =  0.15384\n",
      "Iteration 989500: Avg Loss =  0.19485\n",
      "Iteration 989600: Avg Loss =  0.17363\n",
      "Iteration 989700: Avg Loss =  0.18296\n",
      "Iteration 989800: Avg Loss =  0.16218\n",
      "Iteration 989900: Avg Loss =  0.16143\n",
      "Iteration 990000: Avg Loss =  0.15028\n",
      "Iteration 990100: Avg Loss =  0.18936\n",
      "Iteration 990200: Avg Loss =  0.18435\n",
      "Iteration 990300: Avg Loss =  0.15860\n",
      "Iteration 990400: Avg Loss =  0.18268\n",
      "Iteration 990500: Avg Loss =  0.21537\n",
      "Iteration 990600: Avg Loss =  0.20403\n",
      "Iteration 990700: Avg Loss =  0.19550\n",
      "Iteration 990800: Avg Loss =  0.18354\n",
      "Iteration 990900: Avg Loss =  0.21740\n",
      "Iteration 991000: Avg Loss =  0.17826\n",
      "Iteration 991100: Avg Loss =  0.17510\n",
      "Iteration 991200: Avg Loss =  0.20218\n",
      "Iteration 991300: Avg Loss =  0.14684\n",
      "Iteration 991400: Avg Loss =  0.19685\n",
      "Iteration 991500: Avg Loss =  0.15809\n",
      "Iteration 991600: Avg Loss =  0.18175\n",
      "Iteration 991700: Avg Loss =  0.18778\n",
      "Iteration 991800: Avg Loss =  0.19873\n",
      "Iteration 991900: Avg Loss =  0.22280\n",
      "Iteration 992000: Avg Loss =  0.21687\n",
      "Iteration 992100: Avg Loss =  0.18758\n",
      "Iteration 992200: Avg Loss =  0.14841\n",
      "Iteration 992300: Avg Loss =  0.19577\n",
      "Iteration 992400: Avg Loss =  0.15664\n",
      "Iteration 992500: Avg Loss =  0.15840\n",
      "Iteration 992600: Avg Loss =  0.18853\n",
      "Iteration 992700: Avg Loss =  0.17597\n",
      "Iteration 992800: Avg Loss =  0.16742\n",
      "Iteration 992900: Avg Loss =  0.15241\n",
      "Iteration 993000: Avg Loss =  0.23770\n",
      "Iteration 993100: Avg Loss =  0.21330\n",
      "Iteration 993200: Avg Loss =  0.20728\n",
      "Iteration 993300: Avg Loss =  0.21441\n",
      "Iteration 993400: Avg Loss =  0.17576\n",
      "Iteration 993500: Avg Loss =  0.17595\n",
      "Iteration 993600: Avg Loss =  0.17085\n",
      "Iteration 993700: Avg Loss =  0.19101\n",
      "Iteration 993800: Avg Loss =  0.18106\n",
      "Iteration 993900: Avg Loss =  0.16951\n",
      "Iteration 994000: Avg Loss =  0.18676\n",
      "Iteration 994100: Avg Loss =  0.15528\n",
      "Iteration 994200: Avg Loss =  0.17657\n",
      "Iteration 994300: Avg Loss =  0.21215\n",
      "Iteration 994400: Avg Loss =  0.18790\n",
      "Iteration 994500: Avg Loss =  0.18649\n",
      "Iteration 994600: Avg Loss =  0.20138\n",
      "Iteration 994700: Avg Loss =  0.17386\n",
      "Iteration 994800: Avg Loss =  0.21243\n",
      "Iteration 994900: Avg Loss =  0.17658\n",
      "Iteration 995000: Avg Loss =  0.17104\n",
      "Iteration 995100: Avg Loss =  0.19084\n",
      "Iteration 995200: Avg Loss =  0.16484\n",
      "Iteration 995300: Avg Loss =  0.21550\n",
      "Iteration 995400: Avg Loss =  0.17025\n",
      "Iteration 995500: Avg Loss =  0.18523\n",
      "Iteration 995600: Avg Loss =  0.19328\n",
      "Iteration 995700: Avg Loss =  0.18893\n",
      "Iteration 995800: Avg Loss =  0.17154\n",
      "Iteration 995900: Avg Loss =  0.16241\n",
      "Iteration 996000: Avg Loss =  0.15247\n",
      "Iteration 996100: Avg Loss =  0.18587\n",
      "Iteration 996200: Avg Loss =  0.21531\n",
      "Iteration 996300: Avg Loss =  0.18946\n",
      "Iteration 996400: Avg Loss =  0.18991\n",
      "Iteration 996500: Avg Loss =  0.17201\n",
      "Iteration 996600: Avg Loss =  0.19937\n",
      "Iteration 996700: Avg Loss =  0.16951\n",
      "Iteration 996800: Avg Loss =  0.18130\n",
      "Iteration 996900: Avg Loss =  0.18777\n",
      "Iteration 997000: Avg Loss =  0.18149\n",
      "Iteration 997100: Avg Loss =  0.24716\n",
      "Iteration 997200: Avg Loss =  0.18831\n",
      "Iteration 997300: Avg Loss =  0.21596\n",
      "Iteration 997400: Avg Loss =  0.24690\n",
      "Iteration 997500: Avg Loss =  0.15230\n",
      "Iteration 997600: Avg Loss =  0.19281\n",
      "Iteration 997700: Avg Loss =  0.17806\n",
      "Iteration 997800: Avg Loss =  0.21183\n",
      "Iteration 997900: Avg Loss =  0.18482\n",
      "Iteration 998000: Avg Loss =  0.18420\n",
      "Iteration 998100: Avg Loss =  0.16976\n",
      "Iteration 998200: Avg Loss =  0.17121\n",
      "Iteration 998300: Avg Loss =  0.23356\n",
      "Iteration 998400: Avg Loss =  0.25906\n",
      "Iteration 998500: Avg Loss =  0.15693\n",
      "Iteration 998600: Avg Loss =  0.14562\n",
      "Iteration 998700: Avg Loss =  0.17031\n",
      "Iteration 998800: Avg Loss =  0.19254\n",
      "Iteration 998900: Avg Loss =  0.20715\n",
      "Iteration 999000: Avg Loss =  0.18064\n",
      "Iteration 999100: Avg Loss =  0.18241\n",
      "Iteration 999200: Avg Loss =  0.19267\n",
      "Iteration 999300: Avg Loss =  0.14802\n",
      "Iteration 999400: Avg Loss =  0.17219\n",
      "Iteration 999500: Avg Loss =  0.16282\n",
      "Iteration 999600: Avg Loss =  0.15945\n",
      "Iteration 999700: Avg Loss =  0.16297\n",
      "Iteration 999800: Avg Loss =  0.17807\n",
      "Iteration 999900: Avg Loss =  0.19132\n",
      "Iteration 1000000: Avg Loss =  0.20171\n"
     ]
    }
   ],
   "source": [
    "from src.utils.loggers import WandBLogger\n",
    "\n",
    "horizon = 10\n",
    "input_dim = (obs_dim + action_dim) * horizon\n",
    "dataloader = DataLoader(minari_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "batch = next(iter(dataloader))\n",
    "normalized_chunks = create_normalized_chunks(batch, horizon, minari_dataset_stats)\n",
    "expert_chunk_to_overfit = normalized_chunks[0].to(device)\n",
    "assert expert_chunk_to_overfit.shape == (horizon * (obs_dim + action_dim),)\n",
    "\n",
    "\n",
    "# Try overfitting to a single chunk\n",
    "\n",
    "lr = 1e-4\n",
    "num_epochs = 1000000\n",
    "print_every = 100\n",
    "hidden_dim = 256\n",
    "\n",
    "config = {\n",
    "    \"horizon\": horizon,\n",
    "    \"action_dim\": action_dim,\n",
    "    \"obs_dim\": obs_dim,\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "logger = WandBLogger(config = config)\n",
    "vf = MLP(input_dim=input_dim, time_dim=1, hidden_dim=hidden_dim).to(device)\n",
    "path = AffineProbPath(scheduler=CondOTScheduler())\n",
    "optim = torch.optim.Adam(vf.parameters(), lr=lr)\n",
    "\n",
    "print(\"Overfitting to a single chunk...\")\n",
    "running_loss = 0.0\n",
    "for i in range(num_epochs):\n",
    "    optim.zero_grad()\n",
    "\n",
    "    x_1 = expert_chunk_to_overfit.unsqueeze(0)\n",
    "    x_0 = torch.randn_like(x_1).to(device)\n",
    "    t = torch.rand(x_1.shape[0]).to(device)\n",
    "\n",
    "    path_sample = path.sample(t=t, x_0=x_0, x_1=x_1)\n",
    "    predicted_velocity = vf(path_sample.x_t, path_sample.t)\n",
    "    loss = torch.pow(predicted_velocity - path_sample.dx_t, 2).mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    # Add the current iteration's loss to the accumulator\n",
    "    running_loss += loss.item()\n",
    "    if (i + 1) % print_every == 0:\n",
    "        avg_loss = running_loss / print_every\n",
    "        print(f\"Iteration {i+1:6d}: Avg Loss = {avg_loss:8.5f}\")\n",
    "        logger.log({\"avg_loss\": avg_loss})\n",
    "        running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c25e1",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22867d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try sampling from trained model...\n",
    "class WrappedModel(ModelWrapper):\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor, **extras):\n",
    "        return self.model(x, t)\n",
    "\n",
    "\n",
    "wrapped_vf = WrappedModel(vf)\n",
    "step_size = 0.05\n",
    "batch_size = 1  # batch size\n",
    "T = torch.linspace(0, 1, 10)  # sample times\n",
    "T = T.to(device=device)\n",
    "solver = ODESolver(velocity_model=wrapped_vf)  # create an ODESolver class\n",
    "\n",
    "\n",
    "def generate_trajectory():\n",
    "    x_init = torch.randn((batch_size, input_dim), dtype=torch.float32, device=device)\n",
    "    sol = solver.sample(\n",
    "        time_grid=T,\n",
    "        x_init=x_init,\n",
    "        method=\"midpoint\",\n",
    "        step_size=step_size,\n",
    "        return_intermediates=True,\n",
    "    )\n",
    "    final_trajectory = sol[-1].reshape(horizon, obs_dim + action_dim)\n",
    "\n",
    "    obs, act = unnormalize_trajectory(\n",
    "        final_trajectory.flatten(), minari_dataset_stats, horizon, obs_dim, action_dim\n",
    "    )\n",
    "\n",
    "    # obs = final_trajectory[:, :obs_dim]\n",
    "    # act = final_trajectory[:, obs_dim:obs_dim + action_dim]\n",
    "    return obs, act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "69c538b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0050,  1.4072, -0.5029, -0.1672,  0.0058,  0.1139,  0.0000,  0.0000],\n",
      "        [-0.0099,  1.4028, -0.4930, -0.1928,  0.0095,  0.0756,  0.0000,  0.0000],\n",
      "        [-0.0147,  1.3979, -0.4840, -0.2193,  0.0115,  0.0396,  0.0000,  0.0000],\n",
      "        [-0.0194,  1.3924, -0.4727, -0.2458,  0.0112, -0.0059,  0.0000,  0.0000],\n",
      "        [-0.0240,  1.3862, -0.4607, -0.2725,  0.0085, -0.0539,  0.0000,  0.0000],\n",
      "        [-0.0286,  1.3795, -0.4515, -0.2989,  0.0040, -0.0910,  0.0000,  0.0000],\n",
      "        [-0.0331,  1.3722, -0.4395, -0.3256, -0.0030, -0.1388,  0.0000,  0.0000],\n",
      "        [-0.0375,  1.3642, -0.4301, -0.3526, -0.0118, -0.1765,  0.0000,  0.0000],\n",
      "        [-0.0418,  1.3557, -0.4235, -0.3792, -0.0219, -0.2026,  0.0000,  0.0000],\n",
      "        [-0.0461,  1.3466, -0.4163, -0.4061, -0.0335, -0.2315,  0.0000,  0.0000]])\n",
      "tensor([[ 1.9825e-02,  1.1053e+00, -5.9895e-01, -1.4143e-01,  4.5117e-02,\n",
      "          1.5272e-01, -2.5432e-02, -9.0344e-02],\n",
      "        [ 1.2329e-03,  1.1356e+00, -5.2184e-01, -7.9205e-02,  3.9047e-02,\n",
      "          9.2838e-02,  8.1246e-02,  9.4666e-02],\n",
      "        [-6.7600e-02,  1.5620e+00, -3.6889e-01, -2.6560e-01, -1.7632e-02,\n",
      "          4.9395e-02, -6.7818e-02,  1.9375e-02],\n",
      "        [-7.2920e-02,  1.1784e+00, -4.2491e-01, -2.4153e-01,  3.9271e-02,\n",
      "         -4.4155e-02, -1.5905e-02, -4.0953e-01],\n",
      "        [-2.4432e-02,  1.3864e+00, -3.9055e-01, -1.6093e-01, -2.7530e-02,\n",
      "         -4.5344e-02,  2.0787e-02, -6.8168e-02],\n",
      "        [-2.8081e-02,  1.2570e+00, -5.8022e-01, -3.7381e-01, -2.4255e-02,\n",
      "         -9.5111e-02, -1.9512e-02,  1.0634e-01],\n",
      "        [-2.7854e-02,  1.7420e+00, -5.3259e-01, -3.5509e-01, -3.6799e-02,\n",
      "         -1.2399e-01,  7.8841e-03, -4.5900e-02],\n",
      "        [-1.3557e-04,  1.5253e+00, -3.9124e-01, -3.4982e-01,  2.1152e-02,\n",
      "         -2.0413e-01,  1.3257e-01, -7.7002e-02],\n",
      "        [-4.5078e-02,  7.8518e-01, -2.9065e-01, -4.4770e-01,  1.3559e-02,\n",
      "         -2.2034e-01, -1.8493e-01, -7.4774e-02],\n",
      "        [-5.7078e-03,  1.1962e+00, -2.9168e-01, -4.5034e-01, -1.8209e-02,\n",
      "         -2.7629e-01,  1.1256e-01,  1.4446e-01]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "observations, actions = generate_trajectory()\n",
    "original_obs, original_actions = unnormalize_trajectory(\n",
    "    expert_chunk_to_overfit,\n",
    "    minari_dataset_stats,\n",
    "    horizon,\n",
    "    obs_dim,\n",
    "    action_dim\n",
    ")\n",
    "print(original_obs)\n",
    "ax.set_title(f'Trajectories with horizon {horizon} using normalized chunks')\n",
    "\n",
    "assert original_obs.shape == (horizon, obs_dim)\n",
    "# visulizing trajectories\n",
    "for _ in range(1):\n",
    "    colors = ['red', 'green', 'blue', 'yellow']\n",
    "    observations, actions = generate_trajectory()\n",
    "    print(observations)\n",
    "    visualize_chunk(ax, observations, color='green',\n",
    "                    x_limits=(-2, 2), y_limits=(-2, 2), mode='line')\n",
    "    visualize_chunk(ax, expert_obs, color='red',\n",
    "                    x_limits=(-2, 2), y_limits=(-2, 5), mode='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66c6c74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.2956e-02,  4.6967e-01, -3.6204e-02, -8.6150e-02, -7.0379e-03,\n",
       "         -1.2734e-01, -1.0344e+00,  2.5084e-01],\n",
       "        [ 3.2303e-01,  2.3374e-01, -1.7355e-01,  3.5278e-02, -1.4114e-01,\n",
       "          1.3736e-03, -2.1346e-01, -1.8196e-01],\n",
       "        [ 1.6815e-01, -1.3625e-02, -3.1221e-01,  2.9812e-02,  1.7238e-02,\n",
       "          3.6549e-02, -4.6146e-01, -2.4894e-01],\n",
       "        [-8.6655e-02, -2.5907e-01, -3.7613e-01, -1.5994e-01,  7.7013e-02,\n",
       "          4.8848e-02,  7.7857e-02, -4.4261e-01],\n",
       "        [ 1.8848e-01,  4.8647e-01, -9.0399e-02, -2.1647e-01,  5.9825e-02,\n",
       "         -1.1675e-02, -1.2652e-01,  3.7884e-01],\n",
       "        [ 4.5760e-03,  4.1349e-01, -1.5132e-01, -1.4187e-01, -2.0863e-02,\n",
       "          3.9718e-02,  2.8556e-01, -6.0875e-01],\n",
       "        [ 1.4480e-01,  1.1424e-01,  8.2362e-02, -3.1712e-01,  2.3588e-01,\n",
       "         -5.4350e-02,  4.7168e-01, -4.0803e-01],\n",
       "        [ 1.8460e-01,  1.0713e-01, -3.4588e-02, -6.2269e-02,  1.5528e-01,\n",
       "          1.8685e-02,  4.6654e-01, -9.9737e-02],\n",
       "        [ 1.9426e-02, -8.3707e-01, -3.3204e-01, -1.9411e-01, -7.9904e-02,\n",
       "          5.8965e-02,  8.0344e-02,  2.4219e-01],\n",
       "        [-4.3934e-02,  1.3556e-01, -1.3704e-01, -2.9626e-01,  4.9505e-02,\n",
       "         -9.0402e-02,  2.1533e-01, -2.7357e-01],\n",
       "        [ 1.0586e-01, -1.6668e-02,  2.0189e-01, -1.6108e-01, -6.5016e-03,\n",
       "          8.3691e-02,  4.4933e-02,  1.3158e-01],\n",
       "        [-1.3972e-01,  7.2775e-01, -2.1345e-01,  5.2560e-02, -2.3328e-01,\n",
       "          3.6433e-02,  4.2810e-02, -6.0664e-02],\n",
       "        [ 5.1093e-02,  7.1044e-01, -2.9861e-01, -1.7725e-01,  4.6842e-02,\n",
       "         -8.6169e-02, -2.1901e-01, -1.6450e-01],\n",
       "        [-4.9985e-02,  2.1161e-01, -3.0092e-01, -2.6675e-02, -2.2882e-01,\n",
       "          1.3797e-02,  6.9380e-01, -1.0412e-01],\n",
       "        [-3.8228e-02,  2.0677e-01,  1.4553e-01,  2.8459e-01,  5.5706e-02,\n",
       "         -2.5149e-02, -1.3173e-01, -1.7592e-01],\n",
       "        [ 2.3672e-01, -4.9589e-01, -1.3802e-02, -4.2900e-01, -5.1788e-02,\n",
       "         -4.9372e-02, -7.6762e-02, -6.5580e-02],\n",
       "        [-1.0770e-02, -2.1527e-01, -2.3169e-02, -9.5678e-02,  1.0396e-01,\n",
       "         -1.0837e-01,  2.4084e-01, -2.7438e-01],\n",
       "        [ 8.9162e-02,  4.5442e-01, -6.6828e-02,  1.3649e-02, -5.0416e-02,\n",
       "          6.9034e-02,  2.4135e-01,  1.8825e-02],\n",
       "        [ 5.8553e-02,  8.6197e-02, -4.5982e-02, -1.0638e-01, -5.3886e-02,\n",
       "         -8.1612e-02,  1.5319e-01, -1.5474e-01],\n",
       "        [ 6.5673e-02,  9.9954e-01, -3.7532e-01, -1.0207e-01,  1.9170e-01,\n",
       "         -3.0990e-02,  4.4448e-01,  8.9724e-01],\n",
       "        [ 3.0277e-01,  1.9310e-02,  1.1557e-02, -3.0955e-01,  8.1069e-02,\n",
       "          6.1140e-02, -1.9076e-01, -2.7405e-01],\n",
       "        [ 1.3109e-01,  7.9902e-01, -2.3824e-01, -5.4857e-01,  1.1878e-01,\n",
       "         -1.6261e-02,  4.0743e-01, -2.9345e-01],\n",
       "        [-9.9520e-04,  5.0858e-01, -1.2597e-03, -3.7267e-02, -1.2824e-01,\n",
       "          9.8040e-03,  5.8327e-01, -7.3374e-02],\n",
       "        [ 1.2510e-01,  1.6635e-01, -1.8080e-01, -2.0702e-01, -2.1048e-01,\n",
       "         -4.1966e-02,  1.1280e-01, -9.6805e-02],\n",
       "        [ 3.1581e-03, -3.0432e-01, -2.0948e-01, -9.5327e-02, -5.4701e-02,\n",
       "         -1.1122e-01,  3.0869e-01, -5.8868e-01],\n",
       "        [ 2.5635e-01, -1.1015e+00, -2.3716e-01, -3.5852e-01, -9.2301e-02,\n",
       "          1.6545e-01, -3.2706e-01, -2.6286e-02],\n",
       "        [ 2.2987e-01,  3.7028e-01, -1.8034e-01,  6.2450e-02,  1.2697e-01,\n",
       "          7.1050e-02, -1.2903e-01,  1.2107e-01],\n",
       "        [ 2.6591e-01, -3.2252e-01,  1.6893e-01, -7.1891e-02,  1.7804e-03,\n",
       "          4.6402e-02, -2.0667e-01,  3.6344e-01],\n",
       "        [-5.9781e-02,  3.1181e-02, -3.3784e-01, -1.5908e-01,  7.1833e-02,\n",
       "         -1.2960e-01, -5.9827e-01,  1.6166e-01],\n",
       "        [ 1.1600e-01,  3.7877e-01,  1.5414e-01, -3.1983e-01,  1.3872e-01,\n",
       "          5.5958e-02, -2.4202e-01,  4.9901e-01],\n",
       "        [-2.4958e-01,  4.8300e-02, -2.3471e-01, -1.4957e-01,  1.9529e-02,\n",
       "          1.5008e-01,  1.7222e-01, -2.5374e-01],\n",
       "        [-2.4540e-01,  2.8970e-01, -8.5707e-02, -2.7555e-01, -7.0934e-02,\n",
       "         -6.4372e-02, -3.4507e-01, -2.4177e-01],\n",
       "        [-1.3335e-01, -4.7299e-02,  2.4512e-02, -2.7470e-01,  1.5806e-01,\n",
       "          7.6839e-02, -4.4668e-01, -5.1567e-02],\n",
       "        [ 3.9933e-02,  2.5925e-01, -3.9908e-01, -1.8420e-01, -1.7060e-02,\n",
       "          1.4707e-01, -3.0549e-01,  2.1559e-01],\n",
       "        [-4.2429e-02,  2.4299e-01, -8.8487e-02, -3.8231e-01,  3.4384e-02,\n",
       "         -3.9129e-02, -6.7803e-01, -1.4116e-01],\n",
       "        [-1.5101e-01, -4.0708e-01,  2.2560e-03, -4.1206e-01, -6.9124e-02,\n",
       "         -4.4967e-02, -2.2863e-01,  1.4255e-01],\n",
       "        [ 1.5336e-02,  6.5165e-02, -9.1296e-02, -2.8782e-01, -2.1537e-01,\n",
       "          4.5328e-03,  1.6134e-01,  1.9800e-01],\n",
       "        [-5.0920e-02,  7.5844e-01, -1.7103e-01, -1.1728e-01,  2.9578e-03,\n",
       "          7.7772e-02,  3.5032e-01, -2.6983e-01],\n",
       "        [ 3.1915e-02,  2.5979e-01, -4.5397e-02,  1.1597e-01, -1.1204e-02,\n",
       "         -1.3523e-01, -5.0884e-03,  3.1015e-01],\n",
       "        [ 6.2360e-02, -1.6480e-01, -1.0500e-01, -8.8000e-02, -7.6067e-02,\n",
       "         -1.2836e-01,  2.7325e-01,  1.1249e-01],\n",
       "        [ 1.3550e-01,  4.7783e-01, -7.1447e-02,  1.1784e-01, -1.5936e-01,\n",
       "         -3.6213e-02,  4.9686e-01, -2.8890e-01],\n",
       "        [ 4.5303e-02, -3.3184e-01, -7.2098e-02,  2.1024e-01, -5.1181e-03,\n",
       "         -9.2525e-02, -3.3970e-01, -3.7384e-01],\n",
       "        [ 4.3461e-02,  4.8408e-03, -7.8382e-03, -3.9586e-02, -3.0273e-01,\n",
       "          2.2601e-02,  1.0870e-01, -7.6867e-02],\n",
       "        [-9.4066e-02, -5.2910e-02,  2.8745e-01,  5.1306e-02, -1.4224e-01,\n",
       "         -1.4466e-02, -1.7670e-01, -3.8851e-01],\n",
       "        [-3.5156e-02,  9.1652e-01, -5.0430e-02,  9.0988e-02, -2.1053e-02,\n",
       "          1.0682e-01, -2.2098e-01,  4.2237e-01],\n",
       "        [ 1.1661e-01,  7.7823e-02, -2.6095e-03,  9.9737e-02,  6.3513e-02,\n",
       "         -2.6452e-02,  7.0766e-01, -1.1038e-01],\n",
       "        [ 5.7291e-02, -1.1401e-01, -1.9100e-01, -1.3648e-01,  4.9964e-02,\n",
       "         -7.5860e-02, -1.6293e-01, -2.8774e-01],\n",
       "        [ 8.5835e-02, -2.9922e-02, -1.1134e-01, -1.1394e-02, -8.8003e-02,\n",
       "         -2.1389e-02, -6.0644e-01,  2.0088e-01],\n",
       "        [ 2.1462e-02,  2.3974e-01, -1.0269e-01, -2.9649e-01, -1.6074e-02,\n",
       "         -2.5539e-02, -3.1596e-01, -1.2185e-01],\n",
       "        [-9.3541e-02, -2.1935e-01,  4.7855e-03, -1.9732e-01, -1.2337e-01,\n",
       "         -1.4856e-01, -5.3558e-01,  3.0463e-01],\n",
       "        [-8.8037e-02,  2.0208e-01, -5.7279e-02,  2.7354e-01, -2.2141e-02,\n",
       "         -4.7556e-02,  5.0899e-01, -8.0702e-02],\n",
       "        [-6.9004e-02,  9.2721e-01, -1.6490e-01, -2.5625e-01,  1.1875e-01,\n",
       "         -5.1465e-03,  6.6520e-01, -4.6004e-02],\n",
       "        [-6.9070e-02,  8.7053e-01, -4.2020e-01, -1.4338e-01, -6.9337e-02,\n",
       "          4.4463e-02,  3.5816e-01, -9.7158e-02],\n",
       "        [ 1.9028e-02, -1.8781e-01, -6.9223e-01,  5.1178e-03,  3.8624e-02,\n",
       "          8.9460e-02,  9.0604e-03, -2.5347e-01],\n",
       "        [-1.0797e-03, -2.5491e-02,  5.5785e-02, -2.1844e-01, -3.3044e-02,\n",
       "          4.2008e-02,  1.0828e-02, -4.9940e-02],\n",
       "        [ 1.7001e-01,  3.7920e-01, -3.0274e-01,  1.7515e-01, -5.2189e-02,\n",
       "          9.9366e-02, -4.0997e-01,  2.1575e-02],\n",
       "        [ 5.3342e-02, -3.2801e-01, -3.4534e-01, -3.1583e-01, -1.1726e-01,\n",
       "          1.8626e-01, -1.5401e-02,  2.5013e-01],\n",
       "        [-1.7383e-02,  1.9354e-01, -8.3432e-02,  3.0495e-01, -1.7385e-01,\n",
       "          1.2072e-01,  1.0026e+00, -3.0917e-01],\n",
       "        [ 3.3707e-01,  3.2525e-01, -1.3740e-01, -2.8725e-01, -3.7872e-02,\n",
       "         -8.2083e-02,  3.3338e-01,  3.4797e-01],\n",
       "        [ 4.7778e-02,  3.4308e-01, -1.7119e-01, -2.1643e-01, -1.5844e-02,\n",
       "          1.3287e-01, -2.9656e-01,  2.9488e-01],\n",
       "        [-1.5896e-01, -5.0001e-01, -1.2587e-01, -3.8677e-01, -2.2103e-02,\n",
       "          4.6840e-02,  2.9754e-02,  5.1086e-01],\n",
       "        [-1.0568e-01, -1.8704e-01, -5.4969e-02, -4.8283e-02, -3.8988e-02,\n",
       "          1.5898e-01,  6.2043e-01,  1.0068e+00],\n",
       "        [ 1.5983e-01, -3.6029e-01, -3.0667e-01, -3.5251e-01, -2.0999e-01,\n",
       "          2.9563e-02,  2.5778e-03,  5.1952e-01],\n",
       "        [ 1.4121e-01, -1.4630e-01, -2.4863e-01,  4.7977e-02,  2.3049e-02,\n",
       "         -1.8405e-02,  3.1788e-01,  6.8928e-01],\n",
       "        [-1.4944e-02,  1.2502e-01, -1.2793e-01, -3.3913e-02, -1.2687e-01,\n",
       "         -4.3563e-02,  6.0750e-01,  4.0778e-01],\n",
       "        [ 2.7857e-01,  5.1255e-01, -9.6317e-02, -4.1886e-02, -1.7133e-01,\n",
       "         -1.1503e-01,  7.6053e-01,  1.1182e+00],\n",
       "        [-5.4565e-03,  4.6490e-01,  4.5512e-02, -7.2936e-02,  6.5462e-02,\n",
       "         -1.4172e-01,  1.5029e+00,  9.1125e-01],\n",
       "        [ 8.5088e-02, -4.9743e-01, -6.7244e-02,  4.1933e-02,  5.9020e-02,\n",
       "         -4.9398e-02,  1.2004e+00,  1.3145e+00],\n",
       "        [ 1.4468e-01, -2.3201e-01,  1.9723e-01,  6.4363e-02,  2.4652e-01,\n",
       "         -5.6547e-02,  1.6938e+00,  8.6585e-01],\n",
       "        [-5.5350e-02, -9.5814e-01,  8.7865e-02, -3.8031e-03,  7.4375e-02,\n",
       "         -1.5081e-01,  8.9431e-01,  7.9130e-01],\n",
       "        [-1.8291e-02, -4.6997e-01, -3.7737e-01,  1.0162e-01,  1.2776e-01,\n",
       "          1.4636e-02,  1.1113e+00,  1.3062e+00],\n",
       "        [ 3.1640e-01,  3.0650e-01, -2.3100e-01,  1.3444e-01, -8.8556e-02,\n",
       "          5.7054e-02,  1.3758e+00,  1.0917e+00],\n",
       "        [ 2.4156e-01, -2.6805e-01, -4.8081e-02, -1.7048e-01, -1.2479e-01,\n",
       "          1.9638e-02,  1.3847e+00,  8.0113e-01],\n",
       "        [ 1.4117e-01,  4.4835e-01,  2.7224e-02,  2.2616e-01,  2.4679e-02,\n",
       "         -1.0264e-02,  1.0413e+00,  1.3494e+00],\n",
       "        [ 9.3512e-02,  3.8206e-01, -8.6121e-02,  1.1297e-01, -1.3801e-01,\n",
       "          1.7397e-01,  7.8286e-01,  1.1382e+00],\n",
       "        [-8.0013e-02,  8.2260e-01,  1.6039e-01,  2.6460e-01,  9.8606e-02,\n",
       "         -1.0997e-01,  9.0992e-01,  1.0058e+00],\n",
       "        [-3.3155e-03,  1.9363e-01,  5.5593e-02, -2.0834e-01,  6.8232e-05,\n",
       "          7.0497e-02,  9.7155e-01,  9.4384e-01],\n",
       "        [ 1.4357e-01, -3.9943e-01, -8.3047e-02,  4.7361e-02, -2.1970e-01,\n",
       "         -3.7091e-02,  1.3239e+00,  5.5013e-01],\n",
       "        [ 1.8441e-02, -3.4600e-01, -7.8632e-02,  1.1786e-03, -7.4589e-02,\n",
       "          8.6251e-02,  1.0031e+00,  1.2643e+00],\n",
       "        [-2.0616e-01, -7.6232e-03, -1.2127e-01, -8.9495e-02,  1.2308e-01,\n",
       "         -5.7362e-02,  6.5797e-01,  1.1633e+00],\n",
       "        [-8.7796e-02,  3.0638e-01,  1.0587e-01,  1.7159e-01,  1.9933e-01,\n",
       "         -1.9709e-01,  8.0302e-01,  1.0551e+00],\n",
       "        [-1.0223e-01, -5.5731e-02, -3.1804e-01,  2.7465e-02, -1.0792e-01,\n",
       "         -8.7816e-02,  1.3576e+00,  9.5413e-01],\n",
       "        [-1.4437e-01, -3.3943e-01,  6.1537e-03,  7.4163e-02, -1.2938e-01,\n",
       "          7.2603e-02,  1.6112e+00,  9.9320e-01],\n",
       "        [-1.6797e-01, -5.2485e-01,  1.0273e-01,  1.3290e-01, -1.6687e-01,\n",
       "         -1.7586e-01,  6.2833e-01,  7.2911e-01],\n",
       "        [ 1.5727e-01,  6.6033e-01,  4.4118e-01, -1.3612e-01,  2.3239e-02,\n",
       "         -1.6196e-01,  1.3214e+00,  9.8714e-01],\n",
       "        [-7.6512e-02, -6.4042e-01,  6.4043e-02,  6.7915e-04, -1.0324e-01,\n",
       "          3.7067e-03,  9.1137e-01,  1.3543e+00],\n",
       "        [ 2.1796e-02, -5.7191e-01,  1.7138e-01, -2.7081e-01, -1.2629e-01,\n",
       "         -1.3119e-02,  7.6212e-01,  9.8895e-01],\n",
       "        [-1.2162e-02,  2.8102e-01, -3.0829e-02, -3.3660e-02,  8.8895e-02,\n",
       "         -5.7094e-02,  1.1892e+00,  5.4607e-01],\n",
       "        [-2.1856e-01, -5.6460e-01, -1.0681e-02, -1.4405e-01,  1.2766e-01,\n",
       "          1.7006e-02,  1.5789e+00,  8.9131e-01],\n",
       "        [ 1.5890e-01,  2.1107e-01, -4.7485e-01,  1.7953e-01,  8.8728e-02,\n",
       "          2.6791e-02,  1.2785e+00,  8.2267e-01],\n",
       "        [ 1.2930e-01,  3.6491e-02, -1.4122e-01, -1.4678e-01, -5.6850e-02,\n",
       "          7.9113e-02,  9.7310e-01,  1.1264e+00],\n",
       "        [-3.1596e-02,  4.1199e-01,  7.9249e-03,  1.3353e-01, -1.2298e-01,\n",
       "          1.2737e-02,  8.0619e-01,  7.5817e-01],\n",
       "        [-2.7344e-01, -3.7317e-01,  1.3604e-01,  9.1846e-02,  2.1098e-01,\n",
       "         -2.7626e-02,  1.1997e+00,  6.6330e-01],\n",
       "        [ 1.7379e-02,  4.4801e-01,  8.1262e-02, -1.9944e-01,  2.4734e-02,\n",
       "         -8.3597e-02,  9.6996e-01,  6.4599e-01],\n",
       "        [-2.8891e-02, -5.0420e-01, -7.8003e-02,  2.0507e-01,  6.0522e-02,\n",
       "         -5.1813e-02,  9.0118e-01,  6.5227e-01],\n",
       "        [-2.2443e-02,  4.7092e-01,  1.0634e-02, -7.9042e-02,  3.6459e-02,\n",
       "         -4.4405e-03,  1.0723e+00,  1.4743e+00],\n",
       "        [-1.5359e-01,  1.6333e-03, -5.8760e-01, -6.7456e-02, -3.0657e-02,\n",
       "         -1.2431e-01,  1.5163e+00,  1.3630e+00],\n",
       "        [ 6.3563e-02, -9.2301e-01,  9.2176e-02, -1.3947e-01, -2.5774e-02,\n",
       "          1.1794e-01,  1.3815e+00,  1.5144e+00],\n",
       "        [ 2.9030e-01, -2.3325e-01,  3.1043e-02, -3.6201e-02,  1.1257e-01,\n",
       "          4.1437e-02,  5.3745e-01,  1.1143e+00],\n",
       "        [-5.3745e-02,  6.3966e-01, -9.1899e-02, -2.3715e-02, -5.3925e-02,\n",
       "         -1.9377e-01,  1.0076e+00,  7.3119e-01]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations, actions = generate_trajectory()\n",
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4042d802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode 10/100 - Model Reward: -192.8700771818713, Random Reward: -188.3357817979424\n",
      "Finished episode 20/100 - Model Reward: -64.09468973575761, Random Reward: -212.98812688138722\n",
      "Finished episode 30/100 - Model Reward: -474.06995216143383, Random Reward: -128.82188139279748\n",
      "Finished episode 40/100 - Model Reward: -273.55101054163435, Random Reward: -220.81846856456175\n",
      "Finished episode 50/100 - Model Reward: -173.59328696743677, Random Reward: -119.09430954846611\n",
      "Finished episode 60/100 - Model Reward: -536.931911231939, Random Reward: -60.05257475460127\n",
      "Finished episode 70/100 - Model Reward: -179.45538804732493, Random Reward: -17.444932806175252\n",
      "Finished episode 80/100 - Model Reward: -171.35179663487384, Random Reward: -193.8260620578572\n",
      "Finished episode 90/100 - Model Reward: -566.0786673306559, Random Reward: -21.95657731560732\n",
      "Finished episode 100/100 - Model Reward: -282.1711192997768, Random Reward: -13.373851290462005\n",
      "Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "num_eval_episodes = 100\n",
    "env = minari_dataset.recover_environment(eval_env = True)\n",
    "model_rewards = []\n",
    "random_rewards = []\n",
    "for eps in range(num_eval_episodes):\n",
    "    obs, _ = env.reset()\n",
    "    total_rew = 0\n",
    "    obs, actions = generate_trajectory()\n",
    "    for i in range(horizon):\n",
    "        action = actions[i].cpu().numpy()\n",
    "        obs, rew, terminated, truncated, info = env.step(action)\n",
    "        total_rew += rew\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    model_rewards.append(total_rew)\n",
    "\n",
    "    env.reset()\n",
    "    total_rew_random = 0\n",
    "    for i in range(horizon):\n",
    "        action = env.action_space.sample()\n",
    "        obs, rew, terminated, truncated, info = env.step(action)\n",
    "        total_rew_random += rew\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    random_rewards.append(total_rew_random)\n",
    "    if (eps + 1) % 10 == 0:\n",
    "        print(f\"Finished episode {eps + 1}/{num_eval_episodes} - Model Reward: {total_rew}, Random Reward: {total_rew_random}\")\n",
    "env.close()\n",
    "print(\"Evaluation finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0394d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minari_dataset = minari.load_dataset(dataset_id=\"LunarLanderContinuous-v3/ppo-1000-deterministic-v1\")\n",
    "env = minari_dataset.recover_environment(eval_env=True, render_mode=\"human\")\n",
    "\n",
    "obs, _ = env.reset()\n",
    "total_rew_random = 0\n",
    "obs, actions = generate_trajectory()\n",
    "total_rew = 0\n",
    "for i in range(horizon):\n",
    "    action = actions[i].cpu().numpy()\n",
    "    obs, rew, terminated, truncated, info = env.step(action)\n",
    "    total_rew += rew\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
